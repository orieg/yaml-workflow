{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"YAML Workflow Engine","text":"<p>A lightweight, powerful, and flexible workflow engine that executes tasks defined in YAML configuration files.</p>"},{"location":"#overview","title":"Overview","text":"<p>YAML Workflow is a streamlined task automation tool designed for developers. It excels at: - Running local development workflows - Automating repetitive tasks - Generating daily/weekly reports - Processing data in a structured way</p> <p>Define powerful workflows through simple YAML files with advanced features like error handling, dependencies, and conditional execution. The engine runs locally without requiring external databases or infrastructure.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Simple YAML-based workflow definitions</li> <li>Flexible task execution system</li> <li>Built-in error handling and recovery</li> <li>Modular workflow composition</li> <li>Extensive templating support</li> <li>Rich parameter handling</li> <li>Flow control and conditional execution</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code># Install the package\npip install yaml-workflow\n\n# Initialize a new project with example workflows\nyaml-workflow init --example hello_world\n\n# Run the example workflow\nyaml-workflow run workflows/hello_world.yaml name=World\n</code></pre>"},{"location":"#documentation-structure","title":"Documentation Structure","text":"<ul> <li>Guide: Tutorials, core concepts, features, and usage guides.</li> <li>Examples: Practical workflow examples.</li> <li>API Reference: Detailed API documentation for modules and classes.</li> <li>Contributing: Guidelines for contributing to the project. </li> </ul>"},{"location":"cli/","title":"Command Line Interface","text":"<p>The YAML Workflow CLI provides several commands to manage and execute workflows.</p>"},{"location":"cli/#installation","title":"Installation","text":"<p>The CLI is automatically installed with the package:</p> <pre><code>pip install yaml-workflow\n</code></pre>"},{"location":"cli/#basic-commands","title":"Basic Commands","text":""},{"location":"cli/#initialize-workflows","title":"Initialize Workflows","text":"<p>Create new workflow directories with examples:</p> <pre><code># Create workflows directory with all examples\nyaml-workflow init\n\n# Specify custom directory\nyaml-workflow init --dir my-workflows\n\n# Initialize with specific examples\nyaml-workflow init --example hello_world\nyaml-workflow init --example data_processing\n</code></pre>"},{"location":"cli/#list-workflows","title":"List Workflows","text":"<p>Display available workflows in the current directory:</p> <pre><code># List all workflows\nyaml-workflow list\n\n# List workflows in specific directory\nyaml-workflow list --dir my-workflows\n\n# Show detailed information\nyaml-workflow list --verbose\n</code></pre>"},{"location":"cli/#validate-workflows","title":"Validate Workflows","text":"<p>Check workflow configuration for errors:</p> <pre><code># Validate a specific workflow\nyaml-workflow validate workflows/hello_world.yaml\n\n# Validate all workflows in directory\nyaml-workflow validate --dir workflows/\n\n# Show detailed validation output\nyaml-workflow validate --verbose workflows/hello_world.yaml\n</code></pre>"},{"location":"cli/#run-workflows","title":"Run Workflows","text":"<p>Execute workflow files:</p> <pre><code># Run with input parameters\nyaml-workflow run workflows/hello_world.yaml name=Alice age=25\n\n# Run with environment variables\nyaml-workflow run --env-file .env workflows/process.yaml\n\n# Run specific flow\nyaml-workflow run --flow data_collection workflows/multi_flow.yaml\n\n# Resume failed workflow\nyaml-workflow run --resume workflows/long_process.yaml\n\n# Run with parallel execution\nyaml-workflow run --parallel --max-workers 4 workflows/batch_process.yaml\n</code></pre>"},{"location":"cli/#advanced-usage","title":"Advanced Usage","text":""},{"location":"cli/#environment-variables","title":"Environment Variables","text":"<p>The CLI respects the following environment variables:</p> <ul> <li><code>YAML_WORKFLOW_DIR</code>: Default workflows directory</li> <li><code>YAML_WORKFLOW_CONFIG</code>: Path to global configuration</li> <li><code>YAML_WORKFLOW_LOG_LEVEL</code>: Logging level (DEBUG, INFO, WARNING, ERROR)</li> <li><code>YAML_WORKFLOW_PARALLEL</code>: Enable parallel execution by default</li> <li><code>YAML_WORKFLOW_MAX_WORKERS</code>: Default number of parallel workers</li> </ul>"},{"location":"cli/#configuration-file","title":"Configuration File","text":"<p>Global configuration can be set in <code>~/.yaml-workflow/config.yaml</code>:</p> <pre><code>default_dir: ~/workflows\nlog_level: INFO\nparallel: false\nmax_workers: 4\nenv_files:\n  - ~/.env\n  - .env.local\n</code></pre>"},{"location":"cli/#exit-codes","title":"Exit Codes","text":"<p>The CLI uses the following exit codes:</p> <ul> <li><code>0</code>: Success</li> <li><code>1</code>: General error</li> <li><code>2</code>: Invalid configuration</li> <li><code>3</code>: Workflow execution error</li> <li><code>4</code>: Permission error</li> <li><code>5</code>: Resource not found</li> </ul>"},{"location":"cli/#logging","title":"Logging","text":"<p>Control log output with the following flags:</p> <pre><code># Enable debug logging\nyaml-workflow --debug run workflow.yaml\n\n# Quiet mode (errors only)\nyaml-workflow --quiet run workflow.yaml\n\n# Output logs to file\nyaml-workflow --log-file workflow.log run workflow.yaml\n\n# JSON format logging\nyaml-workflow --log-format json run workflow.yaml\n</code></pre>"},{"location":"cli/#examples","title":"Examples","text":""},{"location":"cli/#basic-workflow-execution","title":"Basic Workflow Execution","text":"<pre><code># Run a simple greeting workflow\nyaml-workflow run workflows/hello.yaml name=World\n\n# Expected output:\n# Starting workflow: hello\n# Step 1/1: Greeting\n# Hello, World!\n# Workflow completed successfully\n</code></pre>"},{"location":"cli/#parallel-batch-processing","title":"Parallel Batch Processing","text":"<pre><code># Process multiple files in parallel\nyaml-workflow run workflows/batch.yaml \\\n  --parallel \\\n  --max-workers 4 \\\n  input_dir=data \\\n  output_dir=processed\n</code></pre>"},{"location":"cli/#error-handling","title":"Error Handling","text":"<pre><code># Run with automatic retry on failure\nyaml-workflow run workflows/api_calls.yaml \\\n  --retry-count 3 \\\n  --retry-delay 5 \\\n  api_key=$API_KEY\n\n# Resume from last successful step\nyaml-workflow run --resume workflows/long_process.yaml\n</code></pre>"},{"location":"dependencies/","title":"Dependencies","text":"<p>YAML Workflow is designed with modularity in mind, allowing you to install only the dependencies you need for your specific use case.</p>"},{"location":"dependencies/#core-dependencies","title":"Core Dependencies","text":"<p>These dependencies are always installed with the package:</p> <pre><code>dependencies = [\n    \"pyyaml&gt;=6.0,&lt;7.0\",    # YAML parsing and writing\n    \"jinja2&gt;=3.0,&lt;4.0\",    # Template processing\n    \"click&gt;=8.0,&lt;9.0\",     # CLI interface\n]\n</code></pre>"},{"location":"dependencies/#optional-dependencies","title":"Optional Dependencies","text":""},{"location":"dependencies/#testing-dependencies","title":"Testing Dependencies","text":"<p>Required for running tests and development:</p> <pre><code>[project.optional-dependencies]\ntest = [\n    \"pytest&gt;=7.0,&lt;8.0\",        # Testing framework\n    \"pytest-cov&gt;=4.0,&lt;5.0\",    # Test coverage\n    \"mypy&gt;=1.0,&lt;2.0\",         # Type checking\n    \"types-PyYAML&gt;=6.0,&lt;7.0\", # Type stubs for PyYAML\n]\n</code></pre> <p>Install with: <pre><code>pip install yaml-workflow[test]\n</code></pre></p>"},{"location":"dependencies/#documentation-dependencies","title":"Documentation Dependencies","text":"<p>Required for building documentation:</p> <pre><code>[project.optional-dependencies]\ndoc = [\n    \"mkdocs&gt;=1.6.0,&lt;2.0\",                 # Documentation generator\n    \"mkdocs-material&gt;=9.6.0,&lt;10.0\",       # Material theme\n    \"mkdocstrings[python]&gt;=0.29.0,&lt;1.0\",  # Python API documentation\n    \"griffe&gt;=0.49.0\",                     # Code parsing\n    \"docstring-parser&gt;=0.16.0,&lt;1.0\",      # Docstring parsing\n    \"mkdocs-gen-files&gt;=0.5.0,&lt;1.0\",       # File generation\n    \"mkdocs-literate-nav&gt;=0.6.0,&lt;1.0\",    # Navigation\n    \"mkdocs-section-index&gt;=0.3.0,&lt;1.0\"    # Section indexing\n]\n</code></pre> <p>Install with: <pre><code>pip install yaml-workflow[doc]\n</code></pre></p>"},{"location":"dependencies/#development-dependencies","title":"Development Dependencies","text":"<p>Required for development work:</p> <pre><code>[project.optional-dependencies]\ndev = [\n    \"black==25.1.0\",           # Code formatting\n    \"isort&gt;=5.0,&lt;6.0\",        # Import sorting\n    \"build&gt;=1.0.0,&lt;2.0.0\",    # Package building\n    \"twine&gt;=4.0.0,&lt;5.0.0\"     # Package publishing\n]\n</code></pre> <p>Install with: <pre><code>pip install yaml-workflow[dev]\n</code></pre></p>"},{"location":"dependencies/#feature-dependencies","title":"Feature Dependencies","text":""},{"location":"dependencies/#basic-features","title":"Basic Features","text":"<p>Core features work with the base installation: - YAML workflow definition - Basic task types (echo, shell, etc.) - Template processing - File operations - CLI interface</p>"},{"location":"dependencies/#advanced-features","title":"Advanced Features","text":"<p>Some advanced features require optional dependencies:</p>"},{"location":"dependencies/#parallel-processing","title":"Parallel Processing","text":"<ul> <li>Uses Python's built-in <code>concurrent.futures</code></li> <li>No additional dependencies required</li> <li>Configure with <code>parallel: true</code> and <code>max_workers</code></li> </ul>"},{"location":"dependencies/#state-management","title":"State Management","text":"<ul> <li>Uses local file system</li> <li>JSON/YAML for state storage</li> <li>No additional dependencies required</li> </ul>"},{"location":"dependencies/#custom-task-types","title":"Custom Task Types","text":"<ul> <li>Python module importing</li> <li>Dynamic code loading</li> <li>Core functionality included</li> </ul>"},{"location":"dependencies/#python-version-compatibility","title":"Python Version Compatibility","text":"<p>YAML Workflow is tested and supported on: - Python 3.10 - Python 3.11 - Python 3.12 - Python 3.13</p>"},{"location":"dependencies/#operating-system-support","title":"Operating System Support","text":"<p>The package is platform-independent and tested on: - Linux - macOS - Windows</p>"},{"location":"dependencies/#installing-multiple-extras","title":"Installing Multiple Extras","text":"<p>You can combine optional dependencies:</p> <pre><code># Install all development-related packages\npip install yaml-workflow[test,dev,doc]\n\n# Install specific combinations\npip install yaml-workflow[test,dev]\n</code></pre>"},{"location":"dependencies/#dependency-management","title":"Dependency Management","text":""},{"location":"dependencies/#version-constraints","title":"Version Constraints","text":"<ul> <li>All dependencies use semantic versioning</li> <li>Upper bounds prevent breaking changes</li> <li>Lower bounds ensure feature availability</li> </ul>"},{"location":"dependencies/#updating-dependencies","title":"Updating Dependencies","text":"<pre><code># Update all dependencies\npip install --upgrade yaml-workflow[all]\n\n# Update specific group\npip install --upgrade yaml-workflow[dev]\n</code></pre>"},{"location":"dependencies/#dependency-conflicts","title":"Dependency Conflicts","text":"<p>If you encounter dependency conflicts: 1. Install minimal required dependencies first 2. Add optional dependencies one by one 3. Use <code>pip freeze</code> to check versions 4. Report conflicts in GitHub issues </p>"},{"location":"development/","title":"Development Guide","text":""},{"location":"development/#setup","title":"Setup","text":"<ol> <li> <p>Install development dependencies: <pre><code>pip install -e \".[dev]\"\n</code></pre></p> </li> <li> <p>Format code: <pre><code># Format Python files\nblack src/ tests/  # Code formatting\nisort --profile black src/ tests/  # Import sorting (using black-compatible settings)\n\n# Run both formatters in one command\nblack src/ tests/ &amp;&amp; isort --profile black src/ tests/\n</code></pre></p> </li> <li> <p>Type checking: <pre><code>mypy src/\n</code></pre></p> </li> </ol>"},{"location":"development/#task-development","title":"Task Development","text":""},{"location":"development/#taskconfig-interface","title":"TaskConfig Interface","text":"<p>All tasks in YAML Workflow use the <code>TaskConfig</code> interface for standardized configuration and error handling:</p> <pre><code>from yaml_workflow.tasks import register_task, TaskConfig\nfrom yaml_workflow.exceptions import TaskExecutionError\n\n@register_task(\"my_task\")\ndef my_task_handler(config: TaskConfig) -&gt; Dict[str, Any]:\n    \"\"\"\n    Task implementation using TaskConfig.\n\n    Args:\n        config: TaskConfig object containing:\n               - name: Task name\n               - type: Task type\n               - inputs: Task inputs\n               - workspace: Workspace path\n               - _context: Variable context\n\n    Returns:\n        Dict containing:\n        - result: Task result\n        - task_name: Name of the task\n        - task_type: Type of task\n        - available_variables: Variables accessible to the task\n    \"\"\"\n    try:\n        # Process inputs with template resolution\n        processed = config.process_inputs()\n\n        # Access variables from different namespaces\n        input_value = config.get_variable('value', namespace='args')\n        env_var = config.get_variable('API_KEY', namespace='env')\n\n        # Access batch context if available\n        batch_ctx = config.get_variable('item', namespace='batch')\n\n        # Perform task logic\n        result = process_data(input_value, env_var)\n\n        return {\n            \"result\": result,\n            \"task_name\": config.name,\n            \"task_type\": config.type,\n            \"available_variables\": config.get_available_variables()\n        }\n    except Exception as e:\n        raise TaskExecutionError(\n            message=f\"Task failed: {str(e)}\",\n            step_name=config.name,\n            original_error=e\n        )\n</code></pre>"},{"location":"development/#error-handling","title":"Error Handling","text":"<p>Tasks should use standardized error handling through <code>TaskExecutionError</code>:</p> <pre><code>from yaml_workflow.exceptions import TaskExecutionError\n\ndef process_with_error_handling(config: TaskConfig) -&gt; Dict[str, Any]:\n    try:\n        # Process task\n        result = process_data()\n        return {\"result\": result}\n    except ValueError as e:\n        raise TaskExecutionError(\n            message=\"Invalid input data\",\n            step_name=config.name,\n            original_error=e\n        )\n    except IOError as e:\n        raise TaskExecutionError(\n            message=\"Failed to read/write data\",\n            step_name=config.name,\n            original_error=e\n        )\n    except Exception as e:\n        raise TaskExecutionError(\n            message=f\"Unexpected error: {str(e)}\",\n            step_name=config.name,\n            original_error=e\n        )\n</code></pre>"},{"location":"development/#template-resolution","title":"Template Resolution","text":"<p>Tasks should use <code>config.process_inputs()</code> for template resolution:</p> <pre><code>@register_task(\"template_task\")\ndef template_task_handler(config: TaskConfig) -&gt; Dict[str, Any]:\n    # Process inputs with template resolution\n    processed = config.process_inputs()\n\n    # Access resolved values\n    template = processed.get(\"template\")\n    variables = processed.get(\"variables\", {})\n\n    try:\n        # Use resolved values\n        result = render_template(template, variables)\n        return {\"result\": result}\n    except Exception as e:\n        raise TaskExecutionError(\n            message=\"Template rendering failed\",\n            step_name=config.name,\n            original_error=e\n        )\n</code></pre>"},{"location":"development/#batch-processing","title":"Batch Processing","text":"<p>Tasks can access batch context when used in batch operations:</p> <pre><code>@register_task(\"batch_aware_task\")\ndef batch_aware_task_handler(config: TaskConfig) -&gt; Dict[str, Any]:\n    # Get batch context if available\n    batch_item = config.get_variable('item', namespace='batch')\n    batch_index = config.get_variable('index', namespace='batch')\n    batch_total = config.get_variable('total', namespace='batch')\n\n    if batch_item is not None:\n        # We're in a batch context\n        print(f\"Processing item {batch_index + 1}/{batch_total}\")\n        result = process_batch_item(batch_item)\n    else:\n        # Regular task execution\n        result = process_single_item()\n\n    return {\"result\": result}\n</code></pre>"},{"location":"development/#testing-tasks","title":"Testing Tasks","text":"<p>Create comprehensive tests for tasks:</p> <pre><code>def test_my_task():\n    # Create test config\n    config = TaskConfig(\n        name=\"test_task\",\n        task_type=\"my_task\",\n        inputs={\n            \"value\": \"test_value\",\n            \"api_key\": \"test_key\"\n        },\n        context={\n            \"args\": {\"value\": \"test_value\"},\n            \"env\": {\"API_KEY\": \"test_key\"},\n            \"steps\": {}\n        },\n        workspace=Path(\"/tmp/test\")\n    )\n\n    # Execute task\n    result = my_task_handler(config)\n\n    # Verify result\n    assert result[\"task_name\"] == \"test_task\"\n    assert result[\"task_type\"] == \"my_task\"\n    assert \"result\" in result\n\n    # Test error handling\n    config.inputs[\"value\"] = None\n    with pytest.raises(TaskExecutionError) as exc_info:\n        my_task_handler(config)\n    assert \"Invalid input\" in str(exc_info.value)\n</code></pre>"},{"location":"development/#building-and-distribution","title":"Building and Distribution","text":"<ol> <li> <p>Ensure you have the latest build tools: <pre><code>python -m pip install --upgrade pip\npython -m pip install --upgrade build twine\n</code></pre></p> </li> <li> <p>Build both source distribution (sdist) and wheel: <pre><code># This will create both sdist and wheel in the dist/ directory\npython -m build\n\n# Or build them separately:\npython -m build --sdist  # Create source distribution\npython -m build --wheel  # Create wheel\n</code></pre></p> </li> <li> <p>Check your distribution files: <pre><code># Validate distribution files\ntwine check dist/*\n</code></pre></p> </li> <li> <p>Upload to TestPyPI first (recommended): <pre><code># Upload to TestPyPI\ntwine upload --repository testpypi dist/*\n\n# Install from TestPyPI to test\npip install --index-url https://test.pypi.org/simple/ yaml-workflow\n</code></pre></p> </li> <li> <p>Upload to PyPI: <pre><code># Upload to PyPI\ntwine upload dist/*\n</code></pre></p> </li> </ol>"},{"location":"development/#running-tests","title":"Running Tests","text":"<pre><code># Install test dependencies\npip install -e \".[test]\"\n\n# Run tests\npytest tests/\n\n# Run tests with coverage\npytest tests/ --cov=yaml_workflow\n</code></pre>"},{"location":"development/#testing-releases","title":"Testing Releases","text":""},{"location":"development/#method-1-local-build-testing","title":"Method 1: Local Build Testing","text":"<ol> <li> <p>Install development dependencies (includes build tools): <pre><code># This will install all development dependencies including build and twine\npip install -e \".[dev]\"\n</code></pre></p> </li> <li> <p>Clean previous builds: <pre><code>rm -rf dist/ build/ *.egg-info\n</code></pre></p> </li> <li> <p>Build the package: <pre><code>python -m build\n</code></pre></p> </li> <li> <p>Check the distribution files: <pre><code>twine check dist/*\n</code></pre></p> </li> <li> <p>Install the built package locally: <pre><code># Create a new virtual environment for testing\npython -m venv test-venv\nsource test-venv/bin/activate  # On Unix/macOS\n# On Windows use: test-venv\\Scripts\\activate\n\n# Install and test the package\npip install dist/*.whl\nyaml-workflow init --example hello_world\nyaml-workflow run workflows/hello_world.yaml name=Test\n</code></pre></p> </li> </ol>"},{"location":"development/#method-2-using-testpypi","title":"Method 2: Using TestPyPI","text":"<ol> <li>Register an account on TestPyPI:</li> <li>Go to https://test.pypi.org/account/register/</li> <li>Create an account</li> <li> <p>Generate an API token</p> </li> <li> <p>Create a <code>.pypirc</code> file in your home directory: <pre><code>[distutils]\nindex-servers =\n    testpypi\n\n[testpypi]\nrepository = https://test.pypi.org/legacy/\nusername = __token__\npassword = your-test-pypi-token\n</code></pre></p> </li> <li> <p>Build and upload to TestPyPI: <pre><code># Clean previous builds\nrm -rf dist/ build/ *.egg-info\n\n# Build the package\npython -m build\n\n# Upload to TestPyPI\ntwine upload --repository testpypi dist/*\n</code></pre></p> </li> <li> <p>Test installation from TestPyPI: <pre><code># Create a new virtual environment for testing\npython -m venv test-venv\nsource test-venv/bin/activate  # On Unix/macOS\n# On Windows use: test-venv\\Scripts\\activate\n\n# Install from TestPyPI\npip install --index-url https://test.pypi.org/simple/ \\\n    --extra-index-url https://pypi.org/simple/ \\\n    yaml-workflow\n\n# Test the package\nyaml-workflow init --example hello_world\nyaml-workflow run workflows/hello_world.yaml name=Test\n</code></pre></p> </li> </ol> <p>Note: The <code>--extra-index-url</code> is needed because TestPyPI doesn't have all the dependencies.</p>"},{"location":"development/#contributing","title":"Contributing","text":"<ol> <li>Fork the repository</li> <li>Create a feature branch</li> <li>Make your changes</li> <li>Run tests and ensure all checks pass</li> <li>Submit a pull request</li> </ol>"},{"location":"development/#package-configuration","title":"Package Configuration","text":"<p>The package uses <code>pyproject.toml</code> for configuration. Here's the minimum required configuration:</p> <pre><code>[build-system]\nrequires = [\"hatchling\"]\nbuild-backend = \"hatchling.build\"\n\n[project]\nname = \"yaml-workflow\"\nversion = \"0.1.0\"\ndescription = \"A powerful and flexible workflow engine that executes tasks defined in YAML configuration files\"\nreadme = \"README.md\"\nauthors = [\n    { name = \"Your Name\", email = \"your.email@example.com\" }\n]\nlicense = { file = \"LICENSE\" }\nclassifiers = [\n    \"Programming Language :: Python :: 3\",\n    \"License :: OSI Approved :: MIT License\",\n    \"Operating System :: OS Independent\",\n]\ndependencies = [\n    \"pyyaml&gt;=6.0\",\n    \"jinja2&gt;=3.0\",\n]\n\n[project.optional-dependencies]\ntest = [\n    \"pytest&gt;=7.0\",\n    \"pytest-cov&gt;=4.0\",\n]\ndev = [\n    \"black&gt;=23.0\",\n    \"isort&gt;=5.0\",\n    \"mypy&gt;=1.0\",\n]\n\n[project.urls]\nHomepage = \"https://github.com/yourusername/yaml-workflow\"\nIssues = \"https://github.com/yourusername/yaml-workflow/issues\"\n\n[project.scripts]\nyaml-workflow = \"yaml_workflow.cli:main\"\n\n[tool.isort]\nprofile = \"black\"\nmulti_line_output = 3\ninclude_trailing_comma = true\nforce_grid_wrap = 0\nuse_parentheses = true\nensure_newline_before_comments = true\nline_length = 88  # Match black's line length\n</code></pre>"},{"location":"development/#creating-custom-tasks","title":"Creating Custom Tasks","text":"<p>The workflow engine allows you to extend its functionality by creating custom tasks written in Python. This guide covers the recommended way to define and register your own tasks.</p>"},{"location":"development/#using-the-register_task-decorator","title":"Using the <code>@register_task</code> Decorator","text":"<p>The simplest and preferred way to create a custom task is by using the <code>@register_task</code> decorator found in <code>yaml_workflow.tasks</code>.</p> <p>Below is a brief example. For the full runnable code, see: *   Python task definitions: <code>docs/examples/custom_tasks/my_tasks.py</code> *   Example workflow YAML: <code>docs/examples/custom_tasks/workflow.yaml</code></p> <pre><code># Example snippet from docs/examples/custom_tasks/my_tasks.py\nfrom yaml_workflow.tasks import register_task, TaskConfig\nimport logging\n\n@register_task() # Register with default name 'multiply_by'\ndef multiply_by(value: int, multiplier: int = 2) -&gt; int:\n    logging.info(f\"Task 'multiply_by': Multiplying {value} by {multiplier}\")\n    return value * multiplier\n\n@register_task(\"custom_greeting\") # Register with custom name\ndef create_special_greeting(name: str) -&gt; str:\n    # ... implementation ...\n    return f\"\u2728 Special Greeting for {name}! \u2728\"\n\n# ... other examples including using TaskConfig ...\n</code></pre> <p>Key Concepts:</p> <ol> <li> <p>Registration:</p> <ul> <li>Import <code>register_task</code> from <code>yaml_workflow.tasks</code>.</li> <li>Decorate your Python function with <code>@register_task()</code>.</li> <li>By default, the task name used in the YAML workflow will be the function name (e.g., <code>multiply_by</code>).</li> <li>You can provide a custom name: <code>@register_task(\"custom_name\")</code>.</li> </ul> </li> <li> <p>Input Handling (Automatic):</p> <ul> <li>The decorator automatically handles mapping inputs defined in your YAML step to the function's parameters.</li> <li>Define parameters in your function signature with type hints (e.g., <code>value: int</code>, <code>multiplier: int = 2</code>).</li> <li>Inputs are automatically processed using the template engine (e.g., <code>value: \"{{ steps.previous.result }}\"</code>).</li> <li>Default values for arguments work as expected.</li> </ul> </li> <li> <p>Accessing <code>TaskConfig</code> (Optional):</p> <ul> <li>If your task needs access to the full context, workspace details, or other metadata, simply include <code>config: TaskConfig</code> as a parameter in your function definition.</li> <li>The decorator will detect this and pass the <code>TaskConfig</code> object to your function. You do not need to provide <code>config</code> in the YAML inputs.</li> <li>You can mix specific arguments and the <code>config</code> parameter.</li> </ul> </li> <li> <p>Return Values:</p> <ul> <li>Tasks can return any Python object (strings, numbers, lists, dictionaries, etc.).</li> <li>The returned value is automatically wrapped and stored in the context under <code>steps.YOUR_STEP_NAME.result</code>.</li> <li>Subsequent steps can access this result using templates like <code>{{ steps.YOUR_STEP_NAME.result }}</code>. If the result is a dictionary, access specific keys like <code>{{ steps.YOUR_STEP_NAME.result.key }}</code>.</li> </ul> </li> <li> <p>Error Handling:</p> <ul> <li>Standard Python exceptions raised within your task will be caught by the engine and will typically cause the workflow to fail (unless <code>on_error</code> is configured for the step).</li> <li>For more controlled error handling specific to the workflow engine (e.g., custom error types recognized by <code>on_error</code> logic), you can import and raise exceptions from <code>yaml_workflow.exceptions</code>.</li> </ul> </li> <li> <p>Discovery:</p> <ul> <li>Ensure the Python module containing your decorated task functions is imported somewhere in your project before the workflow runs, so the decorators execute and register the tasks. A common pattern is to import them in your project's main <code>__init__.py</code> or a dedicated <code>tasks.py</code> module that is imported early.</li> </ul> </li> </ol>"},{"location":"development/#example-yaml-usage","title":"Example YAML Usage","text":"<p>This snippet shows how the custom tasks defined above might be used in a workflow. See <code>docs/examples/custom_tasks/workflow.yaml</code> for the complete runnable example.</p> <pre><code># Example snippet from docs/examples/custom_tasks/workflow.yaml\nsteps:\n  - name: multiply_step\n    task: multiply_by # Uses the function name\n    inputs:\n      value: \"{{ args.initial_value | default(10) }}\"\n      multiplier: 5 # Override default\n\n  - name: show_multiply_result\n    task: echo # Use a built-in task to show the result\n    inputs:\n      message: \"Multiplication Result: {{ steps.multiply_step.result }}\"\n\n  - name: greeting_step\n    task: custom_greeting # Uses the custom registered name\n    inputs:\n      name: \"{{ args.user_name | default('Example User') }}\"\n\n  # ... other steps using process_with_config ...\n</code></pre>"},{"location":"features/","title":"Features","text":"<p>YAML Workflow provides a rich set of features for building and executing workflows. This document outlines the key features and their usage.</p>"},{"location":"features/#core-features","title":"Core Features","text":""},{"location":"features/#yaml-driven-configuration","title":"YAML-Driven Configuration","text":"<p>Define workflows using simple YAML syntax with standardized task configuration:</p> <pre><code>name: data_processing\ndescription: Process and transform data files\nversion: \"1.0.0\"\n\nargs:\n  input_file:\n    type: string\n    description: Input file to process\n    default: input.csv\n\nenv:\n  WORKSPACE: /data/processing\n  API_KEY: \"{{ args.api_key }}\"\n\nsteps:\n  read_data:\n    name: read_data\n    task: read_file\n    inputs:\n      file_path: \"{{ args.input_file }}\"\n      encoding: utf-8\n\n  transform:\n    name: transform\n    task: python\n    inputs:\n      code: |\n        # Access data through namespaces\n        data = steps['read_data']['result']\n        workspace = env['WORKSPACE']\n\n        # Process data\n        result = transform_data(data)\n</code></pre>"},{"location":"features/#namespace-support","title":"Namespace Support","text":"<p>Access variables through isolated namespaces:</p> <ul> <li><code>args</code>: Command-line arguments and workflow parameters</li> <li><code>env</code>: Environment variables</li> <li><code>steps</code>: Results from previous steps</li> <li><code>batch</code>: Batch processing context (in batch tasks)</li> <li><code>current</code>: Information about the current task</li> </ul> <p>Example: <pre><code>steps:\n  process_data:\n    name: process_data\n    task: shell\n    inputs:\n      command: |\n        # Access from different namespaces\n        echo \"Input: {{ args.input_file }}\"\n        echo \"API Key: {{ env.API_KEY }}\"\n        echo \"Previous: {{ steps.previous.result }}\"\n        echo \"Current: {{ steps.current.name }}\"\n</code></pre></p>"},{"location":"features/#error-handling","title":"Error Handling","text":"<p>Standardized error handling through TaskConfig:</p> <pre><code>steps:\n  api_call:\n    name: api_call\n    task: shell\n    inputs:\n      command: \"curl {{ env.API_URL }}\"\n    retry:\n      max_attempts: 3\n      delay: 5\n      backoff: 2\n</code></pre> <p>Error types: - <code>TaskExecutionError</code>: Task execution failures   - Contains step name and original error   - Provides execution context   - Lists available variables - <code>TemplateError</code>: Template resolution failures   - Shows undefined variable details   - Lists available variables by namespace   - Provides template context</p>"},{"location":"features/#task-system","title":"Task System","text":""},{"location":"features/#built-in-tasks","title":"Built-in Tasks","text":"<p>All tasks use the standardized TaskConfig interface:</p> <p>Basic Tasks: - Echo (<code>echo</code>) - Hello World (<code>hello_world</code>) - Add Numbers (<code>add_numbers</code>) - Join Strings (<code>join_strings</code>) - Create Greeting (<code>create_greeting</code>) - Fail (for testing) (<code>fail</code>)</p> <p>File Operations: - Read File (<code>read_file</code>) - Write File (<code>write_file</code>) - Append File (<code>append_file</code>) - Copy File (<code>copy_file</code>) - Move File (<code>move_file</code>) - Delete File (<code>delete_file</code>) - Read JSON (<code>read_json</code>) - Write JSON (<code>write_json</code>) - Read YAML (<code>read_yaml</code>) - Write YAML (<code>write_yaml</code>)</p> <p>Other Tasks: - Shell Command Execution (<code>shell</code>) - Python Function Execution (<code>python</code>) - Template Rendering (<code>template</code>) - Batch Processing (<code>batch</code>)</p>"},{"location":"features/#custom-task-creation","title":"Custom Task Creation","text":"<p>Create tasks using the TaskConfig interface:</p> <pre><code>from yaml_workflow.tasks import register_task, TaskConfig\nfrom yaml_workflow.exceptions import TaskExecutionError\n\n@register_task(\"custom_task\")\ndef custom_task_handler(config: TaskConfig) -&gt; Dict[str, Any]:\n    \"\"\"\n    Custom task implementation using TaskConfig.\n\n    Args:\n        config: TaskConfig object containing:\n               - name: Task name\n               - type: Task type\n               - inputs: Task inputs\n               - workspace: Workspace path\n               - _context: Variable context\n\n    Returns:\n        Dict containing:\n        - result: Task result\n        - task_name: Name of the task\n        - task_type: Type of task\n        - available_variables: Variables accessible to the task\n    \"\"\"\n    try:\n        # Process inputs with template resolution\n        processed = config.process_inputs()\n\n        # Access variables from different namespaces\n        input_value = config.get_variable('value', namespace='args')\n        env_var = config.get_variable('API_KEY', namespace='env')\n\n        # Process data\n        result = process_data(input_value, env_var)\n\n        return {\n            \"result\": result,\n            \"task_name\": config.name,\n            \"task_type\": config.type,\n            \"available_variables\": config.get_available_variables()\n        }\n    except Exception as e:\n        raise TaskExecutionError(\n            message=f\"Custom task failed: {str(e)}\",\n            step_name=config.name,\n            original_error=e\n        )\n</code></pre>"},{"location":"features/#batch-processing","title":"Batch Processing","text":"<p>Process items in parallel with proper error handling and state tracking:</p> <pre><code>steps:\n  process_files:\n    name: process_files\n    task: batch\n    inputs:\n      items: \"{{ args.files }}\"\n      chunk_size: 10          # Process 10 items at a time\n      max_workers: 4          # Use 4 parallel workers\n      retry:\n        max_attempts: 3       # Retry failed items up to 3 times\n        delay: 5              # Wait 5 seconds between retries\n      task:\n        task: shell\n        inputs:\n          command: |\n            echo \"Processing {{ batch.item }}\"\n            echo \"Progress: {{ batch.index + 1 }}/{{ batch.total }}\"\n            echo \"Task: {{ batch.name }}\"\n            ./process.sh \"{{ batch.item }}\"\n          working_dir: \"{{ env.WORKSPACE }}\"\n          timeout: 300        # Timeout after 5 minutes\n\n  check_results:\n    name: check_results\n    task: python\n    inputs:\n      code: |\n        results = steps['process_files']['results']\n\n        # Analyze results\n        completed = [r for r in results if 'result' in r]\n        failed = [r for r in results if 'error' in r]\n\n        result = {\n            'total': len(results),\n            'completed': len(completed),\n            'failed': len(failed),\n            'success_rate': len(completed) / len(results) * 100,\n            'failed_items': [r['item'] for r in failed]\n        }\n</code></pre>"},{"location":"features/#batch-features","title":"Batch Features","text":"<ol> <li>Chunk Processing</li> <li>Configurable chunk sizes</li> <li>Memory optimization</li> <li> <p>Progress tracking</p> </li> <li> <p>Parallel Execution</p> </li> <li>Dynamic worker pools</li> <li>Resource management</li> <li> <p>Timeout handling</p> </li> <li> <p>Error Handling</p> </li> <li>Per-item retry</li> <li>Batch-level retry</li> <li> <p>Detailed error reporting</p> </li> <li> <p>State Tracking</p> </li> <li>Progress monitoring</li> <li>Result aggregation</li> <li>Failure analysis</li> </ol>"},{"location":"features/#template-system","title":"Template System","text":""},{"location":"features/#variable-resolution","title":"Variable Resolution","text":"<p>Access variables through namespaces:</p> <pre><code>steps:\n  create_file:\n    name: create_file\n    task: write_file\n    inputs:\n      content: |\n        User: {{ args.user }}\n        Environment: {{ env.ENV_NAME }}\n        Previous Result: {{ steps.previous.result }}\n        Current Task: {{ steps.current.name }}\n      file_path: \"{{ env.OUTPUT_DIR }}/report.txt\"\n</code></pre>"},{"location":"features/#built-in-functions","title":"Built-in Functions","text":"<p>Template functions with namespace awareness: - Date/time manipulation: <code>now()</code>, <code>format_date()</code> - String operations: <code>trim()</code>, <code>upper()</code>, <code>lower()</code> - Math functions: <code>sum()</code>, <code>min()</code>, <code>max()</code> - Path handling: <code>join_paths()</code>, <code>basename()</code></p>"},{"location":"features/#custom-functions","title":"Custom Functions","text":"<p>Register template functions with namespace support:</p> <pre><code>from yaml_workflow.template import register_function\n\n@register_function\ndef format_with_context(value: str, context: Dict[str, Any]) -&gt; str:\n    \"\"\"Format string with context awareness.\"\"\"\n    return value.format(**context)\n</code></pre>"},{"location":"features/#state-management","title":"State Management","text":""},{"location":"features/#task-results","title":"Task Results","text":"<p>All tasks maintain consistent result format: - <code>result</code>: Task output - <code>task_name</code>: Name of the task - <code>task_type</code>: Type of task - <code>available_variables</code>: Variables accessible to the task</p> <p>Access results through the steps namespace: <pre><code>steps:\n  first_step:\n    name: first_step\n    task: shell\n    inputs:\n      command: \"echo 'Hello'\"\n\n  second_step:\n    name: second_step\n    task: shell\n    inputs:\n      command: |\n        # Access previous results\n        echo \"Output: {{ steps.first_step.stdout }}\"\n        echo \"Exit Code: {{ steps.first_step.exit_code }}\"\n\n        # Access current task\n        echo \"Task: {{ steps.current.name }}\"\n        echo \"Type: {{ steps.current.type }}\"\n</code></pre></p>"},{"location":"features/#error-recovery","title":"Error Recovery","text":"<p>Standardized error handling and recovery: - Automatic retries with configurable backoff - Detailed error context for debugging - State preservation during failures - Resume capability from last successful point</p>"},{"location":"features/#best-practices","title":"Best Practices","text":"<ol> <li>Task Design</li> <li>Use TaskConfig interface</li> <li>Implement proper error handling</li> <li>Maintain namespace isolation</li> <li> <p>Return standardized results</p> </li> <li> <p>Error Handling</p> </li> <li>Use TaskExecutionError for task failures</li> <li>Include context in error messages</li> <li>Implement retry mechanisms</li> <li> <p>Clean up resources on failure</p> </li> <li> <p>Batch Processing</p> </li> <li>Choose appropriate chunk sizes</li> <li>Monitor resource usage</li> <li>Handle errors gracefully</li> <li> <p>Track progress effectively</p> </li> <li> <p>Template Usage</p> </li> <li>Use proper namespace access</li> <li>Validate variable existence</li> <li>Handle undefined variables</li> <li>Document available variables</li> </ol> <p>For more detailed information: - Task Types - Templating Guide - Batch Processing Guide - Error Handling Guide </p>"},{"location":"state/","title":"State Management","text":"<p>YAML Workflow provides robust state management capabilities to track workflow execution, handle failures, and enable resumable workflows.</p>"},{"location":"state/#state-storage","title":"State Storage","text":""},{"location":"state/#state-file-structure","title":"State File Structure","text":"<p>The workflow state is stored in <code>.workflow_state.json</code> (or similar, often within <code>.workflow_metadata.json</code>) in the workspace directory. The exact structure evolves, but conceptually includes:</p> <pre><code>{\n    \"workflow_id\": \"unique-workflow-id\",\n    \"name\": \"workflow-name\",\n    \"start_time\": \"2025-04-14T10:00:00Z\",\n    \"last_updated\": \"2025-04-14T10:05:00Z\",\n    \"status\": \"running\", // Overall workflow status\n    // Information about the execution progress and failures:\n    \"execution_state\": {\n        \"status\": \"running\", // Current execution status (running, failed, completed)\n        \"current_step\": \"step2\",\n        \"failed_step\": null, // Populated on failure\n        \"step_outputs\": {   // Stores results of successfully completed steps\n            \"step1\": {       // Key is the step name\n                \"result\": \"Output from Step 1\" // The actual return value of the task is here\n            }\n            // step2 output would appear here upon completion\n        },\n        \"retry_state\": { // Information about retries\n            \"step_1_retry\": {\n                \"attempt\": 1,\n                \"max_attempts\": 3\n            }\n        }\n        // Other execution details like error messages might be stored here too\n    },\n    \"variables\": { // Snapshot of context variables (args, env etc. might be here)\n        \"user_input\": \"value\",\n        \"computed_value\": 42\n    }\n}\n</code></pre>"},{"location":"state/#state-lifecycle","title":"State Lifecycle","text":"<ol> <li>Initialization</li> <li>Created when workflow starts</li> <li>Records start time and initial parameters</li> <li> <p>Initializes empty step tracking</p> </li> <li> <p>Step Execution</p> </li> <li>Updates current step</li> <li>Records step outputs</li> <li> <p>Tracks execution time</p> </li> <li> <p>Completion/Failure</p> </li> <li>Records final status</li> <li>Preserves outputs for resume</li> <li>Logs error information if failed</li> </ol>"},{"location":"state/#resume-capability","title":"Resume Capability","text":""},{"location":"state/#resuming-failed-workflows","title":"Resuming Failed Workflows","text":"<pre><code># Resume from last successful step\nyaml-workflow run --resume workflow.yaml\n\n# Resume from specific step\nyaml-workflow run --resume --from-step step2 workflow.yaml\n\n# Resume with modified parameters\nyaml-workflow run --resume --override-params workflow.yaml\n</code></pre>"},{"location":"state/#resume-behavior","title":"Resume Behavior","text":"<ol> <li>State Loading</li> <li>Reads previous state file</li> <li>Validates step consistency</li> <li> <p>Merges new parameters</p> </li> <li> <p>Execution Strategy</p> </li> <li>Skips completed steps</li> <li>Restarts from failure point</li> <li> <p>Preserves previous outputs</p> </li> <li> <p>State Updates</p> </li> <li>Maintains execution history</li> <li>Updates modified steps</li> <li>Tracks resume attempts</li> </ol>"},{"location":"state/#progress-tracking","title":"Progress Tracking","text":""},{"location":"state/#step-progress","title":"Step Progress","text":"<pre><code>steps:\n  - name: long_running_step\n    task: batch\n    params:\n      progress_update: true  # Enable progress tracking\n      progress_interval: 5   # Update every 5 seconds\n</code></pre>"},{"location":"state/#progress-information","title":"Progress Information","text":"<ul> <li>Step completion percentage</li> <li>Estimated time remaining</li> <li>Resource usage</li> <li>Error counts</li> <li>Retry attempts</li> </ul>"},{"location":"state/#error-handling","title":"Error Handling","text":""},{"location":"state/#retry-mechanism","title":"Retry Mechanism","text":"<pre><code>steps:\n  - name: api_call\n    task: http_request\n    retry:\n      max_attempts: 3\n      delay: 5\n      backoff: 2\n      on_error:\n        - ConnectionError\n        - TimeoutError\n</code></pre>"},{"location":"state/#error-recovery","title":"Error Recovery","text":"<ol> <li>Automatic Recovery</li> <li>Configurable retry policies</li> <li>Exponential backoff</li> <li> <p>Error-specific handling</p> </li> <li> <p>Manual Intervention</p> </li> <li>State inspection tools</li> <li>Manual retry capability</li> <li>Step skip options</li> </ol>"},{"location":"state/#state-management-api","title":"State Management API","text":""},{"location":"state/#reading-state","title":"Reading State","text":"<pre><code>from yaml_workflow.state import WorkflowState\n\n# Load current state\nstate = WorkflowState.load(\"workflow_id\")\n\n# Access state information\ncurrent_step = state.current_step\noutputs = state.step_outputs\nvariables = state.variables\n</code></pre>"},{"location":"state/#modifying-state","title":"Modifying State","text":"<pre><code># Update state\nstate.update_step(\"step1\", status=\"completed\", output=\"result\")\nstate.set_variable(\"key\", \"value\")\nstate.mark_completed()\n\n# Save changes\nstate.save()\n</code></pre>"},{"location":"state/#state-cleanup","title":"State Cleanup","text":""},{"location":"state/#automatic-cleanup","title":"Automatic Cleanup","text":"<ul> <li>Successful workflows: Optional state retention</li> <li>Failed workflows: State preserved for resume</li> <li>Configurable retention policy</li> </ul>"},{"location":"state/#manual-cleanup","title":"Manual Cleanup","text":"<pre><code># Clean old state files\nyaml-workflow clean --older-than 30d\n\n# Remove specific workflow state\nyaml-workflow clean --workflow-id workflow-123\n\n# Clean all successful states\nyaml-workflow clean --status completed\n</code></pre>"},{"location":"state/#best-practices","title":"Best Practices","text":"<ol> <li>State File Management</li> <li>Use version control ignore rules</li> <li>Implement backup strategies</li> <li> <p>Clean up old state files</p> </li> <li> <p>Resume Strategy</p> </li> <li>Design idempotent steps</li> <li>Handle partial completions</li> <li> <p>Validate state consistency</p> </li> <li> <p>Error Handling</p> </li> <li>Define retry policies</li> <li>Log sufficient context</li> <li> <p>Plan for recovery</p> </li> <li> <p>Progress Monitoring</p> </li> <li>Enable appropriate tracking</li> <li>Set reasonable intervals</li> <li>Monitor resource usage </li> </ol>"},{"location":"tasks/","title":"Task Types","text":"<p>YAML Workflow supports several built-in task types for different use cases. Each task type has specific inputs and capabilities.</p>"},{"location":"tasks/#task-configuration","title":"Task Configuration","text":"<p>All tasks use a standardized configuration format and share common features:</p> <pre><code>name: task_name        # Name of the task (required)\ntask: task_type       # Type of task to execute (required)\ninputs:               # Task-specific inputs (required)\n  input1: value1\n  input2: value2\nretry:                # Optional retry configuration\n  max_attempts: 3     # Number of retry attempts\n  delay: 5           # Delay between retries in seconds\n</code></pre>"},{"location":"tasks/#namespace-support","title":"Namespace Support","text":"<p>Tasks have access to variables in different namespaces through the TaskConfig interface:</p> <ul> <li><code>args</code>: Command-line arguments and workflow parameters</li> <li><code>env</code>: Environment variables</li> <li><code>steps</code>: Results from previous steps</li> <li><code>batch</code>: Batch processing context (in batch tasks)</li> <li><code>current</code>: Information about the current task</li> </ul> <p>Example using namespaces: <pre><code>name: example_step\ntask: shell\ninputs:\n  command: |\n    echo \"Arguments: {{ args.input }}\"\n    echo \"Environment: {{ env.PATH }}\"\n    echo \"Previous step: {{ steps.prev_step.result }}\"\n    echo \"Current task: {{ steps.current.name }}\"\n  working_dir: \"{{ env.WORKSPACE }}\"\n</code></pre></p>"},{"location":"tasks/#error-handling","title":"Error Handling","text":"<p>Tasks use standardized error handling through TaskConfig:</p> <ul> <li><code>TaskExecutionError</code>: Raised for task execution failures</li> <li>Contains step name and original error</li> <li>Provides execution context</li> <li>Includes available variables</li> <li><code>TemplateError</code>: Raised for template resolution failures</li> <li>Shows undefined variable details</li> <li>Lists available variables by namespace</li> <li>Provides template context</li> </ul> <p>Example error messages: <pre><code>TaskExecutionError in step 'read_file': Failed to read file '/path/to/missing.txt'\n  Step: read_file\n  Original error: [Errno 2] No such file or directory\n  Available variables:\n    args: input_file, encoding\n    env: WORKSPACE, PATH\n    steps: previous_step\n\nTemplateError in step 'process_data': Failed to resolve template\n  Template: {{ undefined_var }}\n  Error: Variable 'undefined_var' is undefined\n  Available variables:\n    args: input, output\n    env: API_KEY\n    steps: previous_step.result\n</code></pre></p>"},{"location":"tasks/#basic-tasks","title":"Basic Tasks","text":"<p>These are simple utility tasks for common operations:</p> <pre><code># Echo a message\n- name: echo_step\n  task: echo\n  inputs:\n    message: \"Hello, {{ args.name }}!\"\n\n# Add two numbers\n- name: add_numbers_step\n  task: add_numbers\n  inputs:\n    a: \"{{ args.first }}\"\n    b: \"{{ args.second }}\"\n\n# Join strings\n- name: join_strings_step\n  task: join_strings\n  inputs:\n    strings: [\"{{ args.greeting }}\", \"{{ args.name }}\"]\n    separator: \", \"\n\n# Create a greeting using a template\n- name: greeting_step\n  task: create_greeting\n  inputs:\n    template: \"Welcome, {{ args.name }}!\"\n    name: \"{{ args.user }}\"\n\n# Deliberately fail a task (useful for testing)\n- name: fail_step\n  task: fail\n  inputs:\n    message: \"Custom failure message\"\n</code></pre>"},{"location":"tasks/#file-tasks","title":"File Tasks","text":"<p>Tasks for file operations with support for various formats:</p> <pre><code># Write a file\n- name: write_file_step\n  task: write_file\n  inputs:\n    file_path: \"{{ args.output_dir }}/output.txt\"\n    content: \"{{ steps.previous.result.content }}\"\n    encoding: \"utf-8\"  # Optional, defaults to utf-8\n\n# Write JSON file\n- name: write_json_step\n  task: write_json\n  inputs:\n    file_path: \"data.json\"\n    data: \n      key: \"{{ args.value }}\"\n      timestamp: \"{{ env.TIMESTAMP }}\"\n    indent: 2  # Optional, defaults to 2\n\n# Write YAML file\n- name: write_yaml_step\n  task: write_yaml\n  inputs:\n    file_path: \"config.yaml\"\n    data: \n      settings: \"{{ steps.load_settings.result }}\"\n\n# Read a file\n- name: read_file_step\n  task: read_file\n  inputs:\n    file_path: \"{{ args.input_file }}\"\n    encoding: \"utf-8\"  # Optional, defaults to utf-8\n\n# Read JSON file\n- name: read_json_step\n  task: read_json\n  inputs:\n    file_path: \"{{ env.CONFIG_PATH }}\"\n\n# Read YAML file\n- name: read_yaml_step\n  task: read_yaml\n  inputs:\n    file_path: \"{{ args.config_file }}\"\n\n# Append to a file\n- name: append_file_step\n  task: append_file\n  inputs:\n    file_path: \"{{ env.LOG_FILE }}\"\n    content: \"{{ steps.process.result }}\"\n    encoding: \"utf-8\"  # Optional, defaults to utf-8\n\n# Copy a file\n- name: copy_file_step\n  task: copy_file\n  inputs:\n    source: \"{{ steps.download.result.output_file }}\"\n    destination: \"{{ env.BACKUP_DIR }}/{{ args.filename }}\"\n\n# Move a file\n- name: move_file_step\n  task: move_file\n  inputs:\n    source: \"{{ steps.process.result.temp_file }}\"\n    destination: \"{{ args.output_dir }}/final.txt\"\n\n# Delete a file\n- name: delete_file_step\n  task: delete_file\n  inputs:\n    file_path: \"{{ steps.process.result.temp_file }}\"\n</code></pre>"},{"location":"tasks/#template-tasks","title":"Template Tasks","text":"<p>Tasks for rendering templates using Jinja2. For detailed information about templating capabilities, syntax, and best practices, see the Templating Guide.</p> <pre><code>- name: render_template_step\n  task: template\n  inputs:\n    template: |\n      Hello, {{ args.name }}!\n      Environment: {{ env.ENVIRONMENT }}\n      Previous Result: {{ steps.process.result }}\n    output: \"{{ args.output_file }}\"\n</code></pre>"},{"location":"tasks/#shell-tasks","title":"Shell Tasks","text":"<p>Tasks for executing shell commands with full namespace support:</p> <pre><code>- name: shell_step\n  task: shell\n  inputs:\n    command: |\n      echo \"Processing {{ batch.item }}\"\n      export DEBUG=\"{{ env.DEBUG }}\"\n      ./process.sh \"{{ args.input_file }}\"\n    working_dir: \"{{ env.WORKSPACE }}/{{ args.project }}\"  # Optional\n    env:  # Optional environment variables\n      API_KEY: \"{{ env.API_KEY }}\"\n      DEBUG: \"{{ args.verbose }}\"\n    timeout: 300  # Optional timeout in seconds\n</code></pre>"},{"location":"tasks/#python-tasks","title":"Python Tasks","text":"<p>Tasks for executing Python code with full namespace access:</p> <pre><code>name: python_step\ntask: python\ninputs:\n  code: |\n    # Access variables through namespaces\n    input_data = args['data']\n    api_key = env['API_KEY']\n    prev_result = steps['previous']['result']\n\n    # In batch tasks, access batch context\n    if 'batch' in locals():\n        item = batch['item']\n        index = batch['index']\n        total = batch['total']\n\n    # Process data\n    result = process_data(input_data, api_key)\n\n    # Return value becomes available in steps namespace\n    result = {\n        'processed': result,\n        'timestamp': datetime.now().isoformat()\n    }\n</code></pre>"},{"location":"tasks/#batch-tasks","title":"Batch Tasks","text":"<p>Tasks for processing items in batches with proper error handling and state tracking:</p> <pre><code>name: batch_step\ntask: batch\ninputs:\n  items: \"{{ args.items }}\"  # List of items to process\n  chunk_size: 10            # Optional, process 10 items at a time\n  max_workers: 4            # Optional, number of parallel workers\n  retry:                    # Optional retry configuration\n    max_attempts: 3         # Retry failed items up to 3 times\n    delay: 5               # Wait 5 seconds between retries\n  task:                    # Task configuration for processing each item\n    task: shell\n    inputs:\n      command: |\n        echo \"Processing {{ batch.item }}\"\n        echo \"Progress: {{ batch.index + 1 }}/{{ batch.total }}\"\n        echo \"Task: {{ batch.name }}\"\n        ./process.sh \"{{ batch.item }}\"\n      working_dir: \"{{ env.WORKSPACE }}\"\n      timeout: 300        # Optional timeout in seconds\n\n# Access batch results\nname: check_results\ntask: python\ninputs:\n  code: |\n    batch_results = steps['batch_step']['results']\n\n    # Analyze results\n    completed = [r for r in batch_results if 'result' in r]\n    failed = [r for r in batch_results if 'error' in r]\n\n    result = {\n        'total': len(batch_results),\n        'completed': len(completed),\n        'failed': len(failed),\n        'success_rate': len(completed) / len(batch_results) * 100\n    }\n</code></pre>"},{"location":"tasks/#custom-tasks","title":"Custom Tasks","text":"<p>Create custom tasks using the TaskConfig interface:</p> <pre><code>from yaml_workflow.tasks import register_task, TaskConfig\nfrom yaml_workflow.exceptions import TaskExecutionError\n\n@register_task(\"my_custom_task\")\ndef my_custom_task_handler(config: TaskConfig) -&gt; Dict[str, Any]:\n    \"\"\"\n    Custom task implementation using TaskConfig.\n\n    Args:\n        config: TaskConfig object containing:\n               - name: Task name\n               - type: Task type\n               - inputs: Task inputs\n               - workspace: Workspace path\n               - _context: Variable context\n\n    Returns:\n        Dict containing:\n        - result: Task result\n        - task_name: Name of the task\n        - task_type: Type of task\n        - available_variables: Variables accessible to the task\n\n    Raises:\n        TaskExecutionError: If task execution fails\n    \"\"\"\n    try:\n        # Process inputs with template resolution\n        processed = config.process_inputs()\n\n        # Access variables from different namespaces\n        input_value = config.get_variable('value', namespace='args')\n        env_var = config.get_variable('API_KEY', namespace='env')\n\n        # Access batch context if available\n        batch_ctx = config.get_variable('item', namespace='batch')\n\n        # Perform task logic\n        result = process_data(input_value, env_var)\n\n        return {\n            \"result\": result,\n            \"task_name\": config.name,\n            \"task_type\": config.type,\n            \"available_variables\": config.get_available_variables()\n        }\n    except Exception as e:\n        raise TaskExecutionError(\n            message=f\"Custom task failed: {str(e)}\",\n            step_name=config.name,\n            original_error=e\n        )\n</code></pre> <p>Use custom tasks in workflows: <pre><code>name: custom_step\ntask: my_custom_task\ninputs:\n  value: \"{{ args.input }}\"\n  api_key: \"{{ env.API_KEY }}\"\n</code></pre></p>"},{"location":"tasks/#task-results-and-state","title":"Task Results and State","text":"<p>All tasks maintain consistent result format and state tracking through TaskConfig:</p> <pre><code># First task execution\nname: first_step\ntask: shell\ninputs:\n  command: \"echo 'Hello'\"\n\n# Access results through steps namespace\nname: second_step\ntask: shell\ninputs:\n  command: |\n    # Access previous task results\n    echo \"Previous output: {{ steps.first_step.stdout }}\"\n    echo \"Previous exit code: {{ steps.first_step.exit_code }}\"\n\n    # Access current task info\n    echo \"Current task: {{ steps.current.name }}\"\n    echo \"Task type: {{ steps.current.type }}\"\n    echo \"Available variables: {{ steps.current.available_variables | join(', ') }}\"\n</code></pre> <p>For more detailed information about specific features: - Templating Guide - Template syntax and features - Batch Processing Guide - Detailed batch processing - Error Handling - Error handling patterns </p>"},{"location":"testing/","title":"Test Suite Organization","text":""},{"location":"testing/#overview","title":"Overview","text":"<p>The test suite for yaml-workflow is organized into multiple layers, each focusing on different aspects of the system. This organization helps maintain clear boundaries between components and makes it easier to understand and maintain the test suite.</p>"},{"location":"testing/#test-structure","title":"Test Structure","text":""},{"location":"testing/#core-layer-template-engine-tests","title":"Core Layer: Template Engine Tests","text":"<p>File: <code>tests/test_template.py</code></p> <p>Tests the fundamental template engine implementation (<code>TemplateEngine</code> class), focusing on: - Template compilation and caching mechanisms - Variable resolution and type information handling - Error handling and reporting - Cache management - Basic template processing operations</p> <p>Example: <pre><code>def test_process_template(template_engine, variables):\n    \"\"\"Test processing a template.\"\"\"\n    template = \"Input: {{ args.input_file }}, Output: {{ args.output_file }}\"\n    result = template_engine.process_template(template, variables)\n    assert result == \"Input: input.txt, Output: output.txt\"\n</code></pre></p>"},{"location":"testing/#integration-layer-workflow-engine-template-tests","title":"Integration Layer: Workflow Engine Template Tests","text":"<p>File: <code>tests/test_engine_template.py</code></p> <p>Tests the integration between the workflow engine and template system, covering: - Template resolution within workflow context - Step input resolution - Error message templating - Workflow-specific template operations</p> <p>Example: <pre><code>def test_resolve_template_simple(engine):\n    \"\"\"Test simple template resolution.\"\"\"\n    result = engine.resolve_template(\"File: {{ args.input_file }}\")\n    assert result == \"File: test.txt\"\n</code></pre></p>"},{"location":"testing/#task-layer-template-tasks-tests","title":"Task Layer: Template Tasks Tests","text":"<p>File: <code>tests/test_template_tasks.py</code></p> <p>Tests the high-level template task handlers that users interact with directly: - Template rendering to files - Complex template features (loops, conditionals) - Template filters and modifiers - File-based templates - Whitespace control - Template includes (planned feature)</p> <p>Example: <pre><code>def test_template_with_loops(temp_workspace, template_context):\n    \"\"\"Test template rendering with loops.\"\"\"\n    step = {\n        \"template\": \"\"\"Items:\n{% for item in items %}\n- {{ item }}\n{% endfor %}\"\"\",\n        \"output\": \"items.txt\",\n    }\n    result = render_template(step, template_context, temp_workspace)\n</code></pre></p>"},{"location":"testing/#test-categories","title":"Test Categories","text":"<p>Our tests are organized into several categories:</p> <ol> <li>Unit Tests</li> <li>Test individual components in isolation</li> <li>Focus on specific functionality</li> <li>Fast execution</li> <li> <p>High coverage</p> </li> <li> <p>Integration Tests</p> </li> <li>Test component interactions</li> <li>Verify system behavior</li> <li> <p>End-to-end workflow testing</p> </li> <li> <p>Error Handling Tests</p> </li> <li>Verify error conditions</li> <li>Test error messages</li> <li> <p>Validate error recovery</p> </li> <li> <p>Performance Tests</p> </li> <li>Test caching mechanisms</li> <li>Verify resource usage</li> <li>Check execution time</li> </ol>"},{"location":"testing/#running-tests","title":"Running Tests","text":""},{"location":"testing/#basic-test-execution","title":"Basic Test Execution","text":"<pre><code># Run all tests\npytest tests/\n\n# Run specific test file\npytest tests/test_template.py\n\n# Run with coverage\npytest tests/ --cov=yaml_workflow\n</code></pre>"},{"location":"testing/#test-options","title":"Test Options","text":"<ul> <li><code>-v</code>: Verbose output</li> <li><code>-k \"test_name\"</code>: Run tests matching pattern</li> <li><code>--pdb</code>: Debug on test failure</li> <li><code>--cov-report html</code>: Generate HTML coverage report</li> </ul>"},{"location":"testing/#writing-new-tests","title":"Writing New Tests","text":"<p>When adding new tests:</p> <ol> <li>Choose the Right Layer</li> <li>Core layer for fundamental operations</li> <li>Integration layer for component interactions</li> <li> <p>Task layer for user-facing features</p> </li> <li> <p>Follow Naming Conventions</p> </li> <li>Use descriptive test names</li> <li>Group related tests together</li> <li> <p>Include both positive and negative test cases</p> </li> <li> <p>Use Fixtures</p> </li> <li>Create reusable test data</li> <li>Share common setup code</li> <li> <p>Keep tests focused and clean</p> </li> <li> <p>Document Test Purpose</p> </li> <li>Add clear docstrings</li> <li>Explain test scenarios</li> <li>Document expected behavior</li> </ol>"},{"location":"testing/#test-dependencies","title":"Test Dependencies","text":"<p>The test suite requires additional dependencies, which can be installed using: <pre><code>pip install -e \".[test]\"\n</code></pre></p> <p>Key test dependencies include: - <code>pytest</code>: Testing framework - <code>pytest-cov</code>: Coverage reporting - <code>pytest-mock</code>: Mocking support</p>"},{"location":"testing/#future-improvements","title":"Future Improvements","text":"<p>Planned enhancements to the test suite:</p> <ol> <li>Template Features</li> <li>Add support for template includes</li> <li>Enhance error reporting</li> <li> <p>Add more complex template scenarios</p> </li> <li> <p>Performance Testing</p> </li> <li>Add benchmarks</li> <li>Test large template processing</li> <li> <p>Measure memory usage</p> </li> <li> <p>Integration Testing</p> </li> <li>Add more end-to-end tests</li> <li>Test external integrations</li> <li>Add stress testing </li> </ol>"},{"location":"workflow-structure/","title":"Workflow Structure","text":""},{"location":"workflow-structure/#component-overview","title":"Component Overview","text":"<pre><code>graph TD\n    A[Workflow] --&gt; B[Settings]\n    A --&gt; C[Environment]\n    A --&gt; D[Parameters]\n    A --&gt; E[Flows]\n    A --&gt; F[Steps]\n    E --&gt; G[Flow Definitions]\n    F --&gt; H[Task Configuration]\n    F --&gt; I[Error Handling]\n    F --&gt; J[State Management]\n    H --&gt; K[Inputs/Outputs]\n    H --&gt; L[Retry Logic]\n    I --&gt; M[Error Actions]\n    J --&gt; N[Progress Tracking]\n    J --&gt; O[Batch Processing]</code></pre>"},{"location":"workflow-structure/#basic-structure","title":"Basic Structure","text":"<pre><code>name: My Workflow\ndescription: Workflow description\nversion: \"1.0\"  # Optional\n\n# Optional global settings\nsettings:\n  error_handling:\n    undefined_variables: strict\n    show_available: true\n  batch_processing:\n    chunk_size: 10\n    max_workers: 4\n\n# Optional parameter definitions\nparams:\n  input_file:\n    description: Input file path\n    type: string\n    required: true\n  batch_size:\n    description: Number of items to process at once\n    type: integer\n    default: 10\n\n# Optional flow definitions\nflows:\n  default: process  # Optional, defaults to \"all\" if not specified\n  definitions:\n    - process: [validate, transform, save]  # Main processing flow\n    - data_collection: [collect, process]   # Data collection flow\n    - validation: [validate]                # Validation flow\n\n# Workflow steps\nsteps:\n  - name: validate\n    task: file_check\n    description: Validate input file\n    params:\n      path: \"{{ args.input_file }}\"\n      type: \"csv\"\n\n  - name: transform\n    task: python\n    description: Transform data\n    params:\n      input: \"{{ args.input_file }}\"\n      batch_size: \"{{ args.batch_size }}\"\n    error_handling:\n      undefined_variables: strict\n\n## Workflow Lifecycle\n\n```mermaid\nstateDiagram-v2\n    [*] --&gt; Initialize: Load Workflow\n    Initialize --&gt; Validate: Parse YAML\n    Validate --&gt; PrepareEnv: Validation OK\n    Validate --&gt; [*]: Invalid Config\n    PrepareEnv --&gt; ExecuteSteps: Environment Ready\n    ExecuteSteps --&gt; StepExecution: For Each Step\n    StepExecution --&gt; ErrorHandling: Step Failed\n    StepExecution --&gt; StepExecution: Next Step\n    ErrorHandling --&gt; RetryStep: Can Retry\n    ErrorHandling --&gt; StepExecution: Skip Step\n    ErrorHandling --&gt; [*]: Fail Workflow\n    RetryStep --&gt; StepExecution: Retry\n    StepExecution --&gt; [*]: All Steps Complete\n</code></pre>"},{"location":"workflow-structure/#variable-access","title":"Variable Access","text":"<p>The workflow engine uses a namespaced approach for variable access:</p> <pre><code>steps:\n  - name: process\n    task: python\n    params:\n      # Access workflow parameters\n      input_file: \"{{ args.input_file }}\"\n      batch_size: \"{{ args.batch_size }}\"\n\n      # Access environment variables\n      api_url: \"{{ env.API_URL }}\"\n      debug: \"{{ env.DEBUG }}\"\n\n      # Access step outputs\n      data: \"{{ steps.transform.result }}\"\n      metadata: \"{{ steps.transform.result.metadata }}\"\n\n      # Access workflow information\n      workspace: \"{{ workflow.workspace }}\"\n      run_id: \"{{ workflow.run_id }}\"\n</code></pre>"},{"location":"workflow-structure/#flow-control","title":"Flow Control","text":"<p>The workflow engine supports defining multiple flows within a single workflow. Each flow represents a specific sequence of steps to execute. This allows you to:</p> <ul> <li>Define different execution paths for different purposes</li> <li>Reuse steps across different flows</li> <li>Switch between flows via command line</li> <li>Resume failed flows from the last failed step</li> </ul>"},{"location":"workflow-structure/#flow-configuration-example","title":"Flow Configuration Example","text":"<pre><code>graph LR\n    subgraph \"Process Flow\"\n    A[validate] --&gt; B[transform]\n    B --&gt; C[save]\n    end\n\n    subgraph \"Data Collection Flow\"\n    D[collect] --&gt; E[process]\n    end\n\n    subgraph \"Validation Flow\"\n    F[validate]\n    end</code></pre> <pre><code>flows:\n  # Optional default flow to use when no flow is specified\n  default: process\n\n  # Flow definitions\n  definitions:\n    - process: [validate, transform, save]\n    - data_collection: [collect, process]\n    - validation: [validate]\n\n# Flow execution conditions\nsteps:\n  - name: validate\n    condition: \"{{ args.input_file is defined }}\"\n\n  - name: transform\n    condition: \"{{ steps.validate.result.status == 'completed' }}\"\n</code></pre>"},{"location":"workflow-structure/#error-handling","title":"Error Handling","text":"<p>The workflow engine provides comprehensive error handling with improved error messages and strict variable checking:</p> <pre><code># Global settings for error handling\nsettings:\n  error_handling:\n    undefined_variables: strict  # Enable StrictUndefined behavior\n    show_available: true        # Show available variables in error messages\n\nsteps:\n  - name: template_task\n    task: template\n    error_handling:\n      undefined_variables: strict  # Override at step level\n      show_available: true\n    params:\n      template: \"Hello {{ name }}!\"  # Will fail if name is undefined\n</code></pre> <p>When <code>undefined_variables</code> is set to <code>strict</code>, the engine provides helpful error messages:</p> <pre><code>settings:\n  error_handling:\n    undefined_variables: strict\n    show_available: true  # Shows available env vars in errors\n</code></pre> <p>If an undefined environment variable is referenced, the error message will include: - The name of the missing variable - List of available environment variables - Context where the error occurred</p>"},{"location":"workflow-structure/#environment-variables","title":"Environment Variables","text":"<p>Environment variables in the workflow engine are handled through the workflow context and are accessible via the <code>env</code> namespace. The engine provides several ways to work with environment variables:</p>"},{"location":"workflow-structure/#access-methods","title":"Access Methods","text":"<ol> <li> <p>In Templates <pre><code>steps:\n  - name: use_env\n    task: template\n    params:\n      template: \"API URL is {{ env.API_URL }}\"\n</code></pre></p> </li> <li> <p>In Python Tasks <pre><code>steps:\n  - name: python_task\n    task: python\n    params:\n      code: |\n        import os\n        result = os.environ.get('API_URL')\n</code></pre></p> </li> <li> <p>In Shell Tasks    ```</p> </li> </ol>"},{"location":"contributing/coding-standards/","title":"Coding Standards","text":"<p>This document outlines the coding standards and best practices for contributing to the YAML Workflow Engine project.</p>"},{"location":"contributing/coding-standards/#python-code-style","title":"Python Code Style","text":""},{"location":"contributing/coding-standards/#code-formatting","title":"Code Formatting","text":"<p>We use Black for code formatting and isort for import sorting:</p> <pre><code># Format Python files\nblack src/ tests/\n\n# Sort imports\nisort --profile black src/ tests/\n\n# Run both\nblack src/ tests/ &amp;&amp; isort --profile black src/ tests/\n</code></pre>"},{"location":"contributing/coding-standards/#type-hints","title":"Type Hints","text":"<p>Use type hints for all function parameters and return values:</p> <pre><code>from typing import Dict, List, Optional\n\ndef process_data(\n    input_data: List[Dict[str, str]],\n    batch_size: Optional[int] = None\n) -&gt; Dict[str, int]:\n    \"\"\"Process input data and return statistics.\"\"\"\n    results = {}\n    # Implementation\n    return results\n</code></pre>"},{"location":"contributing/coding-standards/#docstrings","title":"Docstrings","text":"<p>Use Google-style docstrings for all modules, classes, and functions:</p> <pre><code>def validate_workflow(\n    workflow_file: str,\n    strict: bool = False\n) -&gt; Dict[str, Any]:\n    \"\"\"Validate a workflow file without executing it.\n\n    Args:\n        workflow_file: Path to the workflow file to validate.\n        strict: Whether to perform strict validation.\n\n    Returns:\n        Dict containing validation results.\n\n    Raises:\n        ValidationError: If the workflow is invalid.\n        FileNotFoundError: If the workflow file doesn't exist.\n    \"\"\"\n    # Implementation\n</code></pre>"},{"location":"contributing/coding-standards/#error-handling","title":"Error Handling","text":"<ol> <li> <p>Use custom exceptions for domain-specific errors: <pre><code>class WorkflowError(Exception):\n    \"\"\"Base class for workflow-related errors.\"\"\"\n    pass\n\nclass ValidationError(WorkflowError):\n    \"\"\"Raised when workflow validation fails.\"\"\"\n    pass\n</code></pre></p> </li> <li> <p>Provide helpful error messages: <pre><code>if not os.path.exists(workflow_file):\n    raise FileNotFoundError(\n        f\"Workflow file not found: {workflow_file}\"\n    )\n</code></pre></p> </li> </ol>"},{"location":"contributing/coding-standards/#testing","title":"Testing","text":""},{"location":"contributing/coding-standards/#test-organization","title":"Test Organization","text":"<p>Organize tests to mirror the source code structure:</p> <pre><code>tests/\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 test_cli.py\n\u251c\u2500\u2500 test_engine.py\n\u2514\u2500\u2500 tasks/\n    \u251c\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 test_base.py\n    \u2514\u2500\u2500 test_file_tasks.py\n</code></pre>"},{"location":"contributing/coding-standards/#test-cases","title":"Test Cases","text":"<p>Use descriptive test names and arrange tests using the AAA pattern:</p> <pre><code>def test_workflow_validation_catches_missing_required_params():\n    # Arrange\n    workflow_data = {\n        \"name\": \"test\",\n        \"steps\": [\n            {\n                \"name\": \"step1\",\n                \"task\": \"shell\",\n                # Missing required 'command' parameter\n            }\n        ]\n    }\n\n    # Act &amp; Assert\n    with pytest.raises(ValidationError) as exc:\n        validate_workflow_data(workflow_data)\n    assert \"Missing required parameter: command\" in str(exc.value)\n</code></pre>"},{"location":"contributing/coding-standards/#test-coverage","title":"Test Coverage","text":"<p>Maintain high test coverage:</p> <pre><code># Run tests with coverage\npytest tests/ --cov=yaml_workflow\n\n# Generate coverage report\npytest tests/ --cov=yaml_workflow --cov-report=html\n</code></pre>"},{"location":"contributing/coding-standards/#yaml-files","title":"YAML Files","text":""},{"location":"contributing/coding-standards/#workflow-files","title":"Workflow Files","text":"<p>Follow these guidelines for workflow files:</p> <ol> <li> <p>Use descriptive names: <pre><code>name: Data Processing Pipeline\ndescription: Process and analyze data from multiple sources\n</code></pre></p> </li> <li> <p>Group related parameters: <pre><code>params:\n  # Input configuration\n  input_file:\n    type: string\n    description: Input data file\n\n  # Processing options\n  batch_size:\n    type: integer\n    default: 1000\n</code></pre></p> </li> <li> <p>Use consistent indentation (2 spaces): <pre><code>steps:\n  - name: process\n    task: shell\n    params:\n      command: |\n        python process.py \\\n          --input {{ input_file }} \\\n          --batch-size {{ batch_size }}\n</code></pre></p> </li> </ol>"},{"location":"contributing/coding-standards/#configuration-files","title":"Configuration Files","text":"<p>For configuration files:</p> <ol> <li> <p>Use clear sections: <pre><code># Project settings\nproject:\n  name: example\n  version: 1.0.0\n\n# Task defaults\ntasks:\n  shell:\n    timeout: 300\n</code></pre></p> </li> <li> <p>Include comments for non-obvious settings: <pre><code>tasks:\n  http_request:\n    # Increase timeout for slow APIs\n    timeout: 60\n    # Disable SSL verification for local development\n    verify_ssl: false\n</code></pre></p> </li> </ol>"},{"location":"contributing/coding-standards/#git-workflow","title":"Git Workflow","text":""},{"location":"contributing/coding-standards/#commits","title":"Commits","text":"<ol> <li> <p>Use descriptive commit messages: <pre><code>feat: Add HTTP request retry mechanism\n\n- Add exponential backoff retry logic\n- Configure retry attempts via workflow\n- Add tests for retry functionality\n</code></pre></p> </li> <li> <p>Keep commits focused and atomic</p> </li> </ol>"},{"location":"contributing/coding-standards/#branches","title":"Branches","text":"<ol> <li>Feature branches:</li> <li><code>feature/add-http-retry</code></li> <li> <p><code>feature/improve-error-handling</code></p> </li> <li> <p>Fix branches:</p> </li> <li><code>fix/validation-error</code></li> <li><code>fix/cli-parameters</code></li> </ol>"},{"location":"contributing/coding-standards/#pull-requests","title":"Pull Requests","text":"<ol> <li>Include clear descriptions</li> <li>Reference related issues</li> <li>Update documentation</li> <li>Add/update tests</li> <li>Ensure CI passes</li> </ol>"},{"location":"contributing/coding-standards/#code-review","title":"Code Review","text":""},{"location":"contributing/coding-standards/#checklist","title":"Checklist","text":"<ul> <li>[ ] Code follows style guide</li> <li>[ ] Tests added/updated</li> <li>[ ] Documentation updated</li> <li>[ ] Error handling implemented</li> <li>[ ] Performance considerations addressed</li> <li>[ ] Security implications considered</li> </ul>"},{"location":"contributing/coding-standards/#review-comments","title":"Review Comments","text":"<ol> <li>Be constructive and specific</li> <li>Explain the reasoning</li> <li>Provide examples when helpful</li> <li>Consider alternative approaches </li> </ol>"},{"location":"contributing/pull-requests/","title":"Pull Request Guidelines","text":"<p>This document outlines the process for submitting pull requests to the YAML Workflow Engine project.</p>"},{"location":"contributing/pull-requests/#before-creating-a-pull-request","title":"Before Creating a Pull Request","text":"<ol> <li>Check Existing Issues/PRs</li> <li>Search for existing issues or pull requests</li> <li>Create an issue for discussion if needed</li> <li> <p>Link your PR to relevant issues</p> </li> <li> <p>Update Your Fork <pre><code># Add the upstream remote if not already done\ngit remote add upstream https://github.com/orieg/yaml-workflow.git\n\n# Fetch upstream changes\ngit fetch upstream\n\n# Rebase your branch on upstream main\ngit checkout your-feature-branch\ngit rebase upstream/main\n</code></pre></p> </li> <li> <p>Run Local Checks <pre><code># Install development dependencies\npip install -e \".[dev]\"\n\n# Format code\nblack src/ tests/\nisort --profile black src/ tests/\n\n# Run type checking\nmypy src/\n\n# Run tests\npytest tests/\n\n# Check documentation\nmkdocs serve\n</code></pre></p> </li> </ol>"},{"location":"contributing/pull-requests/#creating-a-pull-request","title":"Creating a Pull Request","text":""},{"location":"contributing/pull-requests/#branch-naming","title":"Branch Naming","text":"<p>Follow these conventions: - <code>feature/description</code> for new features - <code>fix/description</code> for bug fixes - <code>docs/description</code> for documentation changes - <code>refactor/description</code> for code refactoring - <code>test/description</code> for test improvements</p> <p>Example: <code>feature/add-http-retry</code></p>"},{"location":"contributing/pull-requests/#commit-messages","title":"Commit Messages","text":"<p>Use conventional commit format:</p> <pre><code>&lt;type&gt;(&lt;scope&gt;): &lt;description&gt;\n\n[optional body]\n\n[optional footer]\n</code></pre> <p>Types: - <code>feat</code>: New feature - <code>fix</code>: Bug fix - <code>docs</code>: Documentation changes - <code>style</code>: Code style changes (formatting, etc.) - <code>refactor</code>: Code refactoring - <code>test</code>: Adding or updating tests - <code>chore</code>: Maintenance tasks</p> <p>Example: <pre><code>feat(tasks): add HTTP request retry mechanism\n\n- Implement exponential backoff retry logic\n- Add retry configuration options\n- Include retry count in task output\n\nCloses #123\n</code></pre></p>"},{"location":"contributing/pull-requests/#pull-request-template","title":"Pull Request Template","text":"<pre><code>## Description\nBrief description of the changes\n\n## Type of Change\n- [ ] Bug fix\n- [ ] New feature\n- [ ] Breaking change\n- [ ] Documentation update\n\n## Checklist\n- [ ] Tests added/updated\n- [ ] Documentation updated\n- [ ] Code follows style guide\n- [ ] All tests passing\n- [ ] Type hints added/updated\n- [ ] Docstrings updated\n\n## Related Issues\nFixes #123\n\n## Additional Notes\nAny additional information that reviewers should know\n</code></pre>"},{"location":"contributing/pull-requests/#review-process","title":"Review Process","text":""},{"location":"contributing/pull-requests/#requesting-reviews","title":"Requesting Reviews","text":"<ol> <li>Choose Reviewers</li> <li>Request review from maintainers</li> <li>Tag relevant stakeholders</li> <li> <p>Consider domain expertise</p> </li> <li> <p>Draft PRs</p> </li> <li>Use draft PRs for work in progress</li> <li>Mark as ready when complete</li> </ol>"},{"location":"contributing/pull-requests/#addressing-feedback","title":"Addressing Feedback","text":"<ol> <li>Review Comments</li> <li>Respond to all comments</li> <li>Explain your changes</li> <li> <p>Link to relevant documentation</p> </li> <li> <p>Making Changes <pre><code># Make requested changes\ngit add .\ngit commit -m \"fix: address review feedback\"\n\n# Update PR\ngit push origin your-feature-branch\n</code></pre></p> </li> <li> <p>Resolving Discussions</p> </li> <li>Mark resolved when addressed</li> <li>Request re-review when ready</li> </ol>"},{"location":"contributing/pull-requests/#after-merge","title":"After Merge","text":"<ol> <li> <p>Clean Up <pre><code># Switch to main\ngit checkout main\n\n# Update main\ngit pull upstream main\n\n# Delete local branch\ngit branch -d your-feature-branch\n\n# Delete remote branch\ngit push origin --delete your-feature-branch\n</code></pre></p> </li> <li> <p>Follow Up</p> </li> <li>Close related issues</li> <li>Update project documentation</li> <li>Monitor CI/CD pipeline</li> </ol>"},{"location":"contributing/pull-requests/#tips-for-success","title":"Tips for Success","text":"<ol> <li>Keep PRs Focused</li> <li>One feature/fix per PR</li> <li>Split large changes into smaller PRs</li> <li> <p>Link related PRs</p> </li> <li> <p>Quality Checks</p> </li> <li>Run all tests locally</li> <li>Check code coverage</li> <li> <p>Verify documentation</p> </li> <li> <p>Communication</p> </li> <li>Be responsive to feedback</li> <li>Ask questions if unclear</li> <li> <p>Update PR description as needed</p> </li> <li> <p>Documentation</p> </li> <li>Update relevant docs</li> <li>Add inline comments</li> <li>Include examples</li> </ol>"},{"location":"contributing/pull-requests/#common-issues","title":"Common Issues","text":""},{"location":"contributing/pull-requests/#pr-too-large","title":"PR Too Large","text":"<p>Split into smaller, logical chunks: 1. Core functionality 2. Additional features 3. Documentation 4. Tests</p>"},{"location":"contributing/pull-requests/#failed-checks","title":"Failed Checks","text":"<p>Common fixes: <pre><code># Code style\nblack src/ tests/\nisort --profile black src/ tests/\n\n# Type checking\nmypy src/\n\n# Fix test failures\npytest tests/ -v\n</code></pre></p>"},{"location":"contributing/pull-requests/#merge-conflicts","title":"Merge Conflicts","text":"<pre><code># Update main\ngit fetch upstream\ngit checkout main\ngit merge upstream/main\n\n# Rebase your branch\ngit checkout your-feature-branch\ngit rebase main\n\n# Force push if needed\ngit push origin your-feature-branch --force-with-lease\n</code></pre>"},{"location":"examples/advanced-hello-world/","title":"Advanced Hello World Example","text":"<p>This example demonstrates advanced features of the workflow engine including: - Input validation with error handling - Conditional execution based on validation results - File operations in different formats (txt, json, yaml) - Shell command execution - Template rendering with variable substitution - Multi-step workflow with dependencies</p>"},{"location":"examples/advanced-hello-world/#workflow-definition","title":"Workflow Definition","text":"<pre><code>name: Advanced Hello World\ndescription: &gt;\n  An advanced hello world workflow demonstrating:\n  - Input validation\n  - Conditional execution\n  - Error handling\n  - Multiple output formats\n  - Shell commands\n  - Template rendering\n  - Custom module tasks\n\nparams:\n  name:\n    description: Name to include in the greeting\n    default: World\n\nsteps:\n  # Step 1: Validate the input name parameter\n  - name: validate_input\n    task: shell\n    command: |\n      mkdir -p \"output/\"\n      if [ -z \"{{ name|default('') }}\" ]; then\n        echo \"Error: Name parameter is required\" &gt; \"output/validation_result.txt\"\n      elif [ \"{{ name|length }}\" -lt 2 ]; then\n        echo \"Error: Name must be at least 2 characters long\" &gt; \"output/validation_result.txt\"\n      elif [ \"{{ name|length }}\" -gt 50 ]; then\n        echo \"Error: Name must not exceed 50 characters\" &gt; \"output/validation_result.txt\"\n      else\n        echo \"Valid: {{ name }}\" &gt; \"output/validation_result.txt\"\n      fi\n\n  # Step 2: Read validation result\n  - name: check_validation\n    task: read_file\n    params:\n      file_path: \"output/validation_result.txt\"\n      encoding: \"utf-8\"\n    outputs: validation_content\n\n  # Step 3: Process validation result\n  - name: process_validation\n    task: shell\n    command: |\n      if grep -q \"^Error:\" \"output/validation_result.txt\"; then\n        echo \"Validation failed:\" &gt;&amp;2\n        cat \"output/validation_result.txt\" &gt;&amp;2\n        printf \"false\" &gt; \"output/validation_passed.txt\"\n      else\n        echo \"Validation passed\"\n        printf \"true\" &gt; \"output/validation_passed.txt\"\n      fi\n\n  # Step 4: Read validation flag\n  - name: read_validation\n    task: read_file\n    params:\n      file_path: \"output/validation_passed.txt\"\n    outputs: validation_content\n\n  # Step 5: Get current timestamp (only if validation passed)\n  - name: get_timestamp\n    task: shell\n    command: date -u +\"%Y-%m-%dT%H:%M:%SZ\"\n    outputs: current_timestamp\n    condition: \"'{{ validation_content }}' == 'true'\"\n\n  # Step 6: Create JSON greeting (only if validation passed)\n  - name: create_greeting\n    task: write_json\n    params:\n      file_path: \"output/greeting.json\"\n      data: \n        greeting: \"Hello, {{ name }}!\"\n        timestamp: \"{{ current_timestamp }}\"\n        run_number: \"{{ run_number }}\"\n        language: \"en\"\n      indent: 2\n    condition: \"'{{ validation_content }}' == 'true'\"\n\n  # Step 7: Create multi-language greetings (only if validation passed)\n  - name: translate_greeting\n    task: write_yaml\n    params:\n      file_path: \"output/greetings.yaml\"\n      data:\n        English: \"Hello, {{ name }}!\"\n        Spanish: \"\u00a1Hola, {{ name }}!\"\n        French: \"Bonjour, {{ name }}!\"\n        German: \"Hallo, {{ name }}!\"\n        Italian: \"Ciao, {{ name }}!\"\n        Japanese: \"\u3053\u3093\u306b\u3061\u306f\u3001{{ name }}\u3055\u3093\uff01\"\n    condition: \"'{{ validation_content }}' == 'true'\"\n\n  # Step 8: Format and display results (only if validation passed)\n  - name: format_output\n    task: shell\n    command: |\n      if [ -f \"output/greeting.json\" ]; then\n        echo \"=== Workflow Results ===\"\n        echo \"Run #{{ run_number }} at {{ current_timestamp }}\"\n        echo\n        echo \"JSON Greeting:\"\n        cat \"output/greeting.json\"\n        echo\n        echo \"Multiple Languages:\"\n        cat \"output/greetings.yaml\"\n        echo\n        echo \"=== End of Results ===\"\n      fi\n    condition: \"'{{ validation_content }}' == 'true'\"\n\n  # Step 9: Handle validation errors (only if validation failed)\n  - name: handle_error\n    task: write_file\n    params:\n      file_path: \"output/error_report.txt\"\n      content: |\n        Workflow encountered an error:\n        Input validation failed{% if name %} for name: {{ name }}{% else %}: name parameter not provided{% endif %}\n\n        Please check the requirements and try again.\n\n        Requirements:\n        - Name must be provided\n        - Name must be between 2 and 50 characters\n        - Name must not contain special characters\n    condition: \"'{{ validation_content }}' == 'false'\"\n\n  # Step 10: Final status notification\n  - name: notify_status\n    task: shell\n    command: |\n      if [ \"$(cat output/validation_passed.txt)\" = \"true\" ]; then\n        echo \"Workflow completed successfully!\"\n        echo \"Check the output files for detailed results:\"\n        echo \"- greeting.json: JSON formatted greeting\"\n        echo \"- greetings.yaml: Multi-language greetings\"\n        echo \"- validation_result.txt: Input validation details\"\n      else\n        echo \"Workflow failed due to validation errors.\"\n        echo \"Check error_report.txt for details.\"\n        if [ -f \"output/error_report.txt\" ]; then\n          cat \"output/error_report.txt\"\n        else\n          cat \"output/validation_result.txt\"\n        fi\n      fi\n</code></pre>"},{"location":"examples/advanced-hello-world/#usage-examples","title":"Usage Examples","text":"<ol> <li> <p>Run with default name: <pre><code>yaml-workflow run advanced-hello-world.yaml\n</code></pre></p> </li> <li> <p>Run with a custom name: <pre><code>yaml-workflow run advanced-hello-world.yaml --name=\"Alice\"\n</code></pre></p> </li> <li> <p>Test validation error (name too short): <pre><code>yaml-workflow run advanced-hello-world.yaml --name=\"A\"\n</code></pre></p> </li> </ol>"},{"location":"examples/advanced-hello-world/#key-features-demonstrated","title":"Key Features Demonstrated","text":"<ol> <li>Input Validation</li> <li>Length checks (2-50 characters)</li> <li>Required parameter validation</li> <li> <p>Validation result storage in files</p> </li> <li> <p>Conditional Execution</p> </li> <li>Steps that run only if validation passes</li> <li>Error handling steps for validation failures</li> <li> <p>Condition-based file operations</p> </li> <li> <p>File Operations</p> </li> <li>Reading and writing files</li> <li>Multiple formats (TXT, JSON, YAML)</li> <li> <p>File-based state management</p> </li> <li> <p>Variable Management</p> </li> <li>Step output capture using <code>outputs</code></li> <li>Variable interpolation in templates</li> <li> <p>Built-in variables (<code>run_number</code>)</p> </li> <li> <p>Error Handling</p> </li> <li>Validation error reporting</li> <li>Custom error messages</li> <li> <p>Error state management</p> </li> <li> <p>Multi-language Support</p> </li> <li>Greetings in multiple languages</li> <li>Unicode text handling</li> <li>YAML formatting</li> </ol>"},{"location":"examples/advanced-hello-world/#example-outputs","title":"Example Outputs","text":""},{"location":"examples/advanced-hello-world/#successful-run","title":"Successful Run","text":"<pre><code>=== Workflow Results ===\nRun #1 at 2024-01-23T10:30:00Z\n\nJSON Greeting:\n{\n  \"greeting\": \"Hello, Alice!\",\n  \"timestamp\": \"2024-01-23T10:30:00Z\",\n  \"run_number\": \"1\",\n  \"language\": \"en\"\n}\n\nMultiple Languages:\nEnglish: Hello, Alice!\nSpanish: \u00a1Hola, Alice!\nFrench: Bonjour, Alice!\nGerman: Hallo, Alice!\nItalian: Ciao, Alice!\nJapanese: \u3053\u3093\u306b\u3061\u306f\u3001Alice\u3055\u3093\uff01\n\n=== End of Results ===\n\nWorkflow completed successfully!\nCheck the output files for detailed results:\n- greeting.json: JSON formatted greeting\n- greetings.yaml: Multi-language greetings\n- validation_result.txt: Input validation details\n</code></pre>"},{"location":"examples/advanced-hello-world/#failed-validation","title":"Failed Validation","text":"<pre><code>Validation failed:\nError: Name must be at least 2 characters long\n\nWorkflow failed due to validation errors.\nCheck error_report.txt for details.\nWorkflow encountered an error:\nInput validation failed for name: A\n\nPlease check the requirements and try again.\n\nRequirements:\n- Name must be provided\n- Name must be between 2 and 50 characters\n- Name must not contain special characters\n</code></pre>"},{"location":"examples/basic-workflow/","title":"Basic Workflow Example","text":"<p>This example demonstrates a simple data processing workflow that: 1. Validates input files 2. Processes data 3. Saves results 4. Sends notifications</p>"},{"location":"examples/basic-workflow/#workflow-definition","title":"Workflow Definition","text":"<pre><code>name: Basic Data Processing\ndescription: Process CSV files and generate reports\n\nparams:\n  input_file:\n    description: Input CSV file path\n    type: string\n    required: true\n  output_dir:\n    description: Output directory for results\n    type: string\n    default: \"output\"\n  notify_email:\n    description: Email for notifications\n    type: string\n    required: true\n\nenv:\n  PYTHONPATH: \".\"\n  TEMP_DIR: \"./temp\"\n\nsteps:\n  # Step 1: Validate input file\n  - name: validate_input\n    task: file_check\n    params:\n      path: \"{{ input_file }}\"\n      required: true\n      readable: true\n      extension: \".csv\"\n\n  # Step 2: Create output directory\n  - name: setup_output\n    task: shell\n    command: |\n      mkdir -p \"{{ output_dir }}\"\n      mkdir -p \"{{ env.TEMP_DIR }}\"\n\n  # Step 3: Process data\n  - name: process_data\n    task: shell\n    command: python scripts/process_data.py --input \"{{ input_file }}\" --output \"{{ output_dir }}/processed.json\"\n    retry:\n      max_attempts: 3\n      delay: 5\n    output_var: process_result\n\n  # Step 4: Generate report\n  - name: generate_report\n    task: write_json\n    params:\n      file_path: \"{{ output_dir }}/report.json\"\n      data:\n        input_file: \"{{ input_file }}\"\n        processed_at: \"{{ current_timestamp }}\"\n        results: \"{{ process_result }}\"\n      indent: 2\n\n  # Step 5: Send notification\n  - name: notify\n    task: shell\n    command: echo \"Processing complete for {{ input_file }}\" | mail -s \"Workflow Complete\" {{ notify_email }}\n    condition: \"{{ process_result is defined }}\"\n</code></pre>"},{"location":"examples/basic-workflow/#usage","title":"Usage","text":"<ol> <li> <p>Save the workflow as <code>workflows/data_process.yaml</code></p> </li> <li> <p>Create the processing script (<code>scripts/process_data.py</code>): <pre><code>import argparse\nimport pandas as pd\nimport json\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--input\", required=True)\n    parser.add_argument(\"--output\", required=True)\n    args = parser.parse_args()\n\n    # Read and process data\n    df = pd.read_csv(args.input)\n    result = df.describe().to_dict()\n\n    # Save results\n    with open(args.output, \"w\") as f:\n        json.dump(result, f, indent=2)\n\nif __name__ == \"__main__\":\n    main()\n</code></pre></p> </li> <li> <p>Run the workflow: <pre><code>yaml-workflow run workflows/data_process.yaml \\\n  input_file=data/sample.csv \\\n  output_dir=output \\\n  notify_email=user@example.com\n</code></pre></p> </li> </ol>"},{"location":"examples/basic-workflow/#flow-control","title":"Flow Control","text":"<p>You can define multiple flows for different purposes:</p> <pre><code>flows:\n  default: process\n  definitions:\n    - process: [validate_input, setup_output, process_data, generate_report, notify]\n    - validate: [validate_input]\n    - cleanup: [setup_output]\n</code></pre> <p>Then run specific flows: <pre><code>yaml-workflow run workflows/data_process.yaml --flow validate \\\n  input_file=data/sample.csv\n</code></pre></p>"},{"location":"examples/basic-workflow/#error-handling","title":"Error Handling","text":"<p>The workflow includes several error handling features:</p> <ol> <li>Input validation using <code>file_check</code></li> <li>Automatic directory creation</li> <li>Retry logic for data processing</li> <li>Conditional notification</li> <li>Output variable capture</li> </ol>"},{"location":"examples/basic-workflow/#next-steps","title":"Next Steps","text":"<ul> <li>See task reference for all available tasks </li> </ul>"},{"location":"examples/hello-world/","title":"Hello World Example","text":"<p>This example demonstrates the core features of YAML Workflow: - Template task for generating text with variable substitution - Shell task for running commands and displaying information - Built-in variables (run_number, workflow_name, timestamp, workspace)</p>"},{"location":"examples/hello-world/#workflow-file","title":"Workflow File","text":"<pre><code># A minimal example workflow that demonstrates core features:\n# - Template task for generating text with variable substitution\n# - Shell task for running commands and displaying information\n# - Built-in variables (run_number, workflow_name, timestamp, workspace)\n#\n# Required parameters:\n# - name: The name to include in the greeting (e.g., name=World)\n\nname: Hello World\ndescription: A simple workflow that creates a greeting\n\nparams:\n  name:\n    description: Name to include in the greeting\n    default: World\n\nsteps:\n  - name: create_greeting\n    task: template\n    template: |\n      Hello, {{ name }}!\n\n      This is run #{{ run_number }} of the {{ workflow_name }} workflow.\n      Created at: {{ timestamp }}\n      Workspace: {{ workspace }}\n    output: greeting.txt\n\n  - name: show_info\n    task: shell\n    command: |\n      echo \"Workflow run information:\"\n      echo \"------------------------\"\n      echo \"Run number: {{ run_number }}\"\n      echo \"Workflow: {{ workflow_name }}\"\n      echo \"Created: {{ timestamp }}\"\n      echo \"Workspace: {{ workspace }}\"\n      echo \"------------------------\"\n      echo \"Current directory: $(pwd)\"\n      cat greeting.txt\n</code></pre>"},{"location":"examples/hello-world/#features-demonstrated","title":"Features Demonstrated","text":"<ol> <li>Parameter Definition</li> <li>Defines a <code>name</code> parameter with a default value</li> <li> <p>Uses parameter validation and description</p> </li> <li> <p>Template Task</p> </li> <li>Creates a greeting using template substitution</li> <li>Demonstrates variable interpolation</li> <li> <p>Shows output file creation</p> </li> <li> <p>Shell Task</p> </li> <li>Runs shell commands</li> <li>Shows environment information</li> <li> <p>Reads and displays files</p> </li> <li> <p>Built-in Variables</p> </li> <li><code>run_number</code>: Unique run identifier</li> <li><code>workflow_name</code>: Name of the workflow</li> <li><code>timestamp</code>: Current time</li> <li><code>workspace</code>: Working directory</li> </ol>"},{"location":"examples/hello-world/#usage","title":"Usage","text":"<ol> <li> <p>Save the workflow: <pre><code>mkdir -p workflows\ncp examples/hello_world.yaml workflows/\n</code></pre></p> </li> <li> <p>Run with default parameter: <pre><code>yaml-workflow run workflows/hello_world.yaml\n</code></pre></p> </li> <li> <p>Run with custom name: <pre><code>yaml-workflow run workflows/hello_world.yaml name=\"Alice\"\n</code></pre></p> </li> </ol>"},{"location":"examples/hello-world/#expected-output","title":"Expected Output","text":"<pre><code>Workflow run information:\n------------------------\nRun number: 1\nWorkflow: Hello World\nCreated: 2024-01-23T10:30:00Z\nWorkspace: /path/to/workspace\n------------------------\nCurrent directory: /path/to/workspace\nHello, Alice!\n\nThis is run #1 of the Hello World workflow.\nCreated at: 2024-01-23T10:30:00Z\nWorkspace: /path/to/workspace\n</code></pre>"},{"location":"examples/test-resume/","title":"Resume Testing Example","text":"<p>This example demonstrates the workflow resumption functionality, allowing you to: - Test workflow failure and recovery - Resume from failed steps - Start from specific steps - Handle required parameters during resumption</p>"},{"location":"examples/test-resume/#workflow-file","title":"Workflow File","text":"<pre><code># Test Resume Workflow\n# This workflow is designed to test the workflow resumption functionality.\n# It has three steps that can be used to verify different resume scenarios:\n#\n# How to test:\n# 1. Run without required_param - will fail at first step:\n#    yaml-workflow run workflows/test_resume.yaml\n#\n# 2. Resume the failed workflow:\n#    yaml-workflow run workflows/test_resume.yaml --resume required_param=test\n#\n# 3. Try to resume a completed workflow (should fail):\n#    yaml-workflow run workflows/test_resume.yaml --resume\n#\n# 4. Start from a specific step (fresh run):\n#    yaml-workflow run workflows/test_resume.yaml --start-from process_data required_param=test\n\nname: Test Resume\ndescription: A simple workflow to test resumption functionality\n\nsteps:\n  # Step 1: Validate required parameter\n  # This step will fail if required_param is not provided\n  - name: check_required_param\n    task: shell\n    command: |\n      if [ -z \"{{ required_param|default('') }}\" ]; then\n        echo \"Error: required_param is required\" &gt;&amp;2\n        exit 1\n      fi\n      echo \"required_param is {{ required_param }}\"\n      echo \"{{ required_param }}\" &gt; \"output/check_result.txt\"\n    outputs:\n      check_result: \"{{ required_param }}\"\n\n  # Step 2: Process the data\n  # Creates a file with the parameter value\n  - name: process_data\n    task: shell\n    command: |\n      echo \"Processing data with {{ required_param }}\"\n      echo \"{{ required_param }}\" &gt; \"output/result.txt\"\n    outputs:\n      process_result: \"{{ required_param }}\"\n\n  # Step 3: Final verification\n  # Reads and displays the processed result\n  - name: final_step\n    task: shell\n    command: |\n      echo \"Final step - reading result\"\n      cat \"output/result.txt\"\n    outputs:\n      final_result: \"$(cat output/result.txt)\"\n</code></pre>"},{"location":"examples/test-resume/#features-demonstrated","title":"Features Demonstrated","text":"<ol> <li>Workflow Resumption</li> <li>Resume from failed steps</li> <li>Start from specific steps</li> <li> <p>Handle required parameters</p> </li> <li> <p>Parameter Validation</p> </li> <li>Required parameter checking</li> <li> <p>Error handling for missing parameters</p> </li> <li> <p>Step Dependencies</p> </li> <li>Sequential step execution</li> <li>Output capture between steps</li> <li> <p>File-based state persistence</p> </li> <li> <p>Error Handling</p> </li> <li>Graceful failure on missing parameters</li> <li>Error message output</li> <li>Exit code handling</li> </ol>"},{"location":"examples/test-resume/#test-scenarios","title":"Test Scenarios","text":""},{"location":"examples/test-resume/#1-initial-failure","title":"1. Initial Failure","text":"<p>Run without required parameter: <pre><code>yaml-workflow run workflows/test_resume.yaml\n</code></pre></p> <p>Expected output: <pre><code>Error: required_param is required\nWorkflow failed at step 'check_required_param'\n</code></pre></p>"},{"location":"examples/test-resume/#2-resume-after-failure","title":"2. Resume After Failure","text":"<p>Resume with required parameter: <pre><code>yaml-workflow run workflows/test_resume.yaml --resume required_param=test\n</code></pre></p> <p>Expected output: <pre><code>required_param is test\nProcessing data with test\nFinal step - reading result\ntest\n</code></pre></p>"},{"location":"examples/test-resume/#3-resume-completed-workflow","title":"3. Resume Completed Workflow","text":"<p>Try to resume a completed workflow: <pre><code>yaml-workflow run workflows/test_resume.yaml --resume\n</code></pre></p> <p>Expected output: <pre><code>Error: Cannot resume workflow - no failed state found\n</code></pre></p>"},{"location":"examples/test-resume/#4-start-from-specific-step","title":"4. Start from Specific Step","text":"<p>Start from the process_data step: <pre><code>yaml-workflow run workflows/test_resume.yaml --start-from process_data required_param=test\n</code></pre></p> <p>Expected output: <pre><code>Processing data with test\nFinal step - reading result\ntest\n</code></pre></p>"},{"location":"examples/test-resume/#tips-for-testing","title":"Tips for Testing","text":"<ol> <li> <p>Clean State <pre><code>rm -rf output/\n</code></pre></p> </li> <li> <p>Check Output Files <pre><code>cat output/check_result.txt\ncat output/result.txt\n</code></pre></p> </li> <li> <p>Monitor Step Execution</p> </li> <li>Watch for step progression</li> <li>Check error messages</li> <li>Verify output files </li> </ol>"},{"location":"guide/batch-tasks/","title":"Batch Task Processing","text":"<p>This guide covers how to effectively use batch processing capabilities in YAML Workflow to handle large datasets and long-running operations.</p>"},{"location":"guide/batch-tasks/#overview","title":"Overview","text":"<p>Batch processing allows you to: - Process large datasets in manageable chunks - Track progress and maintain state between runs - Handle errors gracefully with standardized error handling - Process items in parallel for improved performance - Resume processing from the last successful point - Access batch-specific context variables</p>"},{"location":"guide/batch-tasks/#basic-batch-processing","title":"Basic Batch Processing","text":"<p>Here's a simple example of a batch processing workflow:</p> <pre><code>name: process-items\ndescription: Process a list of items in batches\nversion: '1.0'\n\nargs:\n  items:\n    type: list\n    description: List of items to process\n    default: [\"item1\", \"item2\", \"item3\", \"item4\", \"item5\"]\n  chunk_size:\n    type: integer\n    description: Size of each batch\n    default: 2\n\nsteps:\n  process_items:\n    name: process_items\n    task: batch\n    inputs:\n      items: \"{{ args.items }}\"\n      chunk_size: \"{{ args.chunk_size }}\"\n      max_workers: 2  # Process up to 2 chunks in parallel\n      task:  # Task configuration for processing each item\n        task: shell\n        inputs:\n          command: |\n            echo \"Processing item {{ batch.item }} ({{ batch.index + 1 }}/{{ batch.total }})\"\n            ./process.sh \"{{ batch.item }}\"\n</code></pre>"},{"location":"guide/batch-tasks/#batch-context","title":"Batch Context","text":"<p>Each item in a batch has access to these context variables:</p> <ul> <li><code>batch.item</code>: The current item being processed</li> <li><code>batch.index</code>: Zero-based index of the current item</li> <li><code>batch.total</code>: Total number of items in the batch</li> <li><code>batch.name</code>: Name of the batch task</li> </ul> <p>Example using batch context:</p> <pre><code>steps:\n  process_files:\n    name: process_files\n    task: batch\n    inputs:\n      items: \"{{ args.files }}\"\n      task:\n        task: python\n        inputs:\n          code: |\n            # Access batch context\n            current_file = batch['item']\n            progress = f\"{batch['index'] + 1}/{batch['total']}\"\n            task_name = batch['name']\n\n            print(f\"[{task_name}] Processing {current_file} ({progress})\")\n            result = process_file(current_file)\n</code></pre>"},{"location":"guide/batch-tasks/#error-handling","title":"Error Handling","text":"<p>Batch tasks use standardized error handling:</p> <pre><code>steps:\n  process_with_retries:\n    name: process_with_retries\n    task: batch\n    inputs:\n      items: \"{{ args.items }}\"\n      retry:\n        max_attempts: 3\n        delay: 5\n      task:\n        task: shell\n        inputs:\n          command: \"./process.sh {{ batch.item }}\"\n\n  handle_results:\n    name: handle_results\n    task: python\n    inputs:\n      code: |\n        results = steps['process_with_retries']['results']\n\n        # Check each result\n        for result in results:\n          if 'error' in result:\n            print(f\"Item {result['index']} failed: {result['error']}\")\n          else:\n            print(f\"Item {result['index']} succeeded: {result['result']}\")\n</code></pre>"},{"location":"guide/batch-tasks/#state-tracking","title":"State Tracking","text":"<p>The batch processor maintains detailed state information:</p> <pre><code>steps:\n  process_items:\n    name: process_items\n    task: batch\n    inputs:\n      items: \"{{ args.items }}\"\n      task:\n        task: python\n        inputs:\n          code: |\n            # Process item and update state\n            result = process_item(batch['item'])\n\n            # Results are automatically tracked\n            return {\n              'item': batch['item'],\n              'status': 'completed',\n              'output': result\n            }\n\n  check_progress:\n    name: check_progress\n    task: python\n    inputs:\n      code: |\n        batch_results = steps['process_items']['results']\n\n        # Analyze results\n        completed = [r for r in batch_results if 'result' in r]\n        failed = [r for r in batch_results if 'error' in r]\n\n        print(f\"Completed: {len(completed)}/{len(batch_results)}\")\n        print(f\"Failed: {len(failed)}/{len(batch_results)}\")\n</code></pre>"},{"location":"guide/batch-tasks/#performance-optimization","title":"Performance Optimization","text":"<p>Optimize batch processing with these features:</p> <pre><code>steps:\n  optimized_processing:\n    name: optimized_processing\n    task: batch\n    inputs:\n      items: \"{{ args.items }}\"\n      chunk_size: 10          # Process 10 items at a time\n      max_workers: 4          # Use 4 parallel workers\n      retry:\n        max_attempts: 3       # Retry failed items up to 3 times\n        delay: 5              # Wait 5 seconds between retries\n      task:\n        task: shell\n        inputs:\n          command: \"./process.sh {{ batch.item }}\"\n          timeout: 300        # Timeout after 5 minutes\n          working_dir: \"{{ env.WORKSPACE }}/{{ batch.item }}\"\n</code></pre>"},{"location":"guide/batch-tasks/#best-practices","title":"Best Practices","text":"<ol> <li>Chunk Size:</li> <li>Balance memory usage and performance</li> <li>Consider item processing complexity</li> <li> <p>Test with different sizes for optimization</p> </li> <li> <p>Error Handling:</p> </li> <li>Always implement retry mechanisms</li> <li>Use standardized error handling</li> <li>Track failed items for analysis</li> <li> <p>Provide meaningful error messages</p> </li> <li> <p>State Management:</p> </li> <li>Use the built-in state tracking</li> <li>Monitor progress regularly</li> <li>Implement proper cleanup</li> <li> <p>Handle interruptions gracefully</p> </li> <li> <p>Performance:</p> </li> <li>Use appropriate chunk sizes</li> <li>Enable parallel processing when suitable</li> <li>Monitor resource usage</li> <li> <p>Set reasonable timeouts</p> </li> <li> <p>Context Usage:</p> </li> <li>Use batch context variables</li> <li>Maintain namespace isolation</li> <li>Follow variable naming conventions</li> <li>Document context requirements</li> </ol>"},{"location":"guide/batch-tasks/#complete-example","title":"Complete Example","text":"<p>Here's a comprehensive batch processing workflow:</p> <pre><code>name: process-dataset\ndescription: Process a large dataset with full features\nversion: '1.0'\n\nargs:\n  input_files:\n    type: list\n    description: Files to process\n  chunk_size:\n    type: integer\n    default: 10\n  max_workers:\n    type: integer\n    default: 4\n\nenv:\n  WORKSPACE: \"/data/processing\"\n  API_KEY: \"{{ args.api_key }}\"\n\nsteps:\n  validate_inputs:\n    name: validate_inputs\n    task: python\n    inputs:\n      code: |\n        files = args['input_files']\n        if not files:\n          raise TaskExecutionError(\"No input files provided\")\n        result = [f for f in files if os.path.exists(f)]\n\n  process_files:\n    name: process_files\n    task: batch\n    inputs:\n      items: \"{{ steps.validate_inputs.result }}\"\n      chunk_size: \"{{ args.chunk_size }}\"\n      max_workers: \"{{ args.max_workers }}\"\n      retry:\n        max_attempts: 3\n        delay: 5\n      task:\n        task: shell\n        inputs:\n          command: |\n            echo \"[{{ batch.index + 1 }}/{{ batch.total }}] Processing {{ batch.item }}\"\n            ./process.sh \\\n              --input \"{{ batch.item }}\" \\\n              --output \"{{ env.WORKSPACE }}/output/{{ batch.index }}\" \\\n              --api-key \"{{ env.API_KEY }}\"\n          working_dir: \"{{ env.WORKSPACE }}\"\n          timeout: 300\n\n  generate_report:\n    name: generate_report\n    task: python\n    inputs:\n      code: |\n        results = steps['process_files']['results']\n\n        # Analyze results\n        completed = [r for r in results if 'result' in r]\n        failed = [r for r in results if 'error' in r]\n\n        # Generate report\n        report = {\n          'total': len(results),\n          'completed': len(completed),\n          'failed': len(failed),\n          'success_rate': len(completed) / len(results) * 100,\n          'failed_items': [r['item'] for r in failed]\n        }\n\n        # Save report\n        with open('report.json', 'w') as f:\n          json.dump(report, f, indent=2)\n\n        result = report\n</code></pre> <p>This documentation provides a comprehensive guide to batch processing capabilities, focusing on real-world usage patterns and best practices. </p>"},{"location":"guide/concepts/","title":"Core Concepts","text":"<p>This document explains the core concepts of the YAML Workflow Engine.</p>"},{"location":"guide/concepts/#workflows","title":"Workflows","text":"<p>A workflow is a YAML file that defines a sequence of tasks to be executed. Each workflow can have:</p> <ul> <li>A name and description</li> <li>Parameter definitions</li> <li>Environment variables</li> <li>A sequence of steps (tasks)</li> <li>Flow definitions for organizing steps</li> </ul> <p>Example workflow structure: <pre><code>name: Data Processing Workflow\ndescription: Process and analyze data files\n\nparams:\n  input_file:\n    description: Input file to process\n    type: string\n    required: true\n  batch_size:\n    description: Number of items to process at once\n    type: integer\n    default: 100\n\nenv:\n  DEBUG: \"true\"\n  TEMP_DIR: \"./temp\"\n\nsteps:\n  - name: validate_input\n    task: file_check\n    params:\n      path: \"{{ input_file }}\"\n\n  - name: process_data\n    task: data_processor\n    params:\n      input: \"{{ input_file }}\"\n      batch_size: \"{{ batch_size }}\"\n</code></pre></p>"},{"location":"guide/concepts/#tasks","title":"Tasks","text":"<p>Tasks are the building blocks of workflows. Each task:</p> <ul> <li>Has a specific type (e.g., shell, python, http)</li> <li>Can accept parameters</li> <li>Can produce outputs</li> <li>Can have conditions for execution</li> <li>Can include error handling</li> </ul>"},{"location":"guide/concepts/#parameters","title":"Parameters","text":"<p>Parameters allow workflows to be dynamic and reusable:</p> <ul> <li>Can be defined at workflow or task level</li> <li>Support type validation</li> <li>Can have default values</li> <li>Can be required or optional</li> <li>Support Jinja2 templating</li> </ul>"},{"location":"guide/concepts/#flows","title":"Flows","text":"<p>Flows allow you to organize steps into logical groups:</p> <pre><code>flows:\n  default: process  # Default flow to execute\n  definitions:\n    - process: [validate_input, process_data, save_results]\n    - cleanup: [archive_data, cleanup_temp]\n</code></pre> <p>Benefits of flows:</p> <ul> <li>Organize steps into logical sequences</li> <li>Run different step combinations for different purposes</li> <li>Skip unnecessary steps</li> <li>Maintain multiple workflows in one file</li> </ul>"},{"location":"guide/concepts/#error-handling","title":"Error Handling","text":"<p>The engine provides several error handling mechanisms:</p> <ul> <li>Retry mechanisms for failed tasks</li> <li>Alternative paths on failure</li> <li>Skip or abort options</li> <li>Custom error handlers</li> <li>Detailed error reporting</li> </ul>"},{"location":"guide/concepts/#templating","title":"Templating","text":"<p>The engine uses Jinja2 for templating, providing powerful features for dynamic content generation and variable substitution. For detailed information about templating capabilities, see the Templating Guide.</p> <p>Key templating features include: - Variable substitution using <code>{{ variable }}</code> - Control structures (if/else, loops) - Filters and expressions - Access to environment variables and step outputs - Error handling and default values</p> <p>Example: <pre><code>steps:\n  - name: template_example\n    task: template\n    template: |\n      Hello, {{ name }}!\n      Environment: {{ env.ENVIRONMENT | default('development') }}\n      Run number: {{ run_number }}\n</code></pre></p> <p>For more examples and best practices, refer to the Templating Guide. </p>"},{"location":"guide/configuration/","title":"Configuration Guide","text":"<p>This guide explains how to configure YAML Workflow for your needs.</p>"},{"location":"guide/configuration/#workflow-configuration","title":"Workflow Configuration","text":""},{"location":"guide/configuration/#basic-structure","title":"Basic Structure","text":"<p>A workflow file consists of these main sections:</p> <pre><code>name: My Workflow\ndescription: A description of what this workflow does\n\n# Optional version for compatibility\nversion: \"1.0\"\n\n# Optional environment variables\nenv:\n  DEBUG: \"true\"\n  TEMP_DIR: \"./temp\"\n\n# Parameter definitions\nparams:\n  input_file:\n    description: Input file to process\n    type: string\n    required: true\n  batch_size:\n    description: Number of items to process at once\n    type: integer\n    default: 100\n\n# Optional flow definitions\nflows:\n  default: main_flow\n  definitions:\n    - main_flow: [validate, process, report]\n    - cleanup: [archive, cleanup]\n\n# Workflow steps\nsteps:\n  - name: validate\n    task: file_check\n    params:\n      path: \"{{ args.input_file }}\"\n  - name: process_batch\n    task: batch\n    inputs:\n      # Input items to process\n      # Assuming get_items returns the list directly as its result\n      items: \"{{ steps.get_items.result }}\"\n\n      # Processing configuration\n      chunk_size: 10\n      max_workers: 4\n\n      # Processing task\n      task:\n        task: python\n        inputs:\n          code: \"process_item()\"\n\n      # Optional argument name for items (defaults to \"item\")\n      arg_name: data_item\n\n### Accessing Step Results\n\n   The results of completed steps are stored in the `steps` namespace. All results are nested under a `result` key for consistency and to avoid potential name collisions.\n\n   ```yaml\n   # Example Step\n   - name: process_data\n     task: some_task\n     # ... other params ...\n\n   # Accessing results in a later step\n   - name: use_result\n     task: another_task\n     inputs:\n       # If process_data returns a single value (e.g., a string or number)\n       input_value: \"{{ steps.process_data.result }}\"\n\n       # If process_data returns a dictionary (e.g., {'status': 'ok', 'file_path': '/path/to/file'})\n       status_from_prev: \"{{ steps.process_data.result.status }}\"\n       path_from_prev: \"{{ steps.process_data.result.file_path }}\"\n   ```\n\n### Batch Processing\n\nConfigure batch processing tasks:\n\n```yaml\n# Example Batch Processing Step Configuration (Replace with actual example if available)\nsteps:\n  - name: process_batch_example\n    task: batch_processor # Or relevant batch task type\n    inputs:\n      items: \"{{ steps.get_items.result }}\" # Assuming get_items returns a list\n      chunk_size: 10\n      # ... other batch parameters ...\n      task: # The task to run on each item/chunk\n        task: python \n        # ... sub-task inputs ... \n</code></pre>"},{"location":"guide/configuration/#template-variables","title":"Template Variables","text":"<p>Available template variables are organized in namespaces:</p> <ol> <li> <p>Arguments (<code>args</code>): Access parameters passed to the workflow.     <pre><code>{{ args.input_file }}      # Access parameter value\n{{ args.mode }}           # Access parameter with default\n</code></pre></p> </li> <li> <p>Environment Variables (<code>env</code>): Access environment variables.     <pre><code>{{ env.API_KEY }}        # Environment variable\n{{ env.DEBUG }}         # Environment variable with default\n</code></pre></p> </li> <li> <p>Step Results (<code>steps</code>): Access results from previous steps.     <pre><code># Access the entire result (if it's a single value or you need the whole dict)\n{{ steps.previous_step.result }}\n\n# Access a specific key if the result is a dictionary\n{{ steps.previous_step.result.specific_key }}\n\n# Access the status of a step (completed, failed, skipped) - accessed directly\n{{ steps.previous_step.status }} \n</code></pre> Note: Step status is accessed directly via <code>steps.STEP_NAME.status</code>, not nested under <code>result</code>.</p> </li> <li> <p>Built-in Variables (<code>workflow</code>): Access workflow metadata.     <pre><code>{{ workflow.name }}          # Workflow name\n{{ workflow.workspace }}     # Workspace directory\n{{ workflow.run_id }}        # Unique run ID\n{{ workflow.timestamp }}     # Current time\n</code></pre></p> </li> </ol>"},{"location":"guide/error-handling/","title":"Error Handling Patterns","text":"<p>YAML Workflow provides robust mechanisms for handling errors gracefully within your workflows. This guide covers common patterns and best practices.</p>"},{"location":"guide/error-handling/#core-concepts","title":"Core Concepts","text":"<ul> <li><code>TaskExecutionError</code>: The base exception raised when a task fails during execution. It often wraps the original exception.</li> <li><code>on_error</code> block: A step-level configuration to define behavior when that specific step fails.</li> <li>Retry Mechanism: Automatically retry failed steps based on configuration.</li> <li>Error Context: Information about the error (step name, original exception, etc.) is available in templates within the <code>on_error</code> block and potentially passed to error handling steps.</li> <li>State Management: The engine tracks the status of each step (completed, failed, skipped) and the overall workflow status.</li> </ul>"},{"location":"guide/error-handling/#step-level-error-handling-on_error","title":"Step-Level Error Handling (<code>on_error</code>)","text":"<p>For a runnable example demonstrating the concepts below (retry, continue, next, error messages), see <code>docs/examples/error_handling/workflow.yaml</code>.</p> <p>You can define how a step should react to its own failure using the <code>on_error</code> block within the step definition.</p> <pre><code>steps:\n  - name: risky_api_call\n    task: api_call\n    inputs:\n      url: \"{{ env.API_URL }}/data\"\n    on_error:\n      action: retry # or fail, continue, next\n      retry: 3\n      delay: 10 # seconds\n      message: \"API call failed for {{ args.item }}: {{ error }}\" # Optional custom message\n      next: handle_api_failure # Optional target step for 'next' action\n</code></pre>"},{"location":"guide/error-handling/#actions","title":"Actions:","text":"<ul> <li><code>fail</code> (Default): The step is marked as failed, and the entire workflow halts immediately, raising a <code>WorkflowError</code>.</li> <li><code>retry</code>: Attempts to re-run the failed step.</li> <li><code>retry</code> (integer): Maximum number of retry attempts (defaults to global setting or 3).</li> <li><code>delay</code> (integer/float): Seconds to wait before the next retry attempt (defaults to 0).</li> <li>If retries are exhausted, the behavior defaults to <code>fail</code> unless <code>next</code> or <code>continue</code> is also specified.</li> <li><code>continue</code>: Marks the step as failed but allows the workflow to proceed to the next step in the sequence. The failed step's output will not be available in the <code>steps</code> namespace.</li> <li><code>next</code>: Marks the step as failed and jumps execution to a different step specified by the <code>next</code> key. This allows for dedicated error handling flows.</li> </ul>"},{"location":"guide/error-handling/#custom-error-message-message","title":"Custom Error Message (<code>message</code>)","text":"<ul> <li>You can provide a custom error message template using <code>message</code> for logging and state tracking.</li> <li>This template can use Jinja2 syntax and access standard context variables (<code>args</code>, <code>env</code>, <code>steps</code>).</li> <li>It can also access the core error details using the <code>error</code> variable:</li> <li><code>{{ error }}</code>: Provides the primary error information, often the string representation of the original exception that caused the failure (e.g., \"FileNotFoundError: [Errno 2] No such file or directory...\").</li> <li>The resolved <code>message</code> is stored in the workflow state for the failed step (e.g., accessible later via <code>steps.FAILED_STEP_NAME.error_message</code>) and is used in logs. Use this pattern to access formatted error messages in subsequent error-handling steps.</li> </ul>"},{"location":"guide/error-handling/#retry-strategies","title":"Retry Strategies","text":"<ul> <li>Simple Retry: Use <code>action: retry</code> with <code>retry</code> and <code>delay</code> for transient issues (e.g., network timeouts, temporary API unavailability). Best for idempotent operations where re-running is safe.</li> <li>Retry with Backoff: While not built-in directly as an exponential backoff flag, you could potentially implement custom retry logic within a Python task if needed, though standard linear delay is often sufficient.</li> <li>Global Retries: A global default retry count can potentially be set in workflow <code>settings</code> (implementation may vary).</li> </ul>"},{"location":"guide/error-handling/#error-handling-actions-when-to-use-what","title":"Error Handling Actions: When to Use What","text":"<ul> <li><code>fail</code> (Default): Use when any failure in the step is critical and the entire workflow should stop immediately.</li> <li><code>retry</code>: Use for transient errors where re-running the step might succeed (e.g., network issues, temporary service unavailability). Ensure the step is safe to re-run (idempotent).</li> <li><code>continue</code>: Use when a step's failure is non-critical, and the workflow can proceed meaningfully without its results. Subsequent steps should not depend directly on the output of the failed step.</li> <li><code>next</code>: Use when a failure requires specific cleanup, compensation, or notification actions before potentially stopping or continuing the workflow. Redirects execution to a dedicated error-handling sequence.</li> </ul>"},{"location":"guide/error-handling/#error-handling-flows-action-next","title":"Error Handling Flows (<code>action: next</code>)","text":"<p>Use <code>action: next</code> to redirect the workflow to a dedicated error handling path.</p> <pre><code>flows:\n  default: main_flow\n  definitions:\n    - main_flow: [step_a, risky_step, step_c]\n    - error_flow: [log_error, notify_admin] # Defines the sequence for the error path\n\nsteps:\n  - name: step_a\n    # ...\n  - name: risky_step\n    task: some_task\n    # ...\n    on_error:\n      action: next\n      next: log_error # Jump to the start of the error_flow sequence\n      message: \"Risky step failed for {{ args.id }}: {{ error }}\" # Custom message stored in state\n  - name: step_c\n    # ... only runs if risky_step succeeds ...\n\n  - name: log_error\n    task: write_file\n    inputs:\n      path: \"output/error_log.txt\"\n      content: |\n        Workflow Failure Report\n        -----------------------\n        Timestamp: {{ workflow.timestamp }}\n        Failed Step: {{ steps.risky_step.name }} {# Assumes 'risky_step' is the one that failed #}\n        Reason: {{ steps.risky_step.error_message }} {# Access the formatted message defined above #}\n        Original Error: {{ steps.risky_step.error }} {# Access raw error if needed #}\n\n        Context:\n        Args: {{ args | tojson }}\n        # Add other relevant context if available\n    # Note: This step runs *after* the risky_step failed and was redirected here.\n    # It accesses the state (name, error_message, error) of the failed step.\n\n  - name: notify_admin\n    task: slack_notify # Example custom task\n    inputs:\n      channel: \"#alerts\"\n      message: \"Workflow {{ workflow.name }} failed at step {{ steps.risky_step.name }}. Reason: {{ steps.risky_step.error_message }}. See error_log.txt for details.\"\n</code></pre>"},{"location":"guide/error-handling/#error-propagation","title":"Error Propagation","text":"<ul> <li>When a step fails and the action is <code>fail</code> (or retries are exhausted with no <code>continue</code>/<code>next</code>), the engine wraps the original exception (or the <code>TaskExecutionError</code> created by <code>handle_task_error</code>) within a <code>WorkflowError</code> and halts execution.</li> <li>The <code>WorkflowError</code> contains information about the step that failed and often includes the original exception as its cause (<code>__cause__</code> or an <code>original_error</code> attribute), allowing programmatic inspection if the engine is used as a library.</li> <li>If <code>action: continue</code> is used, the error is logged and recorded in the state, but execution proceeds.</li> <li>If <code>action: next</code> is used, the error context is preserved in the failed step's state, and the workflow jumps to the specified step.</li> </ul>"},{"location":"guide/error-handling/#centralized-error-handling-in-custom-tasks","title":"Centralized Error Handling in Custom Tasks","text":"<p>As detailed in the Task Development Guide, custom Python tasks should use the <code>handle_task_error</code> utility. This ensures: - Consistent logging format. - Wrapping of arbitrary exceptions into <code>TaskExecutionError</code>. - Inclusion of relevant context (step name, task type, task config) in the raised exception. </p>"},{"location":"guide/flows/","title":"Flow Configuration Guide","text":"<p>YAML Workflow allows you to define specific execution paths, called flows, through the steps defined in your workflow. This enables more complex logic, such as running only a subset of steps, defining specific error handling paths, or having different execution sequences based on parameters.</p>"},{"location":"guide/flows/#defining-flows","title":"Defining Flows","text":"<p>Flows are defined within the optional top-level <code>flows</code> block in your workflow YAML file.</p> <p>For a runnable example demonstrating the concepts below, see <code>docs/examples/flows/workflow.yaml</code>.</p> <pre><code>name: My Workflow with Flows\nparams: { ... }\nsteps:\n  - name: step_a\n    task: ...\n  - name: step_b\n    task: ...\n  - name: step_c\n    task: ...\n  - name: error_handler\n    task: ...\n\nflows:\n  default: main_flow # Optional: Specifies the flow to run if none is provided via CLI\n\n  definitions:\n    - main_flow: # Name of the first flow\n        - step_a\n        - step_b\n        - step_c\n\n    - short_flow: # Name of a second flow\n        - step_a\n        - step_c\n\n    - error_handling_flow: # A flow potentially used by on_error.next\n        - error_handler\n        - step_c # Maybe cleanup or final step\n</code></pre> <p>Structure:</p> <ul> <li><code>flows</code>: The main key for flow configuration.</li> <li><code>flows.default</code>: (Optional) The name of the flow to execute if the user runs <code>yaml-workflow run &lt;workflow_file&gt;</code> without specifying a <code>--flow</code> argument. If omitted, and flows are defined, the behavior might depend on the engine version (often defaulting to running all steps sequentially or requiring an explicit flow). For clarity, defining a <code>default</code> is recommended if you use flows.</li> <li><code>flows.definitions</code>: A list containing flow definitions.</li> <li>Flow Definition: Each item in the <code>definitions</code> list is a dictionary where:<ul> <li>The key is the unique name of the flow (e.g., <code>main_flow</code>).</li> <li>The value is an ordered list of step names (strings) that constitute that flow. The steps listed must exist in the main <code>steps:</code> block of the workflow.</li> </ul> </li> </ul>"},{"location":"guide/flows/#executing-a-specific-flow","title":"Executing a Specific Flow","text":"<p>You can execute a specific flow using the <code>--flow</code> option in the CLI:</p> <pre><code># Run the flow named 'short_flow'\nyaml-workflow run my_workflow.yaml --flow short_flow\n\n# Run the default flow (if defined, otherwise might error or run all steps)\nyaml-workflow run my_workflow.yaml\n</code></pre>"},{"location":"guide/flows/#use-cases-for-flows","title":"Use Cases for Flows","text":"<p>Flows allow for more structured and flexible workflow execution. Common use cases include:</p> <ol> <li>Standard Execution Path: Define a <code>default</code> flow that represents the normal, successful execution path of your core logic.</li> <li>Subset Execution: Create shorter flows for specific tasks like:<ul> <li>Setup: A flow that only runs initialization steps.</li> <li>Teardown: A flow that only runs cleanup steps.</li> <li>Validation: A flow that runs only validation steps.</li> <li>Testing: A flow that runs a specific sequence for testing purposes.</li> </ul> </li> <li>Conditional Logic (High-Level): While fine-grained conditions are handled by the <code>condition</code> key within individual steps, you could potentially have different flows triggered based on input parameters passed to an external script that calls <code>yaml-workflow run --flow ...</code>. For example, a script might run <code>--flow full_process</code> normally, but <code>--flow quick_check</code> if a specific flag is passed.</li> <li>Error Handling Paths: Recovery: Define error handling paths using <code>on_error</code> and <code>action: next</code> (see Error Handling Guide).</li> </ol> <p>See Also: The <code>complex_flow_error_handling.yaml</code> file in the examples directory provides a practical demonstration of using different flows for standard execution, subset execution, and error handling paths.</p>"},{"location":"guide/flows/#interaction-with-resume","title":"Interaction with Resume","text":"<p>When a workflow run fails within a specific flow (either the default or one specified via <code>--flow</code>), using the <code>--resume</code> flag on a subsequent run will:</p> <ol> <li>Attempt to restart the same flow that was originally executed.</li> <li>Start execution from the step that initially failed.</li> </ol> <p>The engine does not switch to a different flow automatically upon resuming.</p>"},{"location":"guide/flows/#best-practices","title":"Best Practices","text":"<ul> <li>Clear Naming: Give your flows descriptive names reflecting their purpose (e.g., <code>main_process</code>, <code>setup_resources</code>, <code>error_cleanup</code>).</li> <li>Define a Default: If you use flows, define a <code>default</code> flow for the most common execution path and for clarity when no <code>--flow</code> is specified.</li> <li>Step Reuse: Leverage flows to reuse the same underlying steps in different sequences, promoting modularity (e.g., a <code>validate</code> step might be part of <code>main_process</code> and also its own <code>validation_only</code> flow).</li> <li>Validate Steps: Ensure all step names listed within a flow definition correspond to actual steps defined in the main <code>steps:</code> block. The engine performs validation, but checking beforehand is good practice.</li> <li>Combine with <code>condition</code>: Use step-level <code>condition</code> keys for fine-grained conditional execution within a flow. Flows control the overall sequence, while <code>condition</code> controls whether an individual step in that sequence runs based on the current context.</li> <li>Keep Flows Focused: Avoid overly complex flows. If a flow becomes very long or has many branches, consider if refactoring the workflow or splitting it into multiple workflow files might be clearer. </li> </ul>"},{"location":"guide/flows/#example-flow-configuration","title":"Example Flow Configuration","text":""},{"location":"guide/getting-started/","title":"Getting Started","text":"<p>This guide will help you get started with the YAML Workflow Engine.</p>"},{"location":"guide/getting-started/#installation","title":"Installation","text":"<p>Install the YAML Workflow Engine using pip:</p> <pre><code>pip install yaml-workflow\n</code></pre>"},{"location":"guide/getting-started/#basic-concepts","title":"Basic Concepts","text":"<p>The YAML Workflow Engine is built around a few core concepts:</p> <ol> <li>Workflows: YAML files that define a sequence of tasks to be executed</li> <li>Tasks: Individual units of work that can be executed</li> <li>Flows: Named sequences of tasks that can be executed together</li> <li>Parameters: Values that can be passed to workflows and tasks</li> </ol>"},{"location":"guide/getting-started/#your-first-workflow","title":"Your First Workflow","text":"<ol> <li>Create a new directory for your workflow:</li> </ol> <pre><code>mkdir my-workflow\ncd my-workflow\n</code></pre> <ol> <li>Initialize a new workflow project:</li> </ol> <pre><code>yaml-workflow init --example hello_world\n</code></pre> <ol> <li>Examine the generated workflow file (<code>workflows/hello_world.yaml</code>):</li> </ol> <pre><code>name: Hello World Workflow\ndescription: A simple example workflow\n\nparams:\n  name:\n    description: Name to include in greeting\n    type: string\n    required: true\n\nsteps:\n  - name: greet\n    task: shell\n    command: echo \"Hello, {{ name }}!\"\n</code></pre> <ol> <li>Run the workflow:</li> </ol> <pre><code>yaml-workflow run workflows/hello_world.yaml name=World\n</code></pre>"},{"location":"guide/getting-started/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about workflow configuration</li> <li>Explore built-in tasks</li> <li>See more examples </li> </ul>"},{"location":"guide/task-development/","title":"Task Development Guide","text":"<p>This guide provides instructions and best practices for developing custom tasks for the YAML Workflow engine.</p>"},{"location":"guide/task-development/#creating-new-tasks","title":"Creating New Tasks","text":"<ul> <li>Using <code>TaskConfig</code>: Understand how to access parameters, context, and workspace information via the <code>TaskConfig</code> object passed to your task function.</li> <li>Task Registration: Use the <code>@register_task(\"your_task_name\")</code> decorator to make your task available in workflow YAML files.</li> <li>Type Safety: Utilize Python type hints for function arguments and return values to improve clarity and enable static analysis.</li> <li>Logging: Use <code>get_task_logger</code> from <code>yaml_workflow.tasks.base</code> to get a logger specific to the task instance.</li> </ul>"},{"location":"guide/task-development/#returning-results","title":"Returning Results","text":"<p>Tasks should return the primary output they generate. This could be a single value (like a string, number, boolean) or a dictionary containing multiple related output values.</p> <p>The workflow engine consistently stores the entire return value of a task under the <code>result</code> key within the <code>steps</code> namespace for the executed step. This provides a predictable access pattern regardless of the return type.</p>"},{"location":"guide/task-development/#accessing-previous-step-outputs","title":"Accessing Previous Step Outputs","text":"<p>Always use the <code>steps</code> namespace in your Jinja2 templates within task <code>inputs</code> to access the results of previously executed steps. </p> <ul> <li>Primary Output: Access the complete result returned by the previous step using <code>{{ steps.STEP_NAME.result }}</code>.</li> <li>If the step returned a single value (e.g., a string), this will be the value itself.</li> <li> <p>If the step returned a dictionary (e.g., <code>{\"stdout\": \"output\", \"code\": 0}</code>), this will be the dictionary.</p> </li> <li> <p>Dictionary Keys: If the previous step returned a dictionary, access specific keys within that dictionary using <code>{{ steps.STEP_NAME.result.KEY }}</code>.   <pre><code>steps:\n  - name: my_shell_step\n    task: shell\n    inputs:\n      command: \"ls -l\"\n    # Shell task returns a dict: {\"stdout\": ..., \"stderr\": ..., \"return_code\": ...}\n\n  - name: my_echo\n    task: echo\n    inputs:\n      message: \"Hello\"\n    # Echo task returns a string: \"Hello\"\n\n  - name: use_results\n    task: some_other_task\n    inputs:\n      # Access stdout from the shell step's result dictionary\n      shell_stdout: \"{{ steps.my_shell_step.result.stdout }}\"\n      # Access the return code from the shell step's result dictionary\n      shell_code: \"{{ steps.my_shell_step.result.return_code }}\"\n\n      # Access the single string value returned by the echo step\n      echo_output: \"{{ steps.my_echo.result }}\"\n</code></pre></p> </li> <li> <p>Step Status/Error: Note that step metadata like <code>status</code> and <code>error</code> are accessed directly on the step object, not under the <code>result</code> key:   <pre><code>condition: \"{{ steps.my_shell_step.status == 'completed' }}\"\nerror_message: \"{{ steps.my_shell_step.error }}\" # Only available if step failed\n</code></pre></p> </li> </ul>"},{"location":"guide/task-development/#error-handling-best-practices","title":"Error Handling Best Practices","text":"<ul> <li>Use Centralized Handling: Import <code>handle_task_error</code> and <code>ErrorContext</code> from <code>yaml_workflow.tasks.error_handling</code>.</li> <li>Wrap Exceptions: Catch specific exceptions within your task logic. If an error occurs, create an <code>ErrorContext</code> instance and pass it to <code>handle_task_error</code>. This ensures consistent error logging and propagation.   <pre><code>from yaml_workflow.tasks.error_handling import ErrorContext, handle_task_error\nfrom yaml_workflow.exceptions import TaskExecutionError\n\ntry:\n    # Your task logic here\n    # ...\n    if some_error_condition:\n        raise ValueError(\"Something went wrong\")\nexcept Exception as e:\n    # Avoid raising TaskExecutionError directly if possible,\n    # let handle_task_error wrap it.\n    if isinstance(e, TaskExecutionError):\n        raise # Re-raise if it's already the correct type\n\n    err_context = ErrorContext(\n        step_name=config.name, \n        task_type=config.type, \n        error=e, \n        task_config=config.step # Pass the raw step definition\n    )\n    handle_task_error(err_context) # This will raise TaskExecutionError\n</code></pre></li> <li>Specific Exceptions: Define custom exception classes inheriting from <code>TaskExecutionError</code> for domain-specific errors if needed.</li> </ul>"},{"location":"guide/task-development/#testing-requirements","title":"Testing Requirements","text":"<ul> <li>Write unit tests for your task function's logic.</li> <li>Include integration tests that run your task within a minimal workflow to verify:</li> <li>Parameter handling.</li> <li>Correct output structure (dict vs. single value).</li> <li>Accessing its output via the <code>steps</code> namespace in a subsequent step.</li> <li>Error handling behavior.</li> </ul> <pre><code># Example test structure (using pytest)\nimport pytest\nfrom pathlib import Path\nfrom yaml_workflow.tasks import TaskConfig\nfrom my_custom_tasks.greeting_task import custom_greeting_task # Import your task\n\n@pytest.fixture\ndef temp_workspace(tmp_path: Path) -&gt; Path:\n    return tmp_path\n\n@pytest.fixture\ndef sample_task_config(temp_workspace: Path) -&gt; TaskConfig:\n    step = {\n        \"name\": \"test_greet\",\n        \"task\": \"custom_greet\",\n        \"inputs\": {\n            \"name\": \"Tester\",\n            \"prefix\": \"Hi\"\n        }\n    }\n    context = { # Mock context\n        \"args\": {},\n        \"env\": {},\n        \"steps\": {}\n    }\n    return TaskConfig(step, context, temp_workspace)\n\ndef test_custom_greeting_success(sample_task_config: TaskConfig):\n    \"\"\"Test successful execution of the custom greeting task.\"\"\"\n    result = custom_greeting_task(sample_task_config)\n    assert result is not None\n    assert result[\"greeting_message\"] == \"Hi, Tester!\"\n    assert \"output_file\" in result\n    assert Path(result[\"output_file\"]).exists()\n    assert Path(result[\"output_file\"]).read_text() == \"Hi, Tester!\"\n\ndef test_custom_greeting_invalid_input(sample_task_config: TaskConfig):\n    \"\"\"Test the task with invalid input.\"\"\"\n    sample_task_config.step[\"inputs\"][\"name\"] = \"\" # Invalid empty name\n\n    # Assuming handle_task_error raises TaskExecutionError wrapping the ValueError\n    from yaml_workflow.exceptions import TaskExecutionError\n    with pytest.raises(TaskExecutionError) as exc_info:\n        custom_greeting_task(sample_task_config)\n\n    # Check the original error type\n    assert isinstance(exc_info.value.original_error, ValueError)\n    assert \"Input 'name' must be a non-empty string\" in str(exc_info.value.original_error)\n</code></pre>"},{"location":"guide/templating/","title":"Templating Guide","text":"<p>YAML Workflow uses Jinja2 as its templating engine with StrictUndefined enabled, providing powerful variable substitution, control structures, and expressions in your workflows.</p>"},{"location":"guide/templating/#variable-namespaces","title":"Variable Namespaces","text":"<p>YAML Workflow organizes variables into distinct namespaces:</p>"},{"location":"guide/templating/#arguments-parameters","title":"Arguments (Parameters)","text":"<pre><code>steps:\n  - name: process\n    params:\n      input: \"{{ args.input_file }}\"      # Access parameter\n      mode: \"{{ args.mode | default('fast') }}\"  # With default\n</code></pre>"},{"location":"guide/templating/#environment-variables","title":"Environment Variables","text":"<pre><code>steps:\n  - name: configure\n    params:\n      api_url: \"{{ env.API_URL }}\"        # Access env var\n      debug: \"{{ env.DEBUG | default('false') }}\"  # With default\n</code></pre>"},{"location":"guide/templating/#step-results-steps","title":"Step Results (<code>steps</code>)","text":"<p>Access results from previous steps using the <code>steps</code> namespace. All primary outputs are nested under a <code>result</code> key for consistency. Step status and errors are accessed directly.</p> <pre><code>steps:\n  - name: use_results\n    params:\n      # Access the entire result (if it's a single value or you need the whole dict)\n      data: \"{{ steps.process.result }}\"\n\n      # Access a specific key if the 'process' step's result is a dictionary\n      # e.g., if steps.process.result == {'file': '/data.txt', 'count': 100}\n      file_processed: \"{{ steps.process.result.file }}\"\n      item_count: \"{{ steps.process.result.count }}\"\n\n      # Step status (completed, failed, skipped) - accessed directly\n      status: \"{{ steps.process.status }}\"\n      # Step error message if failed - accessed directly\n      error: \"{{ steps.process.error }}\"\n</code></pre>"},{"location":"guide/templating/#workflow-information","title":"Workflow Information","text":"<pre><code>steps:\n  - name: workflow_info\n    params:\n      name: \"{{ workflow.name }}\"\n      workspace: \"{{ workflow.workspace }}\"\n      run_id: \"{{ workflow.run_id }}\"\n      timestamp: \"{{ workflow.timestamp }}\"\n</code></pre>"},{"location":"guide/templating/#error-handling","title":"Error Handling","text":"<p>YAML Workflow uses StrictUndefined to catch undefined variables early:</p>"},{"location":"guide/templating/#undefined-variables","title":"Undefined Variables","text":"<pre><code># This will fail with a helpful error message:\nsteps:\n  - name: example\n    params:\n      value: \"{{ unknown_var }}\"\n\n# Error message will show:\n# TemplateError: Variable 'unknown_var' is undefined. Available variables:\n# - args: [input_file, mode, batch_size]\n# - env: [API_URL, DEBUG]\n# - steps: [process, transform]\n</code></pre>"},{"location":"guide/templating/#safe-defaults","title":"Safe Defaults","text":"<pre><code>steps:\n  - name: safe_example\n    params:\n      # Use default if variable is undefined\n      mode: \"{{ args.mode | default('standard') }}\"\n\n      # Use default with type conversion\n      debug: \"{{ env.DEBUG | default('false') | lower }}\"\n\n      # Complex default with condition\n      value: \"{{ steps.process.result | default(args.fallback if args.fallback is defined else 'default') }}\"\n</code></pre>"},{"location":"guide/templating/#error-messages","title":"Error Messages","text":"<pre><code>steps:\n  - name: validate\n    params:\n      input: \"{{ args.input_file }}\"\n    error_handling:\n      undefined_variables: strict  # Raises error for undefined\n      show_available: true        # Shows available variables\n    on_error:\n      message: \"Failed: {{ error }}\"  # Access error message\n</code></pre>"},{"location":"guide/templating/#control-structures","title":"Control Structures","text":""},{"location":"guide/templating/#conditionals","title":"Conditionals","text":"<pre><code>steps:\n  - name: conditional_step\n    condition: \"{{ steps.validate.status == 'completed' and args.mode == 'full' }}\"\n    params:\n      {% if env.DEBUG | default('false') | lower == 'true' %}\n      log_level: \"debug\"\n      verbose: true\n      {% else %}\n      log_level: \"info\"\n      verbose: false\n      {% endif %}\n</code></pre>"},{"location":"guide/templating/#loops","title":"Loops","text":"<pre><code>steps:\n  - name: batch_process\n    task: batch\n    inputs:\n      items: \"{{ steps.get_items.result }}\"\n      task:\n        task: python\n        inputs:\n          code: |\n            {% for opt in args.options %}\n            options[\"{{ opt.name }}\"] = \"{{ opt.value }}\"\n            {% endfor %}\n</code></pre>"},{"location":"guide/templating/#task-specific-usage","title":"Task-Specific Usage","text":""},{"location":"guide/templating/#template-tasks","title":"Template Tasks","text":"<pre><code>steps:\n  - name: generate_config\n    task: template\n    template: |\n      # Configuration\n      app_name: {{ args.name }}\n      environment: {{ env.ENVIRONMENT }}\n      debug: {{ env.DEBUG | default('false') | lower }}\n\n      # Processing\n      batch_size: {{ args.batch_size | default(100) }}\n      max_workers: {{ args.max_workers | default(4) }}\n\n      # Previous results\n      last_run: {{ steps.previous.result.timestamp }}\n      status: {{ steps.previous.status }}\n    output: \"{{ args.output_file }}\"\n    error_handling:\n      undefined_variables: strict\n      show_available: true\n</code></pre>"},{"location":"guide/templating/#python-tasks","title":"Python Tasks","text":"<pre><code>steps:\n  - name: process_data\n    task: python\n    params:\n      function: process_batch\n      args:\n        input: \"{{ args.input_file }}\"\n        batch_size: \"{{ args.batch_size }}\"\n      error_handling:\n        undefined_variables: strict\n    # The return value of the 'process_batch' function will be accessible\n    # via 'steps.process_data.result'\n</code></pre>"},{"location":"guide/templating/#batch-processing","title":"Batch Processing","text":"<pre><code>steps:\n  - name: process_items\n    task: batch\n    inputs:\n      # Input configuration\n      items: \"{{ steps.get_items.result }}\"\n      chunk_size: \"{{ args.chunk_size }}\"\n      max_workers: \"{{ args.max_workers }}\"\n\n      # Processing task\n      task:\n        task: python\n        inputs:\n          code: \"process_item()\"\n\n      # Optional argument name for items (defaults to \"item\")\n      arg_name: data_item\n</code></pre>"},{"location":"guide/templating/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Use Namespaced Variables <pre><code># Good: Clear variable source\ninput: \"{{ args.input_file }}\"\napi_key: \"{{ env.API_KEY }}\"\n\n# Bad: Unclear source\ninput: \"{{ input_file }}\"\n</code></pre></p> </li> <li> <p>Enable Strict Mode <pre><code># Good: Catches errors early\nerror_handling:\n  undefined_variables: strict\n  show_available: true\n\n# Bad: Silent failures\nvalue: \"{{ maybe_undefined }}\"\n</code></pre></p> </li> <li> <p>Use Type-Safe Defaults <pre><code># Good: Type-safe conversion\ndebug: \"{{ env.DEBUG | default('false') | lower in ['true', 'yes', '1'] }}\"\n\n# Bad: Potential type issues\ndebug: \"{{ env.DEBUG }}\"\n</code></pre></p> </li> </ol>"},{"location":"guide/tasks/","title":"Task Types","text":"<p>YAML Workflow provides several types of tasks that can be used in your workflows. Each task type serves a specific purpose and has its own set of parameters and capabilities.</p>"},{"location":"guide/tasks/#common-task-properties","title":"Common Task Properties","text":"<p>Every task in YAML Workflow supports these properties:</p> <pre><code>steps:\n  - name: task_name          # Required: Unique name for the task\n    task: task_type         # Required: Type of task to execute\n    description: string     # Optional: Description of what the task does\n    params: {}             # Required: Task-specific parameters\n    retry:                 # Optional: Retry configuration\n      max_attempts: int    # Number of retry attempts\n      delay: int          # Delay between retries in seconds\n      backoff: float      # Exponential backoff multiplier\n    on_error:             # Optional: Error handling configuration\n      action: string      # One of: fail, continue, retry\n      message: string     # Custom error message\n      next: string        # Next task to execute on error\n    timeout: int          # Optional: Task timeout in seconds\n    depends_on: []        # Optional: List of task dependencies\n</code></pre>"},{"location":"guide/tasks/#basic-tasks","title":"Basic Tasks","text":"<p>Simple utility tasks for common operations:</p> <ul> <li> <p><code>echo</code>: Print a message to the console   <pre><code>task: echo\nparams:\n  message: string       # Required: Message to print\n  level: string        # Optional: Log level (info, warning, error)\n</code></pre></p> </li> <li> <p><code>fail</code>: Deliberately fail a workflow (useful for testing)   <pre><code>task: fail\nparams:\n  message: string      # Optional: Custom failure message\n  code: int           # Optional: Exit code (default: 1)\n</code></pre></p> </li> <li> <p><code>add_numbers</code>: Add two numbers together   <pre><code>task: add_numbers\ninputs:\n  a: number          # Required: First number\n  b: number          # Required: Second number\noutputs: sum         # Result of a + b\n</code></pre></p> </li> <li> <p><code>join_strings</code>: Concatenate strings   <pre><code>task: join_strings\ninputs:\n  strings: [string]  # Required: List of strings to join\n  separator: string  # Optional: Separator (default: '')\noutputs: result     # Joined string\n</code></pre></p> </li> </ul>"},{"location":"guide/tasks/#file-operations","title":"File Operations","text":"<p>Tasks for working with files and directories:</p> <ul> <li> <p><code>write_file</code>: Write content to a file   <pre><code>task: write_file\ninputs:\n  file_path: string   # Required: Path to write to\n  content: string     # Required: Content to write\n  mode: string        # Optional: Write mode (w, a, default: w)\n  encoding: string    # Optional: File encoding (default: utf-8)\n</code></pre></p> </li> <li> <p><code>read_file</code>: Read content from a file   <pre><code>task: read_file\ninputs:\n  file_path: string   # Required: Path to read from\n  encoding: string    # Optional: File encoding (default: utf-8)\noutputs: content     # File contents\n</code></pre></p> </li> <li> <p><code>append_file</code>: Append content to a file</p> </li> <li><code>copy_file</code>: Copy a file to another location</li> <li><code>move_file</code>: Move/rename a file</li> <li><code>delete_file</code>: Delete a file</li> </ul> <p>Example: <pre><code>steps:\n  - name: write_config\n    task: write_file\n    inputs:\n      file_path: config.json\n      content: |\n        {\n          \"setting\": \"value\"\n        }\n\n  - name: read_data\n    task: read_file\n    inputs:\n      file_path: data.txt\n    outputs: file_content\n</code></pre></p>"},{"location":"guide/tasks/#shell-commands","title":"Shell Commands","text":"<p>Execute shell commands and scripts:</p> <ul> <li><code>shell</code>: Run shell commands with variable substitution   <pre><code>task: shell\ninputs:\n  command: string     # Required: Command to execute\n  cwd: string        # Optional: Working directory\n  env: object        # Optional: Additional environment variables\n  shell: string      # Optional: Shell to use (default: /bin/sh)\noutputs:\n  stdout: string     # Command standard output\n  stderr: string     # Command standard error\n  exit_code: int     # Command exit code\n</code></pre></li> </ul>"},{"location":"guide/tasks/#template-processing","title":"Template Processing","text":"<p>Tasks for template rendering and text processing:</p> <ul> <li><code>template</code>: Render a template with variable substitution</li> </ul> <p>Example: <pre><code>steps:\n  - name: generate_report\n    task: template\n    template: |\n      # Report for {{ date }}\n\n      Total records: {{ count }}\n      Status: {{ status }}\n    output: report.md\n</code></pre></p>"},{"location":"guide/tasks/#python-integration","title":"Python Integration","text":"<p>Execute Python code within workflows:</p> <ul> <li><code>python</code>: Run Python code with access to workflow context   <pre><code>task: python\ninputs:\n  code: string       # Required: Python code to execute\n  globals: object    # Optional: Global variables\n  locals: object     # Optional: Local variables\n  packages: [string] # Optional: Additional packages to import\noutputs: result     # Return value from Python code\n</code></pre></li> </ul>"},{"location":"guide/tasks/#batch-processing","title":"Batch Processing","text":"<p>Process data in batches:</p> <ul> <li><code>batch</code>: Process items in batches with configurable size and parallelism   <pre><code>task: batch\ninputs:\n  items: [any]       # Required: List of items to process\n  batch_size: int    # Optional: Items per batch (default: 10)\n  parallel: bool     # Optional: Process in parallel (default: false)\n  max_workers: int   # Optional: Max parallel workers (default: 4)\n  task:             # Required: Task configuration to run for each item\n    type: string    # Task type to execute\n    inputs: object  # Task inputs (item available as {{ item }})\noutputs:\n  results: [any]    # List of task results\n  failed: [any]     # List of failed items\n</code></pre></li> </ul>"},{"location":"guide/tasks/#task-features","title":"Task Features","text":"<p>All tasks support these common features:</p> <ol> <li>Variable Substitution</li> <li>Use <code>{{ variable }}</code> syntax to reference variables</li> <li> <p>Access step outputs, environment variables, and parameters</p> </li> <li> <p>Output Capture</p> </li> <li>Store task results in variables</li> <li> <p>Use outputs in subsequent steps</p> </li> <li> <p>Error Handling</p> </li> <li>Configure retry behavior</li> <li>Define error handling steps</li> <li> <p>Set custom error messages</p> </li> <li> <p>Conditional Execution</p> </li> <li>Run tasks based on conditions</li> <li>Skip tasks when conditions aren't met</li> </ol> <p>See the specific task documentation for detailed parameter lists and usage examples.</p>"},{"location":"guide/tasks/#data-processing","title":"Data Processing","text":""},{"location":"guide/tasks/#write_json","title":"<code>write_json</code>","text":"<p>Writes data as JSON to a file.</p> <pre><code>- name: save_json\n  task: write_json\n  params:\n    file_path: \"output/data.json\"\n    data: \"{{ process_result }}\"\n    indent: 2\n</code></pre>"},{"location":"guide/tasks/#write_yaml","title":"<code>write_yaml</code>","text":"<p>Writes data as YAML to a file.</p> <pre><code>- name: save_yaml\n  task: write_yaml\n  params:\n    file_path: \"output/config.yaml\"\n    data: \"{{ config_data }}\"\n</code></pre>"},{"location":"guide/tasks/#creating-custom-tasks","title":"Creating Custom Tasks","text":"<p>You can create custom tasks by:</p> <ol> <li>Creating a Python class that inherits from <code>BaseTask</code></li> <li>Implementing the required methods</li> <li>Registering the task with the engine</li> </ol> <p>Example: <pre><code>from yaml_workflow.tasks import BaseTask\n\nclass CustomTask(BaseTask):\n    def run(self, params):\n        # Task implementation\n        pass\n\n# Register the task\nregister_task(\"custom_task\", CustomTask) \n</code></pre></p>"},{"location":"guide/tasks/#error-handling","title":"Error Handling","text":"<p>Tasks can be configured to handle errors in different ways:</p> <ol> <li> <p>Retry Configuration <pre><code>retry:\n  max_attempts: 3        # Maximum number of attempts\n  delay: 5              # Delay between attempts (seconds)\n  backoff: 2           # Exponential backoff multiplier\n  on_error: [string]   # Retry only on specific errors\n</code></pre></p> </li> <li> <p>Error Actions <pre><code>on_error:\n  action: continue     # continue, fail, or retry\n  message: string      # Custom error message\n  next: cleanup       # Next task to execute on error\n</code></pre></p> </li> <li> <p>Conditional Execution <pre><code>condition: \"{{ prev_step.success and input_file }}\"\n</code></pre></p> </li> </ol>"},{"location":"guide/tasks/#task-dependencies","title":"Task Dependencies","text":"<p>Tasks can specify dependencies using the <code>depends_on</code> property:</p> <pre><code>steps:\n  - name: first_task\n    task: echo\n    inputs:\n      message: \"First\"\n\n  - name: second_task\n    task: echo\n    inputs:\n      message: \"Second\"\n    depends_on: [first_task]\n\n  - name: parallel_task\n    task: echo\n    inputs:\n      message: \"Can run in parallel with second_task\"\n    depends_on: [first_task]\n</code></pre> <p>Dependencies can be: - Single task: <code>depends_on: task_name</code> - Multiple tasks: <code>depends_on: [task1, task2]</code> - Conditional: <code>depends_on: \"{{ success_of_task }}\"</code> </p>"},{"location":"guide/tasks/basic-tasks/","title":"Basic Tasks","text":"<p>Simple utility tasks for common operations.</p>"},{"location":"guide/tasks/basic-tasks/#available-tasks","title":"Available Tasks","text":""},{"location":"guide/tasks/basic-tasks/#echo-task","title":"Echo Task","text":"<p>Print a message to the console:</p> <pre><code>task: echo\ninputs:\n  message: string       # Required: Message to print\n  level: string        # Optional: Log level (info, warning, error)\n</code></pre>"},{"location":"guide/tasks/basic-tasks/#fail-task","title":"Fail Task","text":"<p>Deliberately fail a workflow (useful for testing):</p> <pre><code>task: fail\ninputs:\n  message: string      # Optional: Custom failure message\n  code: int           # Optional: Exit code (default: 1)\n</code></pre>"},{"location":"guide/tasks/basic-tasks/#add-numbers-task","title":"Add Numbers Task","text":"<p>Add two numbers together:</p> <pre><code>task: add_numbers\ninputs:\n  a: number          # Required: First number\n  b: number          # Required: Second number\noutputs: sum         # Result of a + b\n</code></pre>"},{"location":"guide/tasks/basic-tasks/#join-strings-task","title":"Join Strings Task","text":"<p>Concatenate strings:</p> <pre><code>task: join_strings\ninputs:\n  strings: [string]  # Required: List of strings to join\n  separator: string  # Optional: Separator (default: '')\noutputs: result     # Joined string\n</code></pre>"},{"location":"guide/tasks/basic-tasks/#examples","title":"Examples","text":"<p>Here are some examples of using basic tasks:</p> <pre><code>steps:\n  - name: greet\n    task: echo\n    inputs:\n      message: \"Starting workflow...\"\n      level: info\n\n  - name: calculate\n    task: add_numbers\n    inputs:\n      a: 10\n      b: 20\n    outputs: sum\n\n  - name: report\n    task: echo\n    inputs:\n      message: \"The sum is {{ sum }}\"\n</code></pre>"},{"location":"guide/tasks/basic-tasks/#error-handling","title":"Error Handling","text":"<p>All basic tasks support standard error handling:</p> <pre><code>steps:\n  - name: example\n    task: echo\n    inputs:\n      message: \"Test message\"\n    retry:\n      max_attempts: 3\n      delay: 5\n    on_error:\n      action: continue\n      message: \"Echo failed, continuing...\"\n</code></pre>"},{"location":"guide/tasks/batch-tasks/","title":"Batch Processing Tasks","text":""},{"location":"guide/tasks/batch-tasks/#overview","title":"Overview","text":"<pre><code>graph TD\n    A[Input Data] --&gt; B[Split into Batches]\n    B --&gt; C[Process Batches]\n    C --&gt; D[Parallel Processing]\n    C --&gt; E[Sequential Processing]\n    D --&gt; F[Batch Results]\n    E --&gt; F\n    F --&gt; G[Aggregate Results]\n\n    subgraph \"Batch Processing Features\"\n    H[Progress Tracking]\n    I[State Management]\n    J[Error Handling]\n    K[Resume Capability]\n    end</code></pre>"},{"location":"guide/tasks/batch-tasks/#batch-processing-flow","title":"Batch Processing Flow","text":"<pre><code>stateDiagram-v2\n    [*] --&gt; PrepareData: Initialize\n    PrepareData --&gt; CreateBatches: Split Data\n    CreateBatches --&gt; ProcessBatch: For Each Batch\n    ProcessBatch --&gt; CheckParallel: Check Config\n    CheckParallel --&gt; ParallelExecution: Max Workers &gt; 1\n    CheckParallel --&gt; SequentialExecution: Max Workers = 1\n    ParallelExecution --&gt; TrackProgress: Process Items\n    SequentialExecution --&gt; TrackProgress: Process Items\n    TrackProgress --&gt; ProcessBatch: More Batches\n    TrackProgress --&gt; AggregateResults: All Complete\n    AggregateResults --&gt; [*]: Done\n\n    ProcessBatch --&gt; ErrorHandling: Batch Failed\n    ErrorHandling --&gt; RetryBatch: Can Retry\n    ErrorHandling --&gt; SkipBatch: Skip Failed\n    RetryBatch --&gt; ProcessBatch: Retry\n    SkipBatch --&gt; ProcessBatch: Next Batch</code></pre>"},{"location":"guide/tasks/batch-tasks/#basic-usage","title":"Basic Usage","text":"<pre><code>steps:\n  split_into_batches:\n    type: python\n    inputs:\n      code: |\n        numbers = params['numbers']\n        batch_size = params['batch_size']\n        batches = [numbers[i:i + batch_size] for i in range(0, len(numbers), batch_size)]\n        result = batches\n\n  process_batches:\n    type: python\n    for_each: \"{{ steps.split_into_batches.result }}\"\n    inputs:\n      operation: multiply\n      item: \"{{ item }}\"\n      factor: 2\n    retry:\n      max_attempts: 3\n      delay: 5\n</code></pre>"},{"location":"guide/tasks/batch-tasks/#parallel-processing-architecture","title":"Parallel Processing Architecture","text":"<pre><code>graph TD\n    A[Input Batches] --&gt; B[Worker Pool]\n    B --&gt; C[Worker 1]\n    B --&gt; D[Worker 2]\n    B --&gt; E[Worker 3]\n    B --&gt; F[Worker N]\n    C --&gt; G[Results Queue]\n    D --&gt; G\n    E --&gt; G\n    F --&gt; G\n    G --&gt; H[Aggregate Results]\n\n    subgraph \"Worker Management\"\n    I[Max Workers]\n    J[Queue Size]\n    K[Timeout]\n    end</code></pre>"},{"location":"guide/tasks/batch-tasks/#state-management","title":"State Management","text":"<pre><code>graph TD\n    A[Batch State] --&gt; B[Processed Items]\n    A --&gt; C[Failed Items]\n    A --&gt; D[Progress]\n    B --&gt; E[Success Count]\n    B --&gt; F[Success Results]\n    C --&gt; G[Error Count]\n    C --&gt; H[Error Details]\n    D --&gt; I[Total Items]\n    D --&gt; J[Current Item]\n    D --&gt; K[Completion %]</code></pre>"},{"location":"guide/tasks/batch-tasks/#error-handling-and-recovery","title":"Error Handling and Recovery","text":"<pre><code>stateDiagram-v2\n    [*] --&gt; ProcessItem: Next Item\n    ProcessItem --&gt; Success: Item Processed\n    ProcessItem --&gt; Failure: Item Failed\n    Failure --&gt; RetryItem: Can Retry\n    Failure --&gt; SkipItem: Max Retries\n    RetryItem --&gt; ProcessItem: Retry\n    SkipItem --&gt; SaveError: Log Error\n    Success --&gt; UpdateProgress: Track Progress\n    SaveError --&gt; UpdateProgress: Track Error\n    UpdateProgress --&gt; [*]: Next Item</code></pre>"},{"location":"guide/tasks/batch-tasks/#best-practices","title":"Best Practices","text":"<ol> <li>Chunk Size: Choose appropriate chunk sizes based on:</li> <li>Available memory</li> <li>Processing complexity</li> <li> <p>Required processing time</p> </li> <li> <p>State Management:</p> </li> <li>Store progress information in the context</li> <li>Use checkpoints for long-running operations</li> <li> <p>Implement resume capabilities</p> </li> <li> <p>Error Handling:</p> </li> <li>Implement retry mechanisms</li> <li>Log failed items</li> <li> <p>Provide cleanup steps</p> </li> <li> <p>Performance:</p> </li> <li>Use parallel processing when appropriate</li> <li>Monitor resource usage</li> <li> <p>Optimize batch sizes based on performance metrics</p> </li> <li> <p>Monitoring:</p> </li> <li>Track progress regularly</li> <li>Log important metrics</li> <li>Implement alerting for failures</li> </ol>"},{"location":"guide/tasks/batch-tasks/#features","title":"Features","text":""},{"location":"guide/tasks/batch-tasks/#batch-configuration","title":"Batch Configuration","text":"<p>Configure batch processing behavior:</p> <pre><code>steps:\n  - name: process_data\n    task: batch\n    inputs:\n      # Items to process\n      items: [\"a\", \"b\", \"c\", \"d\", \"e\"]\n\n      # Batch size (items per batch)\n      batch_size: 2\n\n      # Enable parallel processing\n      parallel: true\n\n      # Maximum parallel processes\n      max_parallel: 4\n\n      # Continue on errors\n      continue_on_error: false\n\n      # Task to execute for each item\n      task:\n        type: shell\n        command: \"echo Processing {{ item }}\"\n</code></pre>"},{"location":"guide/tasks/batch-tasks/#item-processing","title":"Item Processing","text":"<p>Process items using any available task type:</p> <pre><code>steps:\n  - name: transform_data\n    task: batch\n    inputs:\n      items: [\"file1.csv\", \"file2.csv\", \"file3.csv\"]\n      batch_size: 1\n      task:\n        type: python\n        code: |\n          import pandas as pd\n\n          # Read CSV\n          df = pd.read_csv(item)\n\n          # Transform data\n          result = df.groupby('category').sum()\n\n          # Save result\n          output_file = f\"{item}.result.json\"\n          result.to_json(output_file)\n\n          return {\n              'input': item,\n              'output': output_file,\n              'rows': len(df)\n          }\n    outputs: processing_results\n</code></pre>"},{"location":"guide/tasks/batch-tasks/#parallel-processing","title":"Parallel Processing","text":"<p>Execute batches in parallel:</p> <pre><code>steps:\n  - name: parallel_process\n    task: batch\n    inputs:\n      items: [\"url1\", \"url2\", \"url3\", \"url4\"]\n      batch_size: 1\n      parallel: true\n      max_parallel: 2\n      task:\n        type: http_request\n        url: \"{{ item }}\"\n        method: GET\n    outputs: responses\n</code></pre>"},{"location":"guide/tasks/batch-tasks/#error-handling","title":"Error Handling","text":"<p>Handle batch processing errors:</p> <pre><code>steps:\n  - name: process_with_errors\n    task: batch\n    inputs:\n      items: [\"item1\", \"item2\", \"item3\"]\n      continue_on_error: true\n      on_item_error:\n        task: echo\n        inputs:\n          message: \"Failed to process {{ item }}: {{ error }}\"\n      task:\n        type: shell\n        command: \"process_item.sh {{ item }}\"\n    outputs: results\n</code></pre>"},{"location":"guide/tasks/batch-tasks/#best-practices_1","title":"Best Practices","text":"<ol> <li>Batch Size</li> <li>Choose appropriate batch sizes</li> <li>Consider memory usage</li> <li> <p>Balance throughput and resource usage</p> </li> <li> <p>Parallel Processing</p> </li> <li>Set reasonable max_parallel limits</li> <li>Monitor system resources</li> <li> <p>Handle concurrent access</p> </li> <li> <p>Error Handling</p> </li> <li>Implement proper error recovery</li> <li>Log failed items</li> <li> <p>Consider retry strategies</p> </li> <li> <p>Performance</p> </li> <li>Optimize individual item processing</li> <li>Use efficient data structures</li> <li>Monitor processing times</li> </ol>"},{"location":"guide/tasks/batch-tasks/#examples","title":"Examples","text":""},{"location":"guide/tasks/batch-tasks/#file-processing","title":"File Processing","text":"<pre><code>steps:\n  - name: process_files\n    task: batch\n    inputs:\n      # Get list of files\n      items: $(ls data/*.csv)\n      batch_size: 5\n      parallel: true\n      task:\n        type: python\n        code: |\n          import pandas as pd\n          from pathlib import Path\n\n          # Read input file\n          df = pd.read_csv(item)\n\n          # Process data\n          result = df.groupby('category').agg({\n              'value': ['sum', 'mean', 'count']\n          })\n\n          # Save result\n          output_file = Path(item).with_suffix('.json')\n          result.to_json(output_file)\n\n          return {\n              'file': item,\n              'records': len(df),\n              'output': str(output_file)\n          }\n    outputs: processing_results\n</code></pre>"},{"location":"guide/tasks/batch-tasks/#api-requests","title":"API Requests","text":"<pre><code>steps:\n  - name: fetch_data\n    task: batch\n    inputs:\n      items: [\"user1\", \"user2\", \"user3\"]\n      batch_size: 2\n      parallel: true\n      max_parallel: 3\n      task:\n        type: http_request\n        url: \"https://api.example.com/users/{{ item }}\"\n        method: GET\n        headers:\n          Authorization: \"Bearer {{ env.API_TOKEN }}\"\n        retry:\n          max_attempts: 3\n          delay: 1\n    outputs: user_data\n</code></pre>"},{"location":"guide/tasks/batch-tasks/#data-transformation","title":"Data Transformation","text":"<pre><code>steps:\n  - name: transform_records\n    task: batch\n    inputs:\n      items: {{ input_records }}\n      batch_size: 100\n      task:\n        type: python\n        code: |\n          def transform_record(record):\n              return {\n                  'id': record['id'],\n                  'name': record['name'].upper(),\n                  'score': float(record['score']),\n                  'grade': 'A' if float(record['score']) &gt;= 90 else 'B'\n              }\n\n          # Transform batch of records\n          return [transform_record(r) for r in item]\n    outputs: transformed_data\n</code></pre>"},{"location":"guide/tasks/batch-tasks/#database-operations","title":"Database Operations","text":"<pre><code>steps:\n  - name: update_records\n    task: batch\n    inputs:\n      items: {{ records_to_update }}\n      batch_size: 50\n      parallel: false  # Sequential for database operations\n      task:\n        type: python\n        code: |\n          import psycopg2\n          from psycopg2.extras import execute_batch\n\n          # Connect to database\n          conn = psycopg2.connect(env.DB_URL)\n          cur = conn.cursor()\n\n          try:\n              # Prepare statement\n              stmt = \"\"\"\n                  UPDATE users\n                  SET status = %(status)s,\n                      updated_at = NOW()\n                  WHERE id = %(id)s\n              \"\"\"\n\n              # Execute batch update\n              execute_batch(cur, stmt, item)\n              conn.commit()\n\n              return {\n                  'updated': len(item),\n                  'status': 'success'\n              }\n          finally:\n              cur.close()\n              conn.close()\n    outputs: update_results\n</code></pre>"},{"location":"guide/tasks/file-operations/","title":"File Operations","text":"<p>File operations provide a comprehensive set of tasks for managing files and their contents, supporting various formats including plain text, JSON, and YAML.</p>"},{"location":"guide/tasks/file-operations/#available-operations","title":"Available Operations","text":""},{"location":"guide/tasks/file-operations/#basic-file-operations","title":"Basic File Operations","text":""},{"location":"guide/tasks/file-operations/#write_file","title":"write_file","text":"<p>Writes content to a file: <pre><code>steps:\n  create_file:\n    type: file\n    operation: write_file\n    inputs:\n      path: output.txt\n      content: \"Hello World\"\n      mode: \"w\"  # w=write (default), a=append\n      encoding: utf-8\n</code></pre></p>"},{"location":"guide/tasks/file-operations/#read_file","title":"read_file","text":"<p>Reads content from a file: <pre><code>steps:\n  read_content:\n    type: file\n    operation: read_file\n    inputs:\n      path: input.txt\n      encoding: utf-8\n</code></pre></p>"},{"location":"guide/tasks/file-operations/#append_file","title":"append_file","text":"<p>Appends content to an existing file: <pre><code>steps:\n  append_content:\n    type: file\n    operation: append_file\n    inputs:\n      path: log.txt\n      content: \"New log entry\"\n      encoding: utf-8\n</code></pre></p>"},{"location":"guide/tasks/file-operations/#copy_file","title":"copy_file","text":"<p>Copies a file to a new location: <pre><code>steps:\n  backup_file:\n    type: file\n    operation: copy_file\n    inputs:\n      source: config.yaml\n      destination: backups/config.yaml\n      create_dirs: true\n</code></pre></p>"},{"location":"guide/tasks/file-operations/#move_file","title":"move_file","text":"<p>Moves/renames a file: <pre><code>steps:\n  rename_file:\n    type: file\n    operation: move_file\n    inputs:\n      source: old_name.txt\n      destination: new_name.txt\n</code></pre></p>"},{"location":"guide/tasks/file-operations/#delete_file","title":"delete_file","text":"<p>Deletes a file: <pre><code>steps:\n  cleanup:\n    type: file\n    operation: delete_file\n    inputs:\n      path: temporary.txt\n      ignore_missing: true\n</code></pre></p>"},{"location":"guide/tasks/file-operations/#json-operations","title":"JSON Operations","text":""},{"location":"guide/tasks/file-operations/#read_json","title":"read_json","text":"<p>Reads and parses JSON file: <pre><code>steps:\n  load_config:\n    type: file\n    operation: read_json\n    inputs:\n      path: config.json\n      encoding: utf-8\n</code></pre></p>"},{"location":"guide/tasks/file-operations/#write_json","title":"write_json","text":"<p>Writes data as JSON: <pre><code>steps:\n  save_config:\n    type: file\n    operation: write_json\n    inputs:\n      path: config.json\n      content:\n        name: example\n        version: 1.0\n      indent: 2\n      sort_keys: true\n</code></pre></p>"},{"location":"guide/tasks/file-operations/#yaml-operations","title":"YAML Operations","text":""},{"location":"guide/tasks/file-operations/#read_yaml","title":"read_yaml","text":"<p>Reads and parses YAML file: <pre><code>steps:\n  load_yaml_config:\n    type: file\n    operation: read_yaml\n    inputs:\n      path: config.yaml\n      encoding: utf-8\n</code></pre></p>"},{"location":"guide/tasks/file-operations/#write_yaml","title":"write_yaml","text":"<p>Writes data as YAML: <pre><code>steps:\n  save_yaml_config:\n    type: file\n    operation: write_yaml\n    inputs:\n      path: config.yaml\n      content:\n        name: example\n        version: 1.0\n      default_flow_style: false\n</code></pre></p>"},{"location":"guide/tasks/file-operations/#common-parameters","title":"Common Parameters","text":""},{"location":"guide/tasks/file-operations/#path-handling","title":"Path Handling","text":"<ul> <li><code>path</code>: Target file path</li> <li><code>source</code>: Source file path for copy/move operations</li> <li><code>destination</code>: Destination path for copy/move operations</li> <li><code>create_dirs</code>: Create parent directories if missing (default: false)</li> </ul>"},{"location":"guide/tasks/file-operations/#content-options","title":"Content Options","text":"<ul> <li><code>content</code>: Content to write</li> <li><code>encoding</code>: File encoding (default: utf-8)</li> <li><code>mode</code>: Write mode (w=write, a=append)</li> </ul>"},{"location":"guide/tasks/file-operations/#error-handling","title":"Error Handling","text":"<ul> <li><code>ignore_missing</code>: Don't fail if file is missing (default: false)</li> <li><code>overwrite</code>: Allow overwriting existing files (default: false)</li> <li><code>backup</code>: Create backup before modifying (default: false)</li> </ul>"},{"location":"guide/tasks/file-operations/#format-specific-options","title":"Format-Specific Options","text":"<ul> <li>JSON:</li> <li><code>indent</code>: Indentation level</li> <li><code>sort_keys</code>: Sort dictionary keys</li> <li>YAML:</li> <li><code>default_flow_style</code>: YAML flow style</li> <li><code>explicit_start</code>: Include document start marker</li> </ul>"},{"location":"guide/tasks/file-operations/#examples","title":"Examples","text":""},{"location":"guide/tasks/file-operations/#complex-file-operations","title":"Complex File Operations","text":""},{"location":"guide/tasks/file-operations/#file-processing-pipeline","title":"File Processing Pipeline","text":"<pre><code>steps:\n  read_input:\n    type: file\n    operation: read_json\n    inputs:\n      path: input.json\n\n  transform_data:\n    type: template\n    inputs:\n      template: |\n        name: {{ data.name }}\n        version: {{ data.version }}\n        updated: {{ now() }}\n      variables:\n        data: \"{{ steps.read_input.result }}\"\n\n  save_output:\n    type: file\n    operation: write_yaml\n    inputs:\n      path: output.yaml\n      content: \"{{ steps.transform_data.result }}\"\n</code></pre>"},{"location":"guide/tasks/file-operations/#backup-and-update","title":"Backup and Update","text":"<pre><code>steps:\n  backup_config:\n    type: file\n    operation: copy_file\n    inputs:\n      source: config.yaml\n      destination: \"config.yaml.{{ date('YYYYMMDD') }}\"\n\n  update_config:\n    type: file\n    operation: write_yaml\n    inputs:\n      path: config.yaml\n      content:\n        updated_at: \"{{ now() }}\"\n        settings: \"{{ steps.backup_config.result }}\"\n</code></pre>"},{"location":"guide/tasks/file-operations/#best-practices","title":"Best Practices","text":"<ol> <li>Path Handling:</li> <li>Use absolute paths when working directory might change</li> <li>Enable <code>create_dirs</code> for new file locations</li> <li> <p>Use path validation and normalization</p> </li> <li> <p>Error Handling:</p> </li> <li>Set appropriate <code>ignore_missing</code> flags</li> <li>Use <code>backup</code> for critical files</li> <li> <p>Validate file existence before operations</p> </li> <li> <p>Content Management:</p> </li> <li>Choose appropriate encodings</li> <li>Validate content before writing</li> <li> <p>Use proper indentation for structured formats</p> </li> <li> <p>Security:</p> </li> <li>Validate file paths</li> <li>Restrict file permissions</li> <li> <p>Handle sensitive data appropriately</p> </li> <li> <p>Performance:</p> </li> <li>Use appropriate file modes</li> <li>Handle large files efficiently</li> <li>Clean up temporary files</li> </ol>"},{"location":"guide/tasks/file-operations/#file-check-task","title":"File Check Task","text":"<p>The <code>file_check</code> task validates file existence and permissions.</p>"},{"location":"guide/tasks/file-operations/#parameters","title":"Parameters","text":"<ul> <li><code>path</code> (string, required): Path to the file to check</li> <li><code>required</code> (boolean, default: true): Whether the file must exist</li> <li><code>readable</code> (boolean, default: true): Check if file is readable</li> <li><code>writable</code> (boolean, default: false): Check if file is writable</li> <li><code>extension</code> (string, optional): Expected file extension</li> </ul>"},{"location":"guide/tasks/file-operations/#example","title":"Example","text":"<pre><code>- name: validate_input\n  task: file_check\n  params:\n    path: \"{{ input_file }}\"\n    required: true\n    readable: true\n    extension: \".csv\"\n</code></pre>"},{"location":"guide/tasks/file-operations/#write-file-task","title":"Write File Task","text":"<p>The <code>write_file</code> task writes content to a file.</p>"},{"location":"guide/tasks/file-operations/#parameters_1","title":"Parameters","text":"<ul> <li><code>file_path</code> (string, required): Path where to write the file</li> <li><code>content</code> (string, required): Content to write</li> <li><code>mode</code> (string, default: \"w\"): File open mode (\"w\" or \"a\")</li> <li><code>encoding</code> (string, default: \"utf-8\"): File encoding</li> </ul>"},{"location":"guide/tasks/file-operations/#example_1","title":"Example","text":"<pre><code>- name: save_output\n  task: write_file\n  params:\n    file_path: \"output/result.txt\"\n    content: \"{{ process_result }}\"\n    mode: \"w\"\n    encoding: \"utf-8\"\n</code></pre>"},{"location":"guide/tasks/file-operations/#copy-file-task","title":"Copy File Task","text":"<p>The <code>copy_file</code> task copies files from one location to another.</p>"},{"location":"guide/tasks/file-operations/#parameters_2","title":"Parameters","text":"<ul> <li><code>source</code> (string, required): Source file path</li> <li><code>destination</code> (string, required): Destination file path</li> <li><code>overwrite</code> (boolean, default: false): Whether to overwrite existing files</li> </ul>"},{"location":"guide/tasks/file-operations/#example_2","title":"Example","text":"<pre><code>- name: backup_data\n  task: copy_file\n  params:\n    source: \"data/input.csv\"\n    destination: \"backup/input_{{ current_timestamp }}.csv\"\n    overwrite: true\n</code></pre>"},{"location":"guide/tasks/file-operations/#delete-file-task","title":"Delete File Task","text":"<p>The <code>delete_file</code> task deletes files.</p>"},{"location":"guide/tasks/file-operations/#parameters_3","title":"Parameters","text":"<ul> <li><code>path</code> (string, required): Path to the file to delete</li> <li><code>ignore_missing</code> (boolean, default: true): Don't error if file doesn't exist</li> </ul>"},{"location":"guide/tasks/file-operations/#example_3","title":"Example","text":"<pre><code>- name: cleanup_temp\n  task: delete_file\n  params:\n    path: \"{{ temp_file }}\"\n    ignore_missing: true\n</code></pre>"},{"location":"guide/tasks/file-operations/#directory-operations","title":"Directory Operations","text":""},{"location":"guide/tasks/file-operations/#create-directory","title":"Create Directory","text":"<p>The <code>mkdir</code> task creates directories.</p> <pre><code>- name: setup_dirs\n  task: mkdir\n  params:\n    path: \"output/reports\"\n    parents: true  # Create parent directories if needed\n    exist_ok: true  # Don't error if directory exists\n</code></pre>"},{"location":"guide/tasks/file-operations/#list-directory","title":"List Directory","text":"<p>The <code>list_dir</code> task lists directory contents.</p> <pre><code>- name: find_inputs\n  task: list_dir\n  params:\n    path: \"data\"\n    pattern: \"*.csv\"\n    recursive: true\n  output_var: input_files\n</code></pre>"},{"location":"guide/tasks/python-tasks/","title":"Python Tasks","text":"<p>The YAML Workflow Engine allows you to execute Python code directly in your workflows using the <code>python</code> task.</p> <p>Python tasks allow you to execute Python functions within your workflows. These tasks can accept parameters, which support Jinja2 template substitution (see Templating Guide for details).</p>"},{"location":"guide/tasks/python-tasks/#task-configuration","title":"Task Configuration","text":""},{"location":"guide/tasks/python-tasks/#required-fields","title":"Required Fields","text":"<p>Either <code>code</code> or <code>operation</code> must be specified for a Python task:</p> <pre><code>steps:\n  - name: example_task\n    task: python\n    code: |  # Either specify code...\n      result = x * 2\n\n  - name: another_task\n    task: python\n    operation: multiply  # ...or specify an operation\n    inputs:\n      a: 5\n      b: 3\n</code></pre> <p>Omitting both will raise a ValueError with the message \"Either code or operation must be specified for Python task\".</p>"},{"location":"guide/tasks/python-tasks/#result-handling","title":"Result Handling","text":""},{"location":"guide/tasks/python-tasks/#setting-task-results","title":"Setting Task Results","text":"<p>There are two ways a Python task can produce a result:</p> <ol> <li> <p>Explicit Result Assignment (Recommended)    <pre><code>steps:\n  - name: calculate\n    task: python\n    code: |\n      x = float(input_value)\n      result = x * 2  # Explicitly assign to 'result' variable\n    inputs:\n      input_value: \"5.0\"\n</code></pre></p> </li> <li> <p>Last Expression Value (Fallback)    <pre><code>steps:\n  - name: calculate\n    task: python\n    code: |\n      x = float(input_value)\n      x * 2  # Last expression's value becomes the result\n    inputs:\n      input_value: \"5.0\"\n</code></pre></p> </li> </ol>"},{"location":"guide/tasks/python-tasks/#important-notes-on-result-handling","title":"Important Notes on Result Handling","text":"<ol> <li>Explicit Assignment</li> <li>Always prefer explicitly assigning to the <code>result</code> variable</li> <li>The final value of <code>result</code> will be stored</li> <li> <p>Multiple assignments are allowed; the last one wins    <pre><code>code: |\n  result = initial_value\n  # ... some processing ...\n  result = final_value  # This value will be stored\n</code></pre></p> </li> <li> <p>Last Expression Fallback</p> </li> <li>Only used if no <code>result</code> variable is set</li> <li>Must be a valid expression, not just an assignment</li> <li> <p>Not recommended for complex code    <pre><code>code: |\n  x = 5        # Assignment - not used as result\n  y = 3        # Assignment - not used as result\n  x * y        # Expression - this becomes the result\n</code></pre></p> </li> <li> <p>No Result Cases</p> </li> <li>If no <code>result</code> is set and no valid last expression exists, result will be <code>None</code></li> <li> <p>Comments and empty lines are ignored    <pre><code>code: |\n  x = 5  # Just assignments\n  y = 3  # No result set\n  # Final line is a comment\n  # Result will be None\n</code></pre></p> </li> <li> <p>Conditional Results</p> </li> <li>Results can be set conditionally</li> <li>The final value of <code>result</code> is used, regardless of where it was set    <pre><code>code: |\n  if condition:\n      result = value1\n  else:\n      result = value2\n</code></pre></li> </ol>"},{"location":"guide/tasks/python-tasks/#accessing-results-in-other-tasks","title":"Accessing Results in Other Tasks","text":"<p>Task results are stored in the workflow context and can be accessed by subsequent tasks:</p> <pre><code>steps:\n  - name: first_task\n    task: python\n    code: |\n      result = calculate_something()\n\n  - name: second_task\n    task: python\n    code: |\n      # Access previous task's result\n      previous_result = context['execution_state']['step_outputs']['first_task']['result']\n      result = process_further(previous_result)\n</code></pre>"},{"location":"guide/tasks/python-tasks/#return-values","title":"Return Values","text":"<p>Results are captured through the <code>result</code> variable assignment: - Simple types (str, int, float, bool) - Lists and dictionaries - JSON-serializable objects</p> <pre><code>steps:\n  - name: analyze\n    task: python\n    code: |\n      result = {\n          'status': 'success',\n          'metrics': {\n              'mean': sum(values) / len(values),\n              'count': len(values)\n          }\n      }\n    inputs:\n      values: [1, 2, 3, 4, 5]\n    outputs: analysis\n</code></pre>"},{"location":"guide/tasks/python-tasks/#error-handling","title":"Error Handling","text":"<p>Python exceptions are caught and handled:</p> <pre><code>steps:\n  - name: validate\n    task: python\n    code: |\n      if not isinstance(data, dict):\n          result = {'valid': False, 'error': 'Input must be a dictionary'}\n      else:\n          result = {'valid': True}\n    inputs:\n      data: \"{{ input_data }}\"\n    on_error:\n      action: continue\n      message: \"Validation failed: {{ error }}\"\n</code></pre>"},{"location":"guide/tasks/python-tasks/#task-types","title":"Task Types","text":""},{"location":"guide/tasks/python-tasks/#execute-code","title":"Execute Code","text":"<p>Run arbitrary Python code:</p> <pre><code>task: python\ncode: |\n  # Your Python code here\n  result = calculated_value\n</code></pre>"},{"location":"guide/tasks/python-tasks/#predefined-operations","title":"Predefined Operations","text":"<p>The Python task includes several predefined operations:</p>"},{"location":"guide/tasks/python-tasks/#multiply","title":"Multiply","text":"<p>Multiply two numbers: <pre><code>task: python\noperation: multiply\ninputs:\n  a: 5\n  b: 3\noutputs: product  # Returns 15\n</code></pre></p>"},{"location":"guide/tasks/python-tasks/#divide","title":"Divide","text":"<p>Divide two numbers with error handling: <pre><code>task: python\noperation: divide\ninputs:\n  a: 10\n  b: 2\noutputs: quotient  # Returns 5\n</code></pre></p>"},{"location":"guide/tasks/python-tasks/#print-variables","title":"Print Variables","text":"<p>Debug task by printing available variables: <pre><code>task: python\noperation: print_vars\n</code></pre></p>"},{"location":"guide/tasks/python-tasks/#configuration-options","title":"Configuration Options","text":""},{"location":"guide/tasks/python-tasks/#basic-configuration","title":"Basic Configuration","text":"<pre><code>steps:\n  - name: python_task\n    task: python\n    description: \"Execute Python code\"\n    code: string | null        # Python code to execute\n    operation: string | null   # Predefined operation to run\n    inputs: object            # Input variables\n    outputs: string | object  # Where to store results\n    packages: [string]        # Additional packages to import\n    timeout: int             # Execution timeout in seconds\n</code></pre>"},{"location":"guide/tasks/python-tasks/#input-options","title":"Input Options","text":"<p>The task accepts inputs in various formats:</p> <pre><code>inputs:\n  # Simple values\n  x: 42\n  text: \"Hello\"\n  flag: true\n\n  # Template variables\n  data: \"{{ previous_step.output }}\"\n  config: \"{{ params.settings }}\"\n\n  # Lists and dictionaries\n  items: [1, 2, 3]\n  options: \n    key1: value1\n    key2: value2\n</code></pre>"},{"location":"guide/tasks/python-tasks/#output-options","title":"Output Options","text":"<p>Results can be captured in different ways:</p> <pre><code># Single variable\noutputs: result_var\n\n# Multiple outputs\noutputs:\n  data: result.data\n  status: result.status\n  count: result.count\n\n# Conditional outputs\noutputs:\n  success: \"result.get('success', False)\"\n  error: \"result.get('error', '')\"\n</code></pre>"},{"location":"guide/tasks/python-tasks/#features","title":"Features","text":""},{"location":"guide/tasks/python-tasks/#code-execution","title":"Code Execution","text":"<p>The <code>python</code> task executes Python code in an isolated environment with: - Access to workflow context variables - Standard Python library - Additional installed packages - Error handling and output capture</p>"},{"location":"guide/tasks/python-tasks/#input-variables","title":"Input Variables","text":"<p>Access input variables in your Python code:</p> <pre><code>steps:\n  - name: calculate\n    task: python\n    code: |\n      x = float(x)\n      y = float(y)\n      return x * y\n    inputs:\n      x: \"{{ params.value_x }}\"\n      y: \"{{ params.value_y }}\"\n    outputs: product\n</code></pre>"},{"location":"guide/tasks/python-tasks/#return-values_1","title":"Return Values","text":"<p>Return values are automatically captured and can be: - Simple types (str, int, float, bool) - Lists and dictionaries - JSON-serializable objects</p> <pre><code>steps:\n  - name: analyze\n    task: python\n    code: |\n      return {\n          'status': 'success',\n          'metrics': {\n              'mean': sum(values) / len(values),\n              'count': len(values)\n          }\n      }\n    inputs:\n      values: [1, 2, 3, 4, 5]\n    outputs: analysis\n</code></pre>"},{"location":"guide/tasks/python-tasks/#error-handling_1","title":"Error Handling","text":"<p>Python exceptions are caught and handled:</p> <pre><code>steps:\n  - name: validate\n    task: python\n    code: |\n      if not isinstance(data, dict):\n          raise ValueError(\"Input must be a dictionary\")\n      return {'valid': True}\n    inputs:\n      data: \"{{ input_data }}\"\n    on_error:\n      action: continue\n      message: \"Validation failed: {{ error }}\"\n</code></pre>"},{"location":"guide/tasks/python-tasks/#package-management","title":"Package Management","text":"<p>Specify additional packages to import:</p> <pre><code>steps:\n  - name: process_data\n    task: python\n    packages: \n      - pandas\n      - numpy\n      - scikit-learn\n    code: |\n      import pandas as pd\n      import numpy as np\n      from sklearn.preprocessing import StandardScaler\n\n      # Process data using imported packages\n      df = pd.DataFrame(data)\n      scaled = StandardScaler().fit_transform(df)\n      return scaled.tolist()\n    inputs:\n      data: \"{{ raw_data }}\"\n    outputs: processed_data\n</code></pre>"},{"location":"guide/tasks/python-tasks/#best-practices","title":"Best Practices","text":"<ol> <li>Result Assignment</li> <li>Always explicitly assign to the <code>result</code> variable</li> <li>Don't rely on last expression behavior</li> <li> <p>Use clear and descriptive variable names    <pre><code>code: |\n  # Good\n  result = calculate_total(values)\n\n  # Avoid\n  calculate_total(values)  # Relying on last expression\n</code></pre></p> </li> <li> <p>Error Handling</p> </li> <li>Use try/except blocks when needed</li> <li> <p>Set appropriate result values for error cases    <pre><code>code: |\n  try:\n      value = process_data(input_data)\n      result = {\"status\": \"success\", \"value\": value}\n  except Exception as e:\n      result = {\"status\": \"error\", \"message\": str(e)}\n</code></pre></p> </li> <li> <p>Type Safety</p> </li> <li>Convert input strings to appropriate types</li> <li> <p>Validate inputs before processing    <pre><code>code: |\n  # Convert and validate inputs\n  try:\n      x = float(x)\n      y = float(y)\n      if x &lt;= 0 or y &lt;= 0:\n          result = {\"error\": \"Values must be positive\"}\n      else:\n          result = {\"value\": x * y}\n  except ValueError:\n      result = {\"error\": \"Invalid number format\"}\n</code></pre></p> </li> <li> <p>Context Access</p> </li> <li>Use proper context paths for accessing task outputs</li> <li>Handle missing values gracefully    <pre><code>code: |\n  # Safe context access\n  prev_output = context.get('execution_state', {}).get('step_outputs', {}).get('prev_step', {}).get('result')\n  if prev_output is None:\n      result = {\"error\": \"Previous step output not found\"}\n  else:\n      result = process_output(prev_output)\n</code></pre></li> </ol>"},{"location":"guide/tasks/python-tasks/#examples","title":"Examples","text":""},{"location":"guide/tasks/python-tasks/#data-processing","title":"Data Processing","text":"<pre><code>steps:\n  - name: process_data\n    task: python\n    code: |\n      import json\n\n      # Process input data\n      try:\n          data = json.loads(input_json)\n          processed = [item['value'] * 2 for item in data]\n          result = {\n              \"status\": \"success\",\n              \"count\": len(processed),\n              \"data\": processed\n          }\n      except Exception as e:\n          result = {\n              \"status\": \"error\",\n              \"message\": str(e)\n          }\n    inputs:\n      input_json: \"{{ previous_step.output }}\"\n</code></pre>"},{"location":"guide/tasks/python-tasks/#conditional-processing","title":"Conditional Processing","text":"<pre><code>steps:\n  - name: conditional_calc\n    task: python\n    code: |\n      value = float(input_value)\n\n      if value &lt; 0:\n          result = {\n              \"status\": \"error\",\n              \"message\": \"Value must be positive\"\n          }\n      elif value &lt; 10:\n          result = {\n              \"status\": \"success\",\n              \"category\": \"small\",\n              \"processed\": value * 2\n          }\n      else:\n          result = {\n              \"status\": \"success\",\n              \"category\": \"large\",\n              \"processed\": value * 1.5\n          }\n    inputs:\n      input_value: \"{{ params.value }}\"\n</code></pre>"},{"location":"guide/tasks/python-tasks/#data-transformation","title":"Data Transformation","text":"<pre><code>steps:\n  - name: transform_data\n    task: python\n    code: |\n      def transform_record(record):\n          return {\n              'id': record['id'],\n              'name': record['name'].upper(),\n              'score': float(record['score']),\n              'grade': 'A' if float(record['score']) &gt;= 90 else 'B'\n          }\n\n      # Transform all records\n      result = [transform_record(r) for r in records]\n    inputs:\n      records: \"{{ input_records }}\"\n    outputs: transformed_data\n</code></pre>"},{"location":"guide/tasks/python-tasks/#file-processing","title":"File Processing","text":"<pre><code>steps:\n  - name: process_csv\n    task: python\n    code: |\n      import csv\n      from io import StringIO\n\n      # Parse CSV data\n      reader = csv.DictReader(StringIO(csv_content))\n      data = list(reader)\n\n      # Calculate statistics\n      values = [float(row['value']) for row in data]\n      result = {\n          'count': len(values),\n          'sum': sum(values),\n          'average': sum(values) / len(values)\n      }\n    inputs:\n      csv_content: \"{{ steps.read_file.outputs.content }}\"\n    outputs: statistics\n</code></pre>"},{"location":"guide/tasks/python-tasks/#api-integration","title":"API Integration","text":"<pre><code>steps:\n  - name: process_api_data\n    task: python\n    code: |\n      import json\n      import urllib.parse\n\n      # Process API response\n      data = json.loads(api_response)\n\n      # Extract and transform data\n      items = data.get('items', [])\n      processed = [{\n          'id': item['id'],\n          'url': urllib.parse.urljoin(base_url, item['path']),\n          'metadata': item.get('metadata', {})\n      } for item in items]\n\n      result = {\n          'items': processed,\n          'count': len(processed)\n      }\n    inputs:\n      api_response: \"{{ steps.api_call.outputs.response }}\"\n      base_url: \"https://api.example.com\"\n    outputs: processed_data\n</code></pre>"},{"location":"guide/tasks/shell-tasks/","title":"Shell Tasks","text":"<p>Shell tasks allow you to execute commands in a shell environment with variable substitution and output capture capabilities.</p>"},{"location":"guide/tasks/shell-tasks/#basic-usage","title":"Basic Usage","text":"<pre><code>steps:\n  - name: list_files\n    task: shell\n    command: ls -la\n\n  - name: build_project\n    task: shell\n    command: make build\n</code></pre>"},{"location":"guide/tasks/shell-tasks/#configuration","title":"Configuration","text":""},{"location":"guide/tasks/shell-tasks/#basic-configuration","title":"Basic Configuration","text":"<pre><code>steps:\n  - name: shell_task\n    task: shell\n    description: \"Execute a shell command\"\n    command: string           # Required: Command to execute\n</code></pre>"},{"location":"guide/tasks/shell-tasks/#command-execution","title":"Command Execution","text":"<p>The shell task supports: - Command string execution - Variable substitution using Jinja2 templates (see Templating Guide) - Working directory set to workflow workspace - Output capture (stdout) - Error handling with subprocess</p> <p>Example with variable substitution: <pre><code>steps:\n  - name: greet\n    task: shell\n    command: echo \"Hello, {{ user }}\"\n</code></pre></p>"},{"location":"guide/tasks/shell-tasks/#error-handling","title":"Error Handling","text":"<p>The shell task will: - Raise an error if no command is provided - Raise subprocess.CalledProcessError if command returns non-zero exit code - Capture both stdout and stderr - Support standard workflow error handling:</p> <pre><code>steps:\n  - name: risky_command\n    task: shell\n    command: some_command\n    on_error:\n      action: continue\n      message: \"Command failed: {{ error }}\"\n</code></pre>"},{"location":"guide/tasks/shell-tasks/#output-capture","title":"Output Capture","text":"<p>The task captures command output: - stdout is returned as the task result - stderr is captured but not returned - Output is captured as text with UTF-8 encoding</p> <p>Example capturing output: <pre><code>steps:\n  - name: get_version\n    task: shell\n    command: git describe --tags\n    outputs: version\n\n  - name: use_version\n    task: shell\n    command: echo \"Version is {{ steps.get_version.output }}\"\n</code></pre></p>"},{"location":"guide/tasks/shell-tasks/#implementation-details","title":"Implementation Details","text":"<p>The shell task: 1. Accepts a command string 2. Renders the command using Jinja2 template with workflow context 3. Executes the command using subprocess.run with:    - shell=True    - cwd=workspace    - capture_output=True    - text=True    - check=True 4. Returns the command's stdout as the result</p>"},{"location":"guide/tasks/shell-tasks/#examples","title":"Examples","text":""},{"location":"guide/tasks/shell-tasks/#basic-command","title":"Basic Command","text":"<pre><code>steps:\n  - name: simple_command\n    task: shell\n    command: echo \"Hello World\"\n</code></pre>"},{"location":"guide/tasks/shell-tasks/#using-variables","title":"Using Variables","text":"<pre><code>steps:\n  - name: parameterized_command\n    task: shell\n    command: echo \"Building {{ app_name }} version {{ version }}\"\n</code></pre>"},{"location":"guide/tasks/shell-tasks/#capturing-output","title":"Capturing Output","text":"<pre><code>steps:\n  - name: get_status\n    task: shell\n    command: git status --porcelain\n    outputs: status\n\n  - name: show_status\n    task: shell\n    command: echo \"Git status: {{ steps.get_status.output }}\"\n</code></pre>"},{"location":"guide/tasks/shell-tasks/#error-handling_1","title":"Error Handling","text":"<pre><code>steps:\n  - name: may_fail\n    task: shell\n    command: risky_command\n    on_error:\n      action: continue\n      message: \"Command failed with: {{ error }}\"\n      next: cleanup\n</code></pre>"},{"location":"guide/tasks/shell-tasks/#best-practices","title":"Best Practices","text":"<ol> <li>Command Construction</li> <li>Use clear, readable command strings</li> <li>Break long commands across lines with YAML block scalars</li> <li> <p>Quote variable substitutions appropriately</p> </li> <li> <p>Error Handling</p> </li> <li>Add appropriate error handling for commands that may fail</li> <li>Use workflow error handling rather than shell error handling</li> <li> <p>Capture and log error output when needed</p> </li> <li> <p>Output Management</p> </li> <li>Capture output only when needed</li> <li>Process captured output in subsequent steps</li> <li> <p>Consider output encoding for special characters</p> </li> <li> <p>Security</p> </li> <li>Avoid embedding sensitive data in commands</li> <li>Use environment variables or secure parameters</li> <li>Validate and sanitize input variables</li> </ol>"},{"location":"guide/tasks/shell-tasks/#configuration-options","title":"Configuration Options","text":""},{"location":"guide/tasks/shell-tasks/#command-execution_1","title":"Command Execution","text":"<ul> <li><code>command</code>: The shell command to execute (required)</li> <li><code>shell</code>: Shell to use (default: <code>/bin/bash</code> on Unix, <code>cmd.exe</code> on Windows)</li> <li><code>args</code>: List of command arguments (alternative to embedding in command string)</li> </ul>"},{"location":"guide/tasks/shell-tasks/#environment-variables","title":"Environment Variables","text":"<ul> <li><code>env</code>: Dictionary of environment variables to set</li> <li><code>inherit_env</code>: Whether to inherit parent process environment (default: true)</li> <li><code>expand_env</code>: Whether to expand environment variables in command (default: true)</li> </ul>"},{"location":"guide/tasks/shell-tasks/#working-directory","title":"Working Directory","text":"<ul> <li><code>working_dir</code>: Directory to execute command in</li> <li><code>create_dir</code>: Create working directory if it doesn't exist (default: false)</li> </ul>"},{"location":"guide/tasks/shell-tasks/#output-handling","title":"Output Handling","text":"<ul> <li><code>capture_output</code>: Capture command output (default: true)</li> <li><code>output_encoding</code>: Encoding for output capture (default: utf-8)</li> <li><code>stream_output</code>: Stream output in real-time (default: false)</li> <li><code>output_format</code>: Format for captured output (text/json)</li> </ul>"},{"location":"guide/tasks/shell-tasks/#error-handling_2","title":"Error Handling","text":"<ul> <li><code>fail_on_error</code>: Whether to fail workflow on non-zero exit code (default: true)</li> <li><code>ignore_errors</code>: List of acceptable error patterns to ignore</li> <li><code>retry</code>:</li> <li><code>max_attempts</code>: Maximum retry attempts (default: 1)</li> <li><code>delay</code>: Delay between retries in seconds</li> <li><code>backoff_factor</code>: Exponential backoff factor</li> </ul>"},{"location":"guide/tasks/shell-tasks/#examples_1","title":"Examples","text":""},{"location":"guide/tasks/shell-tasks/#basic-command-execution","title":"Basic Command Execution","text":"<pre><code>steps:\n  simple_command:\n    type: shell\n    inputs:\n      command: echo \"Hello World\"\n</code></pre>"},{"location":"guide/tasks/shell-tasks/#environment-variables_1","title":"Environment Variables","text":"<pre><code>steps:\n  env_example:\n    type: shell\n    inputs:\n      command: echo \"Building ${APP_NAME} in ${ENV}\"\n      env:\n        APP_NAME: my-app\n        ENV: production\n</code></pre>"},{"location":"guide/tasks/shell-tasks/#working-directory_1","title":"Working Directory","text":"<pre><code>steps:\n  build_in_dir:\n    type: shell\n    inputs:\n      command: npm run build\n      working_dir: ./frontend\n      create_dir: true\n</code></pre>"},{"location":"guide/tasks/shell-tasks/#output-capture-and-processing","title":"Output Capture and Processing","text":"<pre><code>steps:\n  process_output:\n    type: shell\n    inputs:\n      command: git status --porcelain\n      capture_output: true\n      output_format: text\n\n  use_output:\n    type: shell\n    inputs:\n      command: echo \"Modified files: {{ steps.process_output.result }}\"\n</code></pre>"},{"location":"guide/tasks/shell-tasks/#error-handling-and-retries","title":"Error Handling and Retries","text":"<pre><code>steps:\n  retry_example:\n    type: shell\n    inputs:\n      command: curl https://api.example.com/data\n      retry:\n        max_attempts: 3\n        delay: 5\n        backoff_factor: 2\n      ignore_errors:\n        - \"Connection timed out\"\n</code></pre>"},{"location":"guide/tasks/shell-tasks/#parallel-command-execution","title":"Parallel Command Execution","text":"<pre><code>steps:\n  parallel_tests:\n    type: shell\n    parallel:\n      max_parallel: 4\n    for_each: [\"test1\", \"test2\", \"test3\", \"test4\"]\n    inputs:\n      command: npm run test {{ item }}\n</code></pre>"},{"location":"guide/tasks/shell-tasks/#best-practices_1","title":"Best Practices","text":"<ol> <li>Security:</li> <li>Avoid embedding sensitive data in commands</li> <li>Use environment variables for secrets</li> <li> <p>Validate and sanitize input variables</p> </li> <li> <p>Error Handling:</p> </li> <li>Set appropriate retry policies for unreliable commands</li> <li>Use <code>ignore_errors</code> for known acceptable failures</li> <li> <p>Capture and log error output</p> </li> <li> <p>Output Management:</p> </li> <li>Use <code>capture_output</code> when output needs to be processed</li> <li>Enable <code>stream_output</code> for long-running commands</li> <li> <p>Consider output encoding for non-ASCII content</p> </li> <li> <p>Working Directory:</p> </li> <li>Use absolute paths when working directory might change</li> <li>Enable <code>create_dir</code> when directory creation is expected</li> <li> <p>Clean up temporary directories when done</p> </li> <li> <p>Environment:</p> </li> <li>Use <code>inherit_env</code> carefully in secure environments</li> <li>Document required environment variables</li> <li>Set sensible defaults for optional variables</li> </ol>"},{"location":"guide/tasks/shell-tasks/#features","title":"Features","text":""},{"location":"guide/tasks/shell-tasks/#command-execution_2","title":"Command Execution","text":"<p>The <code>shell</code> task executes commands in a shell environment with: - Variable substitution - Output capture - Error handling - Working directory management</p>"},{"location":"guide/tasks/shell-tasks/#variable-substitution","title":"Variable Substitution","text":"<p>Use double curly braces for variable substitution in commands:</p> <pre><code>steps:\n  - name: build\n    task: shell\n    command: |\n      make build \\\n        VERSION={{ version }} \\\n        TARGET={{ target }} \\\n        DEBUG={{ env.DEBUG }}\n</code></pre>"},{"location":"guide/tasks/shell-tasks/#output-capture_1","title":"Output Capture","text":"<p>Capture command output using shell command substitution:</p> <pre><code>steps:\n  - name: get_version\n    task: shell\n    command: git describe --tags\n    outputs:\n      version: $(git describe --tags)\n      branch: $(git rev-parse --abbrev-ref HEAD)\n</code></pre>"},{"location":"guide/tasks/shell-tasks/#error-handling_3","title":"Error Handling","text":"<p>Handle command failures with retry and error flows:</p> <pre><code>steps:\n  - name: deploy\n    task: shell\n    command: |\n      kubectl apply -f {{ manifest }}\n    retry:\n      max_attempts: 3\n      delay: 5\n    on_error:\n      - task: echo\n        inputs:\n          message: \"Deployment failed: {{ error }}\"\n</code></pre>"},{"location":"guide/tasks/shell-tasks/#working-directory_2","title":"Working Directory","text":"<p>Specify a working directory for command execution:</p> <pre><code>steps:\n  - name: build_docs\n    task: shell\n    command: |\n      mkdocs build\n    working_dir: docs/\n</code></pre>"},{"location":"guide/tasks/shell-tasks/#environment-variables_2","title":"Environment Variables","text":"<p>Access environment variables in commands:</p> <ol> <li> <p>Workflow Variables <pre><code>steps:\n  - name: show_info\n    task: shell\n    command: |\n      echo \"Workflow: {{ workflow_name }}\"\n      echo \"Run: {{ run_number }}\"\n      echo \"Workspace: {{ workspace }}\"\n</code></pre></p> </li> <li> <p>Custom Variables <pre><code>steps:\n  - name: setup_env\n    task: shell\n    command: |\n      export PATH=\"{{ env.CUSTOM_PATH }}:$PATH\"\n      export PYTHONPATH=\"{{ env.PYTHONPATH }}\"\n</code></pre></p> </li> </ol>"},{"location":"guide/tasks/shell-tasks/#best-practices_2","title":"Best Practices","text":"<ol> <li>Command Organization</li> <li>Use multiline commands for clarity</li> <li>Group related commands</li> <li> <p>Add comments for complex operations</p> </li> <li> <p>Error Handling</p> </li> <li>Set appropriate exit codes</li> <li>Use error handling flows</li> <li> <p>Implement retries for flaky commands</p> </li> <li> <p>Security</p> </li> <li>Validate input variables</li> <li>Avoid shell injection</li> <li> <p>Use proper permissions</p> </li> <li> <p>Performance</p> </li> <li>Minimize command execution</li> <li>Use efficient shell operations</li> <li>Consider parallel execution</li> </ol>"},{"location":"guide/tasks/shell-tasks/#examples_2","title":"Examples","text":""},{"location":"guide/tasks/shell-tasks/#file-processing","title":"File Processing","text":"<pre><code>steps:\n  - name: process_files\n    task: shell\n    command: |\n      # Create output directory\n      mkdir -p output/\n\n      # Process each file\n      for file in data/*.csv; do\n        filename=$(basename \"$file\")\n        python process.py \\\n          --input \"$file\" \\\n          --output \"output/${filename%.csv}.json\"\n      done\n    outputs:\n      files: $(ls output/)\n</code></pre>"},{"location":"guide/tasks/shell-tasks/#system-commands","title":"System Commands","text":"<pre><code>steps:\n  - name: system_info\n    task: shell\n    command: |\n      # Collect system information\n      echo \"=== System Info ===\"\n      uname -a\n\n      echo \"=== Memory Usage ===\"\n      free -h\n\n      echo \"=== Disk Usage ===\"\n      df -h\n    outputs:\n      kernel: $(uname -r)\n      memory: $(free -h | awk '/^Mem:/ {print $3}')\n</code></pre>"},{"location":"guide/tasks/shell-tasks/#git-operations","title":"Git Operations","text":"<pre><code>steps:\n  - name: git_ops\n    task: shell\n    command: |\n      # Ensure we're on the right branch\n      git checkout {{ branch }}\n\n      # Update dependencies\n      npm install\n\n      # Build and test\n      npm run build\n      npm test\n\n      # Create release tag\n      git tag -a v{{ version }} -m \"Release {{ version }}\"\n      git push origin v{{ version }}\n    outputs:\n      commit: $(git rev-parse HEAD)\n      tag: v{{ version }}\n</code></pre>"},{"location":"guide/tasks/shell-tasks/#docker-commands","title":"Docker Commands","text":"<pre><code>steps:\n  - name: docker_build\n    task: shell\n    command: |\n      # Build image\n      docker build \\\n        --tag {{ image }}:{{ tag }} \\\n        --build-arg VERSION={{ version }} \\\n        --file Dockerfile \\\n        .\n\n      # Run tests\n      docker run --rm \\\n        -e TEST_MODE=1 \\\n        {{ image }}:{{ tag }} \\\n        npm test\n\n      # Push if tests pass\n      docker push {{ image }}:{{ tag }}\n    outputs:\n      image_id: $(docker images -q {{ image }}:{{ tag }})\n</code></pre>"},{"location":"guide/tasks/shell-tasks/#database-operations","title":"Database Operations","text":"<pre><code>steps:\n  - name: db_backup\n    task: shell\n    command: |\n      # Set timestamp\n      timestamp=$(date +%Y%m%d_%H%M%S)\n\n      # Create backup\n      pg_dump \\\n        -h {{ env.DB_HOST }} \\\n        -U {{ env.DB_USER }} \\\n        -d {{ env.DB_NAME }} \\\n        -F c \\\n        -f \"backup_${timestamp}.dump\"\n\n      # Compress backup\n      gzip \"backup_${timestamp}.dump\"\n\n      # Upload to storage\n      aws s3 cp \\\n        \"backup_${timestamp}.dump.gz\" \\\n        \"s3://{{ env.BACKUP_BUCKET }}/db/\"\n    outputs:\n      backup_file: backup_${timestamp}.dump.gz\n</code></pre>"},{"location":"guide/tasks/template-tasks/","title":"Template Tasks","text":"<p>For a comprehensive guide on templating syntax, features, and best practices, see the Templating Guide.</p>"},{"location":"guide/tasks/template-tasks/#overview","title":"Overview","text":"<pre><code>graph TD\n    A[Template Source] --&gt; B[Template Engine]\n    C[Variables] --&gt; B\n    D[Context] --&gt; B\n    B --&gt; E[Rendered Output]\n\n    subgraph \"Template Features\"\n    F[Variable Substitution]\n    G[Control Structures]\n    H[Filters]\n    I[Error Handling]\n    end\n\n    subgraph \"Variable Sources\"\n    J[Step Inputs]\n    K[Environment]\n    L[Parameters]\n    M[Step Outputs]\n    end</code></pre>"},{"location":"guide/tasks/template-tasks/#template-processing-flow","title":"Template Processing Flow","text":"<pre><code>stateDiagram-v2\n    [*] --&gt; LoadTemplate: Read Template\n    LoadTemplate --&gt; ParseTemplate: Jinja2 Parser\n    ParseTemplate --&gt; ValidateVars: Check Variables\n    ValidateVars --&gt; RenderTemplate: All Vars Present\n    ValidateVars --&gt; ErrorHandling: Missing Vars\n    RenderTemplate --&gt; WriteOutput: Success\n    RenderTemplate --&gt; ErrorHandling: Render Error\n    WriteOutput --&gt; [*]: Complete\n    ErrorHandling --&gt; [*]: Failed</code></pre> <p>Template tasks provide powerful templating capabilities using Jinja2, allowing you to generate files and content with variable substitution and complex logic.</p>"},{"location":"guide/tasks/template-tasks/#basic-usage","title":"Basic Usage","text":"<pre><code>steps:\n  generate_config:\n    type: template\n    inputs:\n      template: |\n        app_name: {{ app_name }}\n        environment: {{ env }}\n        debug: {{ debug | lower }}\n      variables:\n        app_name: my-application\n        env: production\n        debug: True\n      output_file: config.yaml\n</code></pre>"},{"location":"guide/tasks/template-tasks/#configuration-options","title":"Configuration Options","text":""},{"location":"guide/tasks/template-tasks/#template-source","title":"Template Source","text":"<ul> <li><code>template</code>: Inline template string</li> <li><code>template_file</code>: Path to template file</li> <li><code>template_encoding</code>: Template file encoding (default: utf-8)</li> </ul>"},{"location":"guide/tasks/template-tasks/#variable-handling","title":"Variable Handling","text":"<ul> <li><code>variables</code>: Dictionary of variables to use in template</li> <li><code>strict_undefined</code>: Fail on undefined variables (default: true)</li> <li><code>default_value</code>: Default value for undefined variables</li> <li><code>filters</code>: Custom filter functions</li> </ul>"},{"location":"guide/tasks/template-tasks/#output-configuration","title":"Output Configuration","text":"<ul> <li><code>output_file</code>: Path to output file (required)</li> <li><code>output_mode</code>: Write mode (create/append/overwrite)</li> <li><code>output_encoding</code>: Output file encoding (default: utf-8)</li> <li><code>create_dirs</code>: Create parent directories (default: false)</li> </ul>"},{"location":"guide/tasks/template-tasks/#error-handling","title":"Error Handling","text":"<ul> <li><code>ignore_undefined</code>: Ignore undefined variables (default: false)</li> <li><code>strict_mode</code>: Strict template processing (default: true)</li> <li><code>error_on_missing_file</code>: Fail if template file missing (default: true)</li> </ul>"},{"location":"guide/tasks/template-tasks/#template-features","title":"Template Features","text":""},{"location":"guide/tasks/template-tasks/#variable-substitution","title":"Variable Substitution","text":"<pre><code>steps:\n  basic_substitution:\n    type: template\n    inputs:\n      template: \"Hello {{ name }}!\"\n      variables:\n        name: World\n      output_file: greeting.txt\n</code></pre>"},{"location":"guide/tasks/template-tasks/#conditional-logic","title":"Conditional Logic","text":"<pre><code>steps:\n  conditional_template:\n    type: template\n    inputs:\n      template: |\n        {% if env == 'production' %}\n        debug: false\n        logging: error\n        {% else %}\n        debug: true\n        logging: debug\n        {% endif %}\n      variables:\n        env: production\n      output_file: app-config.yaml\n</code></pre>"},{"location":"guide/tasks/template-tasks/#loops-and-iterations","title":"Loops and Iterations","text":"<pre><code>steps:\n  loop_template:\n    type: template\n    inputs:\n      template: |\n        services:\n        {% for service in services %}\n          - name: {{ service.name }}\n            port: {{ service.port }}\n        {% endfor %}\n      variables:\n        services:\n          - name: web\n            port: 8080\n          - name: api\n            port: 3000\n      output_file: docker-compose.yaml\n</code></pre>"},{"location":"guide/tasks/template-tasks/#filters-and-functions","title":"Filters and Functions","text":"<pre><code>steps:\n  filter_example:\n    type: template\n    inputs:\n      template: |\n        username: {{ username | lower }}\n        path: {{ path | basename }}\n        data: {{ data | tojson }}\n      variables:\n        username: JohnDoe\n        path: /path/to/file.txt\n        data:\n          key: value\n      output_file: config.yaml\n</code></pre>"},{"location":"guide/tasks/template-tasks/#template-inheritance","title":"Template Inheritance","text":"<pre><code>steps:\n  base_template:\n    type: template\n    inputs:\n      template_file: base.yaml.j2\n      variables:\n        title: My App\n        content: Hello World\n      output_file: output.yaml\n</code></pre>"},{"location":"guide/tasks/template-tasks/#error-handling-examples","title":"Error Handling Examples","text":""},{"location":"guide/tasks/template-tasks/#undefined-variables","title":"Undefined Variables","text":"<pre><code>steps:\n  strict_variables:\n    type: template\n    inputs:\n      template: \"{{ required_var }}\"\n      variables: {}\n      strict_undefined: true\n      output_file: output.txt\n</code></pre>"},{"location":"guide/tasks/template-tasks/#default-values","title":"Default Values","text":"<pre><code>steps:\n  default_values:\n    type: template\n    inputs:\n      template: \"{{ optional_var | default('fallback') }}\"\n      variables: {}\n      output_file: output.txt\n</code></pre>"},{"location":"guide/tasks/template-tasks/#best-practices","title":"Best Practices","text":"<ol> <li>Template Organization:</li> <li>Use template files for complex templates</li> <li>Implement template inheritance for reusability</li> <li> <p>Keep templates DRY (Don't Repeat Yourself)</p> </li> <li> <p>Variable Management:</p> </li> <li>Document required variables</li> <li>Use descriptive variable names</li> <li>Provide sensible defaults</li> <li> <p>Validate variable types</p> </li> <li> <p>Error Handling:</p> </li> <li>Enable strict mode for development</li> <li>Use default values for optional variables</li> <li>Implement proper error handling</li> <li> <p>Validate template syntax</p> </li> <li> <p>Output Management:</p> </li> <li>Use appropriate file permissions</li> <li>Handle file conflicts gracefully</li> <li>Clean up temporary files</li> <li> <p>Validate output content</p> </li> <li> <p>Security:</p> </li> <li>Sanitize input variables</li> <li>Avoid template injection</li> <li>Use safe defaults</li> <li>Restrict file access</li> </ol>"},{"location":"guide/tasks/template-tasks/#built-in-variables","title":"Built-in Variables","text":"<p>The template task provides access to:</p> <ol> <li>Workflow Variables</li> <li><code>workflow_name</code>: Name of the workflow</li> <li><code>run_number</code>: Current run number</li> <li> <p><code>workspace</code>: Workspace directory path</p> </li> <li> <p>Environment Variables</p> </li> <li> <p>Access using <code>env.VARIABLE_NAME</code></p> </li> <li> <p>Parameters</p> </li> <li> <p>Access using <code>params.PARAM_NAME</code></p> </li> <li> <p>Step Outputs</p> </li> <li>Access using <code>steps.STEP_NAME.outputs.OUTPUT_NAME</code></li> </ol>"},{"location":"guide/tasks/template-tasks/#examples","title":"Examples","text":""},{"location":"guide/tasks/template-tasks/#configuration-file","title":"Configuration File","text":"<pre><code>steps:\n  - name: generate_config\n    task: template\n    template: |\n      # Configuration for {{ env.APP_NAME }}\n      # Generated: {{ timestamp }}\n\n      [database]\n      host = {{ env.DB_HOST }}\n      port = {{ env.DB_PORT }}\n      name = {{ env.DB_NAME }}\n\n      [api]\n      url = {{ env.API_URL }}\n      timeout = {{ env.API_TIMEOUT }}\n\n      [logging]\n      level = {{ env.LOG_LEVEL | default('INFO') }}\n      file = {{ env.LOG_FILE | default('app.log') }}\n    output: config.ini\n</code></pre>"},{"location":"guide/tasks/template-tasks/#html-report","title":"HTML Report","text":"<pre><code>steps:\n  - name: create_report\n    task: template\n    template: |\n      &lt;!DOCTYPE html&gt;\n      &lt;html&gt;\n      &lt;head&gt;\n        &lt;title&gt;{{ title }}&lt;/title&gt;\n        &lt;style&gt;\n          .success { color: green; }\n          .error { color: red; }\n        &lt;/style&gt;\n      &lt;/head&gt;\n      &lt;body&gt;\n        &lt;h1&gt;{{ title }}&lt;/h1&gt;\n        &lt;p&gt;Generated: {{ timestamp }}&lt;/p&gt;\n\n        &lt;h2&gt;Results&lt;/h2&gt;\n        &lt;table&gt;\n          &lt;tr&gt;\n            &lt;th&gt;Test&lt;/th&gt;\n            &lt;th&gt;Status&lt;/th&gt;\n            &lt;th&gt;Duration&lt;/th&gt;\n          &lt;/tr&gt;\n          {% for test in tests %}\n          &lt;tr&gt;\n            &lt;td&gt;{{ test.name }}&lt;/td&gt;\n            &lt;td class=\"{{ test.status }}\"&gt;{{ test.status }}&lt;/td&gt;\n            &lt;td&gt;{{ test.duration }}ms&lt;/td&gt;\n          &lt;/tr&gt;\n          {% endfor %}\n        &lt;/table&gt;\n\n        &lt;h2&gt;Summary&lt;/h2&gt;\n        &lt;ul&gt;\n          &lt;li&gt;Total: {{ tests | length }}&lt;/li&gt;\n          &lt;li&gt;Passed: {{ tests | selectattr('status', 'eq', 'success') | list | length }}&lt;/li&gt;\n          &lt;li&gt;Failed: {{ tests | selectattr('status', 'eq', 'error') | list | length }}&lt;/li&gt;\n        &lt;/ul&gt;\n      &lt;/body&gt;\n      &lt;/html&gt;\n    output: report.html\n</code></pre>"},{"location":"guide/tasks/template-tasks/#email-template","title":"Email Template","text":"<pre><code>steps:\n  - name: prepare_email\n    task: template\n    template: |\n      Subject: {{ subject }}\n      From: {{ sender }}\n      To: {{ recipient }}\n      Content-Type: text/html\n\n      &lt;html&gt;\n      &lt;body&gt;\n        &lt;h2&gt;{{ subject }}&lt;/h2&gt;\n\n        &lt;p&gt;Dear {{ recipient_name }},&lt;/p&gt;\n\n        {% if notification_type == 'alert' %}\n        &lt;p style=\"color: red;\"&gt;\n          Alert: {{ message }}\n        &lt;/p&gt;\n        {% else %}\n        &lt;p&gt;\n          {{ message }}\n        &lt;/p&gt;\n        {% endif %}\n\n        {% if details %}\n        &lt;h3&gt;Details:&lt;/h3&gt;\n        &lt;ul&gt;\n        {% for key, value in details.items() %}\n          &lt;li&gt;&lt;strong&gt;{{ key }}:&lt;/strong&gt; {{ value }}&lt;/li&gt;\n        {% endfor %}\n        &lt;/ul&gt;\n        {% endif %}\n\n        &lt;p&gt;Best regards,&lt;br&gt;{{ sender_name }}&lt;/p&gt;\n      &lt;/body&gt;\n      &lt;/html&gt;\n    output: email.html\n</code></pre>"},{"location":"reference/SUMMARY/","title":"API Reference","text":"<ul> <li>yaml_workflow<ul> <li>cli</li> <li>engine</li> <li>exceptions</li> <li>runner</li> <li>state</li> <li>step</li> <li>tasks<ul> <li>base</li> <li>basic_tasks</li> <li>batch</li> <li>batch_context</li> <li>config</li> <li>error_handling</li> <li>file_tasks</li> <li>file_utils</li> <li>noop</li> <li>python_tasks</li> <li>shell_tasks</li> <li>template_tasks</li> </ul> </li> <li>template</li> <li>types</li> <li>utils<ul> <li>yaml_utils</li> </ul> </li> <li>workspace</li> </ul> </li> </ul>"},{"location":"reference/yaml_workflow/","title":"yaml_workflow","text":""},{"location":"reference/yaml_workflow/#yaml_workflow","title":"<code>yaml_workflow</code>","text":"<p>YAML Workflow Engine - A simple workflow engine using YAML configuration</p>"},{"location":"reference/yaml_workflow/cli/","title":"yaml_workflow.cli","text":""},{"location":"reference/yaml_workflow/cli/#yaml_workflow.cli","title":"<code>yaml_workflow.cli</code>","text":"<p>Command-line interface for the workflow engine.</p>"},{"location":"reference/yaml_workflow/cli/#yaml_workflow.cli-classes","title":"Classes","text":""},{"location":"reference/yaml_workflow/cli/#yaml_workflow.cli.WorkflowArgumentParser","title":"<code>WorkflowArgumentParser</code>","text":"<p>               Bases: <code>ArgumentParser</code></p> <p>Custom argument parser that handles workflow parameters.</p> Source code in <code>src/yaml_workflow/cli.py</code> <pre><code>class WorkflowArgumentParser(argparse.ArgumentParser):\n    \"\"\"Custom argument parser that handles workflow parameters.\"\"\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.workflow_params = []\n\n    def error(self, message):\n        \"\"\"Custom error handling for workflow parameters.\"\"\"\n        if \"unrecognized arguments\" in message:\n            # Check if the unrecognized argument is a parameter\n            args = message.split(\": \")[-1].split()\n            for arg in args:\n                # Skip standard flags like --version, --help\n                if arg in [\"--version\", \"--help\"]:\n                    super().error(message)\n                    return\n                if \"=\" in arg:\n                    self.workflow_params.append(arg)\n                else:\n                    # If it's not a parameter, raise an error\n                    print(\n                        f\"Invalid parameter format: {arg}\\nParameters must be in the format: name=value\",\n                        file=sys.stderr,\n                    )\n                    sys.exit(1)\n        else:\n            super().error(message)\n\n    def parse_args(self, args=None, namespace=None):\n        \"\"\"Parse arguments and collect workflow parameters.\"\"\"\n        self.workflow_params = []\n        args = super().parse_args(args, namespace)\n        if hasattr(args, \"params\"):\n            args.params.extend(self.workflow_params)\n        return args\n</code></pre>"},{"location":"reference/yaml_workflow/cli/#yaml_workflow.cli.WorkflowArgumentParser-functions","title":"Functions","text":""},{"location":"reference/yaml_workflow/cli/#yaml_workflow.cli.WorkflowArgumentParser.error","title":"<code>error(message)</code>","text":"<p>Custom error handling for workflow parameters.</p> Source code in <code>src/yaml_workflow/cli.py</code> <pre><code>def error(self, message):\n    \"\"\"Custom error handling for workflow parameters.\"\"\"\n    if \"unrecognized arguments\" in message:\n        # Check if the unrecognized argument is a parameter\n        args = message.split(\": \")[-1].split()\n        for arg in args:\n            # Skip standard flags like --version, --help\n            if arg in [\"--version\", \"--help\"]:\n                super().error(message)\n                return\n            if \"=\" in arg:\n                self.workflow_params.append(arg)\n            else:\n                # If it's not a parameter, raise an error\n                print(\n                    f\"Invalid parameter format: {arg}\\nParameters must be in the format: name=value\",\n                    file=sys.stderr,\n                )\n                sys.exit(1)\n    else:\n        super().error(message)\n</code></pre>"},{"location":"reference/yaml_workflow/cli/#yaml_workflow.cli.WorkflowArgumentParser.parse_args","title":"<code>parse_args(args=None, namespace=None)</code>","text":"<p>Parse arguments and collect workflow parameters.</p> Source code in <code>src/yaml_workflow/cli.py</code> <pre><code>def parse_args(self, args=None, namespace=None):\n    \"\"\"Parse arguments and collect workflow parameters.\"\"\"\n    self.workflow_params = []\n    args = super().parse_args(args, namespace)\n    if hasattr(args, \"params\"):\n        args.params.extend(self.workflow_params)\n    return args\n</code></pre>"},{"location":"reference/yaml_workflow/cli/#yaml_workflow.cli-functions","title":"Functions","text":""},{"location":"reference/yaml_workflow/cli/#yaml_workflow.cli.clean_workspaces","title":"<code>clean_workspaces(args)</code>","text":"<p>Clean up old workflow runs.</p> Source code in <code>src/yaml_workflow/cli.py</code> <pre><code>def clean_workspaces(args):\n    \"\"\"Clean up old workflow runs.\"\"\"\n    base_dir_path = Path(args.base_dir)\n    if not base_dir_path.exists():\n        print(f\"Base directory not found: {base_dir_path}\", file=sys.stderr)\n        sys.exit(1)\n\n    cutoff = datetime.now() - timedelta(days=args.older_than)\n    pattern = f\"*_run_*\" if not args.workflow else f\"{args.workflow}_run_*\"\n\n    to_delete = []\n    for run_dir in base_dir_path.glob(pattern):\n        if run_dir.is_dir():\n            try:\n                info = get_workspace_info(run_dir)\n                created = datetime.fromisoformat(info[\"created_at\"])\n                if created &lt; cutoff:\n                    to_delete.append((run_dir, info))\n            except Exception as e:\n                print(f\"Warning: Could not process {run_dir}: {e}\", file=sys.stderr)\n\n    if not to_delete:\n        print(\"No old workflow runs to clean up.\")\n        return\n\n    print(\"\\nWorkflow runs to remove:\")\n    total_size = 0\n    for run_dir, info in to_delete:\n        size_mb = info[\"size\"] / (1024 * 1024)\n        total_size += info[\"size\"]\n        age = datetime.now() - datetime.fromisoformat(info[\"created_at\"])\n        print(f\"- {run_dir.name}\")\n        print(f\"  Age: {age.days} days\")\n        print(f\"  Size: {size_mb:.1f} MB\")\n\n    total_size_mb = total_size / (1024 * 1024)\n    print(f\"\\nTotal space to be freed: {total_size_mb:.1f} MB\")\n\n    if not args.dry_run:\n        for run_dir, _ in to_delete:\n            try:\n                shutil.rmtree(run_dir)\n                print(f\"Removed: {run_dir}\")\n            except Exception as e:\n                print(f\"Error removing {run_dir}: {e}\")\n    else:\n        print(\"\\nDry run - no files were deleted\")\n</code></pre>"},{"location":"reference/yaml_workflow/cli/#yaml_workflow.cli.init_project","title":"<code>init_project(args)</code>","text":"<p>Initialize a new project with example workflows.</p> Source code in <code>src/yaml_workflow/cli.py</code> <pre><code>def init_project(args):\n    \"\"\"Initialize a new project with example workflows.\"\"\"\n    try:\n        # Create target directory if it doesn't exist\n        target_dir = Path(args.dir)\n        target_dir.mkdir(parents=True, exist_ok=True)\n\n        # Find examples directory relative to this file's location\n        # Assumes cli.py is in src/yaml_workflow/ and examples is in src/yaml_workflow/examples\n        base_path = Path(__file__).parent\n        examples_dir = base_path / \"examples\"  # Try direct relative path first\n\n        # Fallback: If not found directly, try navigating up (e.g., running from source root)\n        if not examples_dir.is_dir():\n            project_root = base_path.parent  # src/yaml_workflow\n            if (\n                project_root.name == \"yaml_workflow\"\n                and (project_root.parent / \"src\").exists()\n            ):\n                # If running from src/yaml_workflow, go up twice for project root\n                examples_dir = (\n                    project_root.parent / \"src\" / \"yaml_workflow\" / \"examples\"\n                )\n            else:\n                # Assume current structure: src/yaml_workflow/cli.py -&gt; src/yaml_workflow/examples\n                pass  # Keep original examples_dir = base_path / \"examples\"\n\n        if not examples_dir.is_dir():\n            print(\n                f\"Error: Examples directory not found. Looked near: {base_path}\",\n                file=sys.stderr,\n            )\n            sys.exit(1)\n\n        if args.example:\n            # Copy specific example\n            example_file = examples_dir / f\"{args.example}.yaml\"\n            if not example_file.exists():\n                print(\n                    f\"Example '{args.example}' not found in {examples_dir}\",\n                    file=sys.stderr,\n                )\n                sys.exit(1)\n            shutil.copy2(example_file, target_dir)\n            print(\n                f\"Initialized project with example '{example_file.name}' in: {target_dir}\"\n            )\n        else:\n            # Copy all examples\n            copied_any = False\n            for example in examples_dir.glob(\"*.yaml\"):\n                shutil.copy2(example, target_dir)\n                copied_any = True\n\n            if not copied_any:\n                print(\n                    f\"Warning: No example YAML files found in {examples_dir}\",\n                    file=sys.stderr,\n                )\n            else:\n                print(f\"Initialized project with examples in: {target_dir}\")\n\n    except Exception as e:\n        print(f\"Error initializing project: {e}\", file=sys.stderr)\n        sys.exit(1)\n</code></pre>"},{"location":"reference/yaml_workflow/cli/#yaml_workflow.cli.list_workflows","title":"<code>list_workflows(args)</code>","text":"<p>List available workflows.</p> Source code in <code>src/yaml_workflow/cli.py</code> <pre><code>def list_workflows(args):\n    \"\"\"List available workflows.\"\"\"\n    workflow_dir = Path(args.base_dir)\n    if not workflow_dir.exists():\n        print(f\"Directory not found: {workflow_dir}\", file=sys.stderr)\n        sys.exit(1)\n\n    print(\"\\nAvailable workflows:\")\n    # Recursively find all .yaml files\n    found = False\n    for workflow in sorted(workflow_dir.rglob(\"*.yaml\")):\n        try:\n            # Try to load the file to verify it's a valid workflow\n            with open(workflow) as f:\n                content = yaml.safe_load(f)\n\n                # Handle both top-level workflow and direct steps format\n                if isinstance(content, dict):\n                    if \"workflow\" in content:\n                        content = content[\"workflow\"]\n\n                    # Check if it's a valid workflow file\n                    if \"steps\" in content:\n                        name = content.get(\"usage\", {}).get(\"name\") or workflow.stem\n                        desc = content.get(\"usage\", {}).get(\n                            \"description\", \"No description available\"\n                        )\n                        print(f\"\\n- {workflow.relative_to(workflow_dir)}\")\n                        print(f\"  Name: {name}\")\n                        print(f\"  Description: {desc}\")\n                        found = True\n\n        except Exception:\n            # Skip files that can't be parsed as YAML\n            continue\n\n    if not found:\n        print(\n            \"No workflow files found. Workflows should be YAML files containing 'steps' section.\"\n        )\n        print(\n            f\"\\nMake sure you have workflow YAML files in the '{workflow_dir}' directory.\"\n        )\n        print(\"You can specify a different directory with --base-dir option.\")\n    print()\n</code></pre>"},{"location":"reference/yaml_workflow/cli/#yaml_workflow.cli.list_workspaces","title":"<code>list_workspaces(args)</code>","text":"<p>List workflow run directories.</p> Source code in <code>src/yaml_workflow/cli.py</code> <pre><code>def list_workspaces(args):\n    \"\"\"List workflow run directories.\"\"\"\n    base_dir_path = Path(args.base_dir)\n    if not base_dir_path.exists():\n        print(f\"Base directory not found: {base_dir_path}\", file=sys.stderr)\n        sys.exit(1)\n\n    # Get all run directories\n    runs = []\n    pattern = f\"*_run_*\" if not args.workflow else f\"{args.workflow}_run_*\"\n\n    for run_dir in base_dir_path.glob(pattern):\n        if run_dir.is_dir():\n            try:\n                info = get_workspace_info(run_dir)\n                runs.append(\n                    {\n                        \"name\": run_dir.name,\n                        \"created\": datetime.fromisoformat(info[\"created_at\"]),\n                        \"size\": info[\"size\"],\n                        \"files\": info[\"files\"],\n                    }\n                )\n            except Exception as e:\n                print(f\"Warning: Could not get info for {run_dir}: {e}\")\n\n    # Sort by creation time\n    runs.sort(key=lambda x: x[\"created\"], reverse=True)\n\n    if not runs:\n        print(\"No workflow runs found.\")\n        return\n\n    print(\"\\nWorkflow runs:\")\n    for run in runs:\n        size_mb = run[\"size\"] / (1024 * 1024)\n        age = datetime.now() - run[\"created\"]\n        print(f\"- {run['name']}\")\n        print(f\"  Created: {run['created'].isoformat()} ({age.days} days ago)\")\n        print(f\"  Size: {size_mb:.1f} MB\")\n        print(f\"  Files: {run['files']}\")\n    print()\n</code></pre>"},{"location":"reference/yaml_workflow/cli/#yaml_workflow.cli.main","title":"<code>main()</code>","text":"<p>Main entry point for the CLI.</p> Source code in <code>src/yaml_workflow/cli.py</code> <pre><code>def main():\n    \"\"\"Main entry point for the CLI.\"\"\"\n    parser = WorkflowArgumentParser(description=\"YAML Workflow Engine CLI\")\n    parser.formatter_class = argparse.RawDescriptionHelpFormatter\n    parser.description = f\"\"\"YAML Workflow Engine CLI v{__version__}\n\nCommands:\n  run                 Run a workflow\n  list               List available workflows\n  validate           Validate a workflow file\n  workspace          Workspace management commands\n  init               Initialize a new project with example workflows\n\"\"\"\n    parser.add_argument(\n        \"--version\",\n        action=\"version\",\n        version=f\"%(prog)s {__version__}\",\n        help=\"Show program version and exit\",\n    )\n\n    subparsers = parser.add_subparsers(dest=\"command\", help=\"Commands\")\n\n    # Run command\n    run_parser = subparsers.add_parser(\"run\", help=\"Run a workflow\", add_help=True)\n    run_parser.add_argument(\"workflow\", help=\"Path to workflow file\")\n    run_parser.add_argument(\"--workspace\", help=\"Custom workspace directory\")\n    run_parser.add_argument(\n        \"--base-dir\", default=\"runs\", help=\"Base directory for workflow runs\"\n    )\n    run_parser.add_argument(\n        \"--resume\", action=\"store_true\", help=\"Resume workflow from last failed step\"\n    )\n    run_parser.add_argument(\n        \"--start-from\", help=\"Start workflow execution from specified step\"\n    )\n    run_parser.add_argument(\n        \"--skip-steps\", help=\"Comma-separated list of steps to skip during execution\"\n    )\n    run_parser.add_argument(\n        \"--flow\",\n        help=\"Name of the flow to execute (default: use flow specified in workflow file)\",\n    )\n    run_parser.add_argument(\n        \"params\", nargs=\"*\", help=\"Parameters in the format name=value or --name=value\"\n    )\n\n    # List command\n    list_parser = subparsers.add_parser(\"list\", help=\"List available workflows\")\n    list_parser.add_argument(\n        \"--base-dir\", default=\"workflows\", help=\"Base directory containing workflows\"\n    )\n\n    # Validate command\n    validate_parser = subparsers.add_parser(\"validate\", help=\"Validate a workflow file\")\n    validate_parser.add_argument(\"workflow\", help=\"Path to workflow file\")\n\n    # Workspace commands\n    workspace_parser = subparsers.add_parser(\n        \"workspace\", help=\"Workspace management commands\"\n    )\n    workspace_subparsers = workspace_parser.add_subparsers(\n        dest=\"workspace_command\", help=\"Workspace commands\"\n    )\n\n    # Workspace list command\n    workspace_list_parser = workspace_subparsers.add_parser(\n        \"list\", help=\"List workflow run directories\"\n    )\n    workspace_list_parser.add_argument(\n        \"--base-dir\", \"-b\", default=\"runs\", help=\"Base directory for workflow runs\"\n    )\n    workspace_list_parser.add_argument(\n        \"--workflow\", \"-w\", help=\"Filter by workflow name\"\n    )\n\n    # Workspace clean command\n    workspace_clean_parser = workspace_subparsers.add_parser(\n        \"clean\", help=\"Clean up old workflow runs\"\n    )\n    workspace_clean_parser.add_argument(\n        \"--base-dir\", \"-b\", default=\"runs\", help=\"Base directory for workflow runs\"\n    )\n    workspace_clean_parser.add_argument(\n        \"--older-than\", \"-o\", type=int, default=30, help=\"Remove runs older than N days\"\n    )\n    workspace_clean_parser.add_argument(\n        \"--workflow\", \"-w\", help=\"Clean only runs of this workflow\"\n    )\n    workspace_clean_parser.add_argument(\n        \"--dry-run\",\n        \"-n\",\n        action=\"store_true\",\n        help=\"Show what would be deleted without actually deleting\",\n    )\n\n    # Workspace remove command\n    workspace_remove_parser = workspace_subparsers.add_parser(\n        \"remove\", help=\"Remove specific workflow runs\"\n    )\n    workspace_remove_parser.add_argument(\n        \"runs\", nargs=\"+\", help=\"Names of runs to remove\"\n    )\n    workspace_remove_parser.add_argument(\n        \"--base-dir\", \"-b\", default=\"runs\", help=\"Base directory for workflow runs\"\n    )\n    workspace_remove_parser.add_argument(\n        \"--force\", \"-f\", action=\"store_true\", help=\"Don't ask for confirmation\"\n    )\n\n    # Init command\n    init_parser = subparsers.add_parser(\n        \"init\", help=\"Initialize a new project with example workflows\"\n    )\n    init_parser.add_argument(\n        \"--dir\", default=\"workflows\", help=\"Directory to create workflows in\"\n    )\n    init_parser.add_argument(\"--example\", help=\"Specific example workflow to copy\")\n\n    args = parser.parse_args()\n\n    if not args.command:\n        parser.print_help()\n        sys.exit(1)\n\n    try:\n        if args.command == \"run\":\n            run_workflow(args)\n        elif args.command == \"list\":\n            list_workflows(args)\n        elif args.command == \"validate\":\n            validate_workflow(args)\n        elif args.command == \"workspace\":\n            if args.workspace_command == \"list\":\n                list_workspaces(args)\n            elif args.workspace_command == \"clean\":\n                clean_workspaces(args)\n            elif args.workspace_command == \"remove\":\n                remove_workspaces(args)\n            else:\n                workspace_parser.print_help()\n                sys.exit(1)\n        elif args.command == \"init\":\n            init_project(args)\n    except KeyboardInterrupt:\n        print(\"\\nOperation cancelled by user\", file=sys.stderr)\n        sys.exit(1)\n    except Exception as e:\n        print(f\"Error: {str(e)}\", file=sys.stderr)\n        sys.exit(1)\n</code></pre>"},{"location":"reference/yaml_workflow/cli/#yaml_workflow.cli.parse_params","title":"<code>parse_params(args_list: List[str]) -&gt; Dict[str, str]</code>","text":"<p>Parse command line parameters.</p> Source code in <code>src/yaml_workflow/cli.py</code> <pre><code>def parse_params(args_list: List[str]) -&gt; Dict[str, str]:\n    \"\"\"Parse command line parameters.\"\"\"\n    result = {}\n    for arg in args_list:\n        try:\n            name, value = arg.split(\"=\", 1)\n            # Remove leading '--' if present\n            name = name.lstrip(\"-\")\n            result[name.strip()] = value.strip()\n        except ValueError:\n            raise ValueError(\n                f\"Invalid parameter format: {arg}\\nParameters must be in the format: name=value\"\n            )\n    return result\n</code></pre>"},{"location":"reference/yaml_workflow/cli/#yaml_workflow.cli.remove_workspaces","title":"<code>remove_workspaces(args)</code>","text":"<p>Remove specific workflow runs.</p> Source code in <code>src/yaml_workflow/cli.py</code> <pre><code>def remove_workspaces(args):\n    \"\"\"Remove specific workflow runs.\"\"\"\n    base_dir_path = Path(args.base_dir)\n    if not base_dir_path.exists():\n        print(f\"Base directory not found: {base_dir_path}\", file=sys.stderr)\n        sys.exit(1)\n\n    to_remove = []\n    for run_name in args.runs:\n        run_dir = base_dir_path / run_name\n        if not run_dir.exists():\n            print(f\"Warning: Run directory not found: {run_dir}\")\n            continue\n        if not run_dir.is_dir():\n            print(f\"Warning: Not a directory: {run_dir}\", file=sys.stderr)\n            continue\n        to_remove.append(run_dir)\n\n    if not to_remove:\n        print(\"No valid run directories to remove.\")\n        return\n\n    print(\"\\nWorkflow runs to remove:\")\n    total_size = 0\n    for run_dir in to_remove:\n        try:\n            info = get_workspace_info(run_dir)\n            size_mb = info[\"size\"] / (1024 * 1024)\n            total_size += info[\"size\"]\n            print(f\"- {run_dir.name}\")\n            print(f\"  Size: {size_mb:.1f} MB\")\n            print(f\"  Files: {info['files']}\")\n        except Exception as e:\n            print(f\"Warning: Could not get info for {run_dir}: {e}\")\n\n    total_size_mb = total_size / (1024 * 1024)\n    print(f\"\\nTotal space to be freed: {total_size_mb:.1f} MB\")\n\n    if not args.force:\n        response = input(\"\\nAre you sure you want to remove these runs? [y/N] \")\n        if response.lower() != \"y\":\n            print(\"Operation cancelled.\")\n            return\n\n    for run_dir in to_remove:\n        try:\n            shutil.rmtree(run_dir)\n            print(f\"Removed: {run_dir}\")\n        except Exception as e:\n            print(f\"Error removing {run_dir}: {e}\")\n</code></pre>"},{"location":"reference/yaml_workflow/cli/#yaml_workflow.cli.run_workflow","title":"<code>run_workflow(args)</code>","text":"<p>Run a workflow.</p> Source code in <code>src/yaml_workflow/cli.py</code> <pre><code>def run_workflow(args):\n    \"\"\"Run a workflow.\"\"\"\n    try:\n        try:\n            param_dict = parse_params(args.params)\n        except ValueError as e:\n            print(str(e), file=sys.stderr)\n            sys.exit(1)\n\n        # If resuming, check the existing workspace and load metadata first\n        resume_from = None\n        metadata = None\n        if args.resume and args.workspace:\n            workspace_path = Path(args.workspace)\n            if workspace_path.exists():\n                metadata_path = workspace_path / \".workflow_metadata.json\"\n                if metadata_path.exists():\n                    try:\n                        with open(metadata_path) as f:\n                            metadata = json.load(f)\n                    except json.JSONDecodeError as e:\n                        raise ValueError(\n                            f\"Cannot resume: Invalid metadata file format - {str(e)}\"\n                        )\n                    except Exception as e:\n                        raise ValueError(\n                            f\"Cannot resume: Failed to read metadata file - {str(e)}\"\n                        )\n\n                    # Ensure execution_state exists\n                    if \"execution_state\" not in metadata:\n                        raise ValueError(\n                            \"Cannot resume: Invalid metadata format - missing execution_state\"\n                        )\n\n                    # Ensure retry_state exists\n                    if \"retry_state\" not in metadata[\"execution_state\"]:\n                        metadata[\"execution_state\"][\"retry_state\"] = {}\n\n                    # Check if workflow is in failed state\n                    if metadata[\"execution_state\"].get(\"status\") == \"failed\":\n                        failed_step = metadata[\"execution_state\"].get(\"failed_step\")\n                        if failed_step:\n                            resume_from = failed_step[\"step_name\"]\n                            print(\n                                f\"Found failed workflow state, resuming from step: {resume_from}\"\n                            )\n                        else:\n                            raise ValueError(\"No failed step found to resume from.\")\n                    else:\n                        raise ValueError(\n                            \"Cannot resume: workflow is not in failed state\"\n                        )\n                else:\n                    raise ValueError(\"Cannot resume: No workflow metadata found\")\n            else:\n                raise ValueError(\"Cannot resume: Workspace directory not found\")\n\n        # Create workflow engine with loaded metadata\n        engine = WorkflowEngine(\n            workflow=args.workflow,\n            workspace=args.workspace,\n            base_dir=args.base_dir,\n            metadata=metadata,  # Pass loaded metadata to engine\n        )\n\n        # Update parameters\n        if param_dict:\n            print(\"Parameters provided:\")\n            for name, value in param_dict.items():\n                print(f\"  {name}: {value}\")\n\n        # Parse skip steps\n        skip_step_list = []\n        if args.skip_steps:\n            skip_step_list = [step.strip() for step in args.skip_steps.split(\",\")]\n            print(f\"Skipping steps: {', '.join(skip_step_list)}\")\n\n        # Handle start-from and resume logic\n        start_from_step = None\n\n        # Check start-from first (takes precedence)\n        if args.start_from:\n            start_from_step = args.start_from\n            print(f\"Starting workflow from step: {start_from_step}\")\n\n        # Run workflow with appropriate parameters\n        results = engine.run(\n            param_dict,\n            resume_from=resume_from,\n            start_from=start_from_step,\n            skip_steps=skip_step_list,\n            flow=args.flow,\n        )\n\n        # Print completion status\n        print(\"\\n=== Workflow Status ===\")\n        if resume_from:\n            print(f\"\u2713 Workflow resumed from '{resume_from}' and completed successfully\")\n        elif start_from_step:\n            print(\n                f\"\u2713 Workflow started from '{start_from_step}' and completed successfully\"\n            )\n        else:\n            print(\"\u2713 Workflow completed successfully\")\n\n        if skip_step_list:\n            print(f\"\u2022 Skipped steps: {', '.join(skip_step_list)}\")\n        if args.flow:\n            print(f\"\u2022 Flow executed: {args.flow}\")\n\n        # Print step outputs in a clean format\n        if results.get(\"outputs\"):\n            print(\"=== Step Outputs ===\")\n            first_step = True\n            for step_name, output_container in results[\"outputs\"].items():\n                # The actual result is nested under 'result'\n                output_value = output_container.get(\"result\")\n\n                # Skip printing entirely if the actual result is None or empty string\n                if output_value is None or (\n                    isinstance(output_value, str) and not output_value.strip()\n                ):\n                    continue  # Skip printing this step's output section\n\n                # Print step name header (only if output is being printed)\n                if first_step:\n                    print(f\"\u2022 {step_name}:\")\n                    first_step = False\n                else:\n                    print(f\"\\n\u2022 {step_name}:\")  # Add newline before subsequent steps\n\n                # Print the actual output value (potentially multi-line)\n                if isinstance(output_value, str) and \"\\n\" in output_value:\n                    print(output_value)  # Print multi-line strings directly\n                elif isinstance(output_value, dict) or isinstance(output_value, list):\n                    # Pretty print dicts/lists using YAML for readability\n                    print(yaml.dump(output_value, indent=2, default_flow_style=False))\n                else:\n                    print(f\"  {output_value}\")  # Indent simple values\n\n        print(\"\\n=== Workspace Info ===\")\n        print(f\"\u2022 Location: {engine.workspace}\")\n        # Get run number from the workspace metadata\n        run_number = engine.state.metadata.get(\"run_number\", \"unknown\")\n        print(f\"\u2022 Run number: {run_number}\")\n\n    except WorkflowError as e:\n        print(f\"Workflow error: {str(e)}\", file=sys.stderr)\n        sys.exit(1)\n    except Exception as e:\n        print(f\"Error: {str(e)}\", file=sys.stderr)\n        sys.exit(1)\n</code></pre>"},{"location":"reference/yaml_workflow/cli/#yaml_workflow.cli.validate_workflow","title":"<code>validate_workflow(args)</code>","text":"<p>Validate a workflow file.</p> Source code in <code>src/yaml_workflow/cli.py</code> <pre><code>def validate_workflow(args):\n    \"\"\"Validate a workflow file.\"\"\"\n    try:\n        # Just try to create the engine, which will validate the workflow\n        WorkflowEngine(args.workflow)\n        print(\"Workflow validation successful\")\n    except Exception as e:\n        print(f\"Validation failed: {e}\", file=sys.stderr)\n        sys.exit(1)\n</code></pre>"},{"location":"reference/yaml_workflow/engine/","title":"yaml_workflow.engine","text":""},{"location":"reference/yaml_workflow/engine/#yaml_workflow.engine","title":"<code>yaml_workflow.engine</code>","text":"<p>Core workflow engine implementation.</p>"},{"location":"reference/yaml_workflow/engine/#yaml_workflow.engine-classes","title":"Classes","text":""},{"location":"reference/yaml_workflow/engine/#yaml_workflow.engine.RetryStepException","title":"<code>RetryStepException</code>","text":"<p>               Bases: <code>TaskExecutionError</code></p> <p>Indicates a step should be retried.</p> Source code in <code>src/yaml_workflow/engine.py</code> <pre><code>class RetryStepException(TaskExecutionError):\n    \"\"\"Indicates a step should be retried.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/yaml_workflow/engine/#yaml_workflow.engine.WorkflowEngine","title":"<code>WorkflowEngine</code>","text":"<p>Main workflow engine class.</p> Source code in <code>src/yaml_workflow/engine.py</code> <pre><code>class WorkflowEngine:\n    \"\"\"Main workflow engine class.\"\"\"\n\n    def __init__(\n        self,\n        workflow: str | Dict[str, Any],\n        workspace: Optional[str] = None,\n        base_dir: str = \"runs\",\n        metadata: Optional[Dict[str, Any]] = None,\n    ):\n        \"\"\"\n        Initialize the workflow engine.\n\n        Args:\n            workflow: Path to workflow YAML file or workflow definition dictionary\n            workspace: Optional custom workspace directory\n            base_dir: Base directory for workflow runs\n            metadata: Optional pre-loaded metadata for resuming workflows\n\n        Raises:\n            WorkflowError: If workflow file not found or invalid\n        \"\"\"\n        # Load workflow definition\n        if isinstance(workflow, dict):\n            self.workflow = workflow\n            self.workflow_file = None\n        else:\n            self.workflow_file = Path(workflow)\n            if not self.workflow_file.exists():\n                raise WorkflowError(f\"Workflow file not found: {workflow}\")\n\n            # Load workflow from file\n            try:\n                with open(self.workflow_file) as f:\n                    self.workflow = yaml.load(f, Loader=get_safe_loader())\n            except yaml.YAMLError as e:\n                raise WorkflowError(f\"Invalid YAML in workflow file: {e}\")\n\n        # Validate workflow structure\n        if not isinstance(self.workflow, dict):\n            raise WorkflowError(\"Invalid workflow format: root must be a mapping\")\n\n        # Validate required sections\n        if not self.workflow.get(\"steps\") and not self.workflow.get(\"flows\"):\n            raise WorkflowError(\n                \"Invalid workflow file: missing both 'steps' and 'flows' sections\"\n            )\n\n        # Get workflow name\n        self.name = self.workflow.get(\"name\")\n        if not self.name:\n            if self.workflow_file:\n                self.name = self.workflow_file.stem\n            else:\n                self.name = \"workflow\"\n\n        # Create workspace\n        self.workspace = create_workspace(self.name, workspace, base_dir)\n        self.workspace_info = get_workspace_info(self.workspace)\n\n        # Set up logging\n        self.logger = setup_logging(self.workspace, self.name)\n\n        # Initialize workflow state with pre-loaded metadata if available\n        self.state = WorkflowState(self.workspace, metadata)\n\n        # Initialize template engine\n        self.template_engine = TemplateEngine()\n\n        # Initialize context with default parameter values\n        self.context = {\n            \"workflow_name\": self.name,\n            \"workspace\": str(self.workspace),\n            \"run_number\": self.workspace_info.get(\"run_number\"),\n            \"timestamp\": datetime.now().isoformat(),\n            # Initialize namespaced variables\n            \"args\": {},\n            \"env\": dict(os.environ),\n            \"steps\": {},\n            # Add workflow namespace\n            \"workflow\": {\n                \"name\": self.name,\n                \"file\": str(self.workflow_file) if self.workflow_file else None,\n                \"workspace\": str(self.workspace),\n                \"run_number\": self.workspace_info.get(\"run_number\"),\n                \"timestamp\": datetime.now().isoformat(),\n            },\n        }\n\n        # Add workflow file path if available\n        if self.workflow_file:\n            self.context[\"workflow_file\"] = str(self.workflow_file.absolute())\n\n        # Load default parameter values from workflow file\n        params = self.workflow.get(\"params\", {})\n        for param_name, param_config in params.items():\n            if isinstance(param_config, dict) and \"default\" in param_config:\n                # Store in both root (backward compatibility) and args namespace\n                default_value = param_config[\"default\"]\n                self.context[param_name] = default_value\n                self.context[\"args\"][param_name] = default_value\n            elif isinstance(param_config, dict):\n                # Handle case where param is defined but no default\n                self.context[\"args\"][param_name] = None\n            else:\n                # Handle simple parameter definition\n                self.context[param_name] = param_config\n                self.context[\"args\"][param_name] = param_config\n\n        # If there's existing state, restore step outputs to context\n        if self.state.metadata.get(\"execution_state\", {}).get(\"step_outputs\"):\n            step_outputs = self.state.metadata[\"execution_state\"][\"step_outputs\"]\n            for step_name, outputs in step_outputs.items():\n                if isinstance(outputs, dict):\n                    # If outputs is a dict with a single key matching step name, use its value\n                    if len(outputs) == 1 and step_name in outputs:\n                        self.context[step_name] = outputs[step_name]\n                    else:\n                        self.context[step_name] = outputs\n                else:\n                    self.context[step_name] = outputs\n\n        # Validate flows if present\n        self._validate_flows()\n\n        self.logger.info(f\"Initialized workflow: {self.name}\")\n        self.logger.info(f\"Workspace: {self.workspace}\")\n        self.logger.info(f\"Run number: {self.context['run_number']}\")\n        if params:\n            self.logger.info(\"Default parameters loaded:\")\n            for name, value in self.context[\"args\"].items():\n                self.logger.info(f\"  {name}: {value}\")\n\n        self.current_step = None  # Track current step for error handling\n\n    def _validate_flows(self) -&gt; None:\n        \"\"\"Validate workflow flows configuration.\"\"\"\n        flows = self.workflow.get(\"flows\", {})\n        if not flows:\n            return\n\n        if not isinstance(flows, dict):\n            raise InvalidFlowDefinitionError(\"root\", \"flows must be a mapping\")\n\n        # Validate flows structure\n        if \"definitions\" not in flows:\n            raise InvalidFlowDefinitionError(\"root\", \"missing 'definitions' section\")\n\n        if not isinstance(flows[\"definitions\"], list):\n            raise InvalidFlowDefinitionError(\"root\", \"'definitions' must be a list\")\n\n        # Validate each flow definition\n        defined_flows: Set[str] = set()\n        for flow_def in flows[\"definitions\"]:\n            if not isinstance(flow_def, dict):\n                raise InvalidFlowDefinitionError(\n                    \"unknown\", \"flow definition must be a mapping\"\n                )\n\n            for flow_name, steps in flow_def.items():\n                if not isinstance(steps, list):\n                    raise InvalidFlowDefinitionError(flow_name, \"steps must be a list\")\n\n                # Check for duplicate flow names\n                if flow_name in defined_flows:\n                    raise InvalidFlowDefinitionError(flow_name, \"duplicate flow name\")\n                defined_flows.add(flow_name)\n\n                # Validate step references\n                workflow_steps = {\n                    step.get(\"name\") for step in self.workflow.get(\"steps\", [])\n                }\n                for step in steps:\n                    if step not in workflow_steps:\n                        raise StepNotInFlowError(step, flow_name)\n\n        # Validate default flow\n        default_flow = flows.get(\"default\")\n        if default_flow and default_flow not in defined_flows and default_flow != \"all\":\n            raise FlowNotFoundError(default_flow)\n\n    def _get_flow_steps(self, flow_name: Optional[str] = None) -&gt; List[Dict[str, Any]]:\n        \"\"\"Get ordered list of steps for a flow.\"\"\"\n        all_steps = self.workflow.get(\"steps\", [])\n        if not all_steps:\n            raise WorkflowError(\"No steps defined in workflow\")\n\n        # If no flows defined or flow is None or flow is \"all\", return all steps\n        flows = self.workflow.get(\"flows\", {})\n        if not flows or flow_name is None or flow_name == \"all\":\n            return all_steps\n\n        # Get flow definition\n        flow_to_use = flow_name or flows.get(\"default\", \"all\")\n        if flow_to_use == \"all\":\n            return all_steps\n\n        # Find flow steps in definitions\n        flow_steps = None\n        defined_flows: Set[str] = set()\n        for flow_def in flows.get(\"definitions\", []):\n            if isinstance(flow_def, dict):\n                defined_flows.update(flow_def.keys())\n                if flow_to_use in flow_def:\n                    flow_steps = flow_def[flow_to_use]\n                    break\n\n        if not flow_steps:\n            raise FlowNotFoundError(flow_to_use)\n\n        # Map step names to step configurations\n        step_map = {step.get(\"name\"): step for step in all_steps}\n        ordered_steps = []\n        for step_name in flow_steps:\n            if step_name not in step_map:\n                raise StepNotInFlowError(step_name, flow_to_use)\n            ordered_steps.append(step_map[step_name])\n\n        return ordered_steps\n\n    def run(\n        self,\n        params: Optional[Dict[str, Any]] = None,\n        resume_from: Optional[str] = None,\n        start_from: Optional[str] = None,\n        skip_steps: Optional[List[str]] = None,\n        flow: Optional[str] = None,\n        max_retries: int = 3,\n    ) -&gt; Dict[str, Any]:\n        \"\"\"\n        Run the workflow.\n\n        Args:\n            params: Optional parameters to pass to the workflow\n            resume_from: Optional step name to resume from after failure (preserves outputs)\n            start_from: Optional step name to start execution from (fresh start)\n            skip_steps: Optional list of step names to skip during execution\n            flow: Optional flow name to execute. If not specified, uses default flow.\n            max_retries: Global maximum number of retries for failed steps (default: 3)\n\n        Returns:\n            dict: Workflow results\n        \"\"\"\n        # Update context with provided parameters (overriding defaults)\n        if params:\n            # Update both root (backward compatibility) and args namespace\n            self.context.update(params)\n            self.context[\"args\"].update(params)\n            self.logger.info(\"Parameters provided:\")\n            for name, value in params.items():\n                self.logger.info(f\"  {name}: {value}\")\n\n        # Handle resume from parameter validation failure\n        if (\n            resume_from\n            and self.state.metadata[\"execution_state\"][\"failed_step\"]\n            and self.state.metadata[\"execution_state\"][\"failed_step\"][\"step_name\"]\n            == \"parameter_validation\"\n        ):\n            # Reset state but keep the failed status\n            self.state.reset_state()\n            self.state.metadata[\"execution_state\"][\"status\"] = \"failed\"\n            resume_from = None\n\n        # Validate required parameters\n        workflow_params = self.workflow.get(\"params\", {})\n        for param_name, param_config in workflow_params.items():\n            if isinstance(param_config, dict):\n                if param_config.get(\"required\", False):\n                    if (\n                        param_name not in self.context[\"args\"]\n                        or self.context[\"args\"][param_name] is None\n                    ):\n                        error_msg = f\"Required parameter '{param_name}' is undefined\"\n                        self.state.mark_step_failed(\"parameter_validation\", error_msg)\n                        raise WorkflowError(error_msg)\n                    if \"minLength\" in param_config:\n                        value = str(self.context[\"args\"][param_name])\n                        if len(value) &lt; param_config[\"minLength\"]:\n                            error_msg = f\"Parameter '{param_name}' must be at least {param_config['minLength']} characters long\"\n                            self.state.mark_step_failed(\n                                \"parameter_validation\", error_msg\n                            )\n                            raise WorkflowError(error_msg)\n\n        # Get flow configuration\n        flows = self.workflow.get(\"flows\", {})\n\n        # Determine which flow to use\n        if resume_from:\n            # When resuming, use the flow from the previous execution\n            saved_flow = self.state.get_flow()\n            if saved_flow and flow and saved_flow != flow:\n                raise WorkflowError(\n                    f\"Cannot resume with different flow. Previous flow was '{saved_flow}', \"\n                    f\"requested flow is '{flow}'\"\n                )\n            flow = saved_flow\n        else:\n            # For new runs, determine the flow to use\n            flow_to_use = flow or flows.get(\"default\", \"all\")\n\n            # Validate flow exists if specified\n            if flow and flows:\n                # Check if flow exists in definitions\n                defined_flows: Set[str] = set()\n                for flow_def in flows.get(\"definitions\", []):\n                    if isinstance(flow_def, dict):\n                        defined_flows.update(flow_def.keys())\n\n                if flow != \"all\" and flow not in defined_flows:\n                    raise FlowNotFoundError(flow)\n\n            # Set the flow before we start\n            if flows or (flow and flow != \"all\"):\n                self.state.set_flow(flow_to_use)\n                self.logger.info(f\"Using flow: {flow_to_use}\")\n            flow = flow_to_use\n\n        # Get steps for the specified flow\n        try:\n            steps = self._get_flow_steps(flow)\n        except WorkflowError as e:\n            self.logger.error(str(e))\n            raise\n\n        if not steps:\n            raise WorkflowError(\"No steps to execute\")\n\n        # Handle workflow resumption vs fresh start\n        if resume_from:\n            # Verify workflow is in failed state and step exists\n            state = self.state.metadata[\"execution_state\"]\n            if state[\"status\"] != \"failed\" or not state[\"failed_step\"]:\n                raise WorkflowError(\"Cannot resume: workflow is not in failed state\")\n            if not any(step.get(\"name\") == resume_from for step in steps):\n                raise WorkflowError(\n                    f\"Cannot resume: step '{resume_from}' not found in workflow\"\n                )\n\n            # Restore outputs from completed steps\n            self.context.update(self.state.get_completed_outputs())\n            self.logger.info(f\"Resuming workflow from failed step: {resume_from}\")\n        else:\n            # Reset state for fresh run\n            self.state.reset_state()\n            # Set the flow for the new run (again after reset)\n            if flows or (flow and flow != \"all\"):\n                self.state.set_flow(flow)\n\n        # Initialize execution state if not resuming\n        if not resume_from:\n            self.state.initialize_execution()\n\n        # Restore step outputs from state if resuming or has previous state\n        if self.state.metadata.get(\"execution_state\", {}).get(\"step_outputs\"):\n            self.context[\"steps\"] = self.state.metadata[\"execution_state\"][\n                \"step_outputs\"\n            ].copy()\n\n        # Determine the sequence of steps to execute\n        all_steps = self._get_flow_steps()  # Get *all* defined steps for jump targets\n        step_dict = {step[\"name\"]: step for step in all_steps}\n\n        # Determine starting point based on the *flow-specific* steps list\n        flow_steps = self._get_flow_steps(flow)  # Get steps for the current flow\n        flow_step_dict = {step[\"name\"]: step for step in flow_steps}\n\n        start_index = 0\n        if resume_from:\n            if resume_from not in flow_step_dict:\n                raise StepNotInFlowError(\n                    resume_from,\n                    flow or \"default\",\n                )\n            start_index = next(\n                (i for i, step in enumerate(flow_steps) if step[\"name\"] == resume_from),\n                0,\n            )\n            self.logger.info(f\"Resuming workflow from step: {resume_from}\")\n        elif start_from:\n            if start_from not in flow_step_dict:\n                raise StepNotInFlowError(start_from, flow or \"default\")\n            start_index = next(\n                (i for i, step in enumerate(flow_steps) if step[\"name\"] == start_from),\n                0,\n            )\n            self.logger.info(f\"Starting workflow from step: {start_from}\")\n\n        # Apply initial skips only - runtime skips are handled in execute_step\n        steps_to_execute_initially = flow_steps[start_index:]\n        initial_skip_set = set(skip_steps or [])\n        steps_to_execute = [\n            step\n            for step in steps_to_execute_initially\n            if step[\"name\"] not in initial_skip_set\n        ]\n\n        # Main execution loop\n        current_index = 0\n        executed_step_names: Set[str] = set(self.state.get_executed_steps())\n        while current_index &lt; len(steps_to_execute):\n            step = steps_to_execute[current_index]\n            step_name = step[\"name\"]\n\n            # Skip if already executed (in case of resume/retry jumps)\n            if step_name in executed_step_names:\n                self.logger.info(f\"Skipping already executed step: {step_name}\")\n                current_index += 1\n                continue\n\n            # Execute step with retry/error handling\n            try:\n                self.execute_step(step, max_retries)\n                executed_step_names.add(step_name)\n                current_index += 1\n            except TaskExecutionError as e:\n                # Check if it was a retry request first!\n                if isinstance(e, RetryStepException):\n                    self.logger.debug(\n                        f\"Caught RetryStepException for step '{step_name}'. Looping.\"\n                    )\n                    # Don't increment current_index, just continue the loop\n                    continue\n\n                # Not a retry, so it's either a jump or a final halt\n                self.logger.debug(\n                    f\"TaskExecutionError caught in run loop for step '{step_name}'. Checking for error flow.\"\n                )\n                error_flow_target = self.state.get_error_flow_target()\n                if error_flow_target:\n                    # --- Handle Error Flow Jump ---\n                    self.logger.info(\n                        f\"Jumping to error handling step: {error_flow_target}\"\n                    )\n                    # Find the index of the target step in the original *full* list of steps\n                    try:\n                        target_index_in_all = next(\n                            i\n                            for i, s in enumerate(all_steps)\n                            if s[\"name\"] == error_flow_target\n                        )\n                        # Reset the execution queue to start from the target step,\n                        # using the main list of all steps and respecting skips.\n                        steps_to_execute = [\n                            s\n                            for s in all_steps[target_index_in_all:]\n                            if s[\"name\"] not in initial_skip_set\n                        ]\n                        current_index = 0  # Start from the beginning of the new list\n                        self.state.clear_error_flow_target()\n                        # Add the target step to executed_step_names *before* continuing\n                        # to prevent immediate re-execution if it was skipped initially.\n                        # However, let execute_step handle adding it after successful run.\n                        # We might need to clear executed_step_names specific to the failed branch?\n                        # For now, just continue loop.\n                        continue\n                    except StopIteration:\n                        # This means the target step from on_error.next doesn't exist in the workflow steps\n                        self.logger.error(\n                            f\"Configuration error: on_error.next target '{error_flow_target}' not found in workflow steps.\"\n                        )\n                        # Mark the *original* step as failed, as the jump target is invalid\n                        self.state.mark_step_failed(\n                            step_name,\n                            f\"Invalid on_error.next target: {error_flow_target}\",\n                        )\n                        self.state.save()\n                        raise WorkflowError(\n                            f\"Invalid on_error.next target '{error_flow_target}' for step '{step_name}'\"\n                        ) from e\n                else:\n                    # --- Handle Terminal Failure (No Jump Target) ---\n                    # The error was already marked as terminally failed in execute_step\n                    # which also sets the workflow state to failed.\n                    # Re-raise a WorkflowError to signal the end of execution\n                    root_cause = e.original_error or e  # Get the actual root cause\n                    final_error_message = f\"Workflow halted at step '{step_name}' due to unhandled error: {root_cause}\"  # Use root cause in message\n                    self.logger.error(final_error_message)\n                    # No need to call mark_workflow_failed here; mark_step_failed in execute_step handles it.\n                    raise WorkflowError(\n                        final_error_message, original_error=root_cause\n                    ) from root_cause\n            except Exception as e:\n                # Catch unexpected errors during engine loop logic itself\n                self.logger.error(\n                    f\"Unexpected engine error during step '{step_name}': {e}\",\n                    exc_info=True,\n                )\n                # Mark the step as failed (which also marks workflow as failed)\n                # Use a generic error message as this is an engine-level failure\n                engine_error_msg = (\n                    f\"Unexpected engine error during step '{step_name}': {e}\"\n                )\n                if (\n                    self.current_step\n                ):  # current_step might be None if error happens outside a step\n                    self.state.mark_step_failed(self.current_step, engine_error_msg)\n                else:\n                    # If we don't know the step, mark the workflow directly (though this is less ideal)\n                    # We might need a way to handle non-step-specific failures better.\n                    # For now, let's just log and re-raise, assuming execute_step handled state.\n                    pass  # Avoid redundant state marking if possible\n\n                # Wrap this in StepExecutionError for clarity, only passing original_error\n                raise StepExecutionError(step_name, original_error=e)\n\n        # Save final state only if no exceptions occurred during the loop\n        # Check status before marking completed\n        final_state = cast(ExecutionState, self.state.metadata[\"execution_state\"])\n        if final_state[\"status\"] != \"failed\":\n            self.state.mark_workflow_completed()\n            self.state.save()\n            self.logger.info(\"Workflow completed successfully.\")\n            self.logger.info(\"Final workflow outputs:\")\n            for key, value in self.context[\"steps\"].items():\n                self.logger.info(f\"  {key}: {value}\")\n\n        return {\n            \"status\": \"completed\",\n            \"outputs\": self.context[\"steps\"],\n            \"execution_state\": self.state.metadata[\"execution_state\"],\n        }\n\n    def setup_workspace(self) -&gt; Path:\n        \"\"\"\n        Set up the workspace for this workflow run.\n\n        Returns:\n            Path: Path to the workspace directory\n        \"\"\"\n        # Get workflow name from usage section or file name\n        workflow_name = self.workflow.get(\"usage\", {}).get(\"name\") or (\n            self.workflow_file.stem if self.workflow_file else \"unnamed_workflow\"\n        )\n\n        # Create workspace\n        self.workspace = create_workspace(\n            workflow_name=workflow_name,\n            custom_dir=getattr(self, \"workspace_dir\", None),\n            base_dir=getattr(self, \"base_dir\", \"runs\"),\n        )\n\n        # Initialize workspace info in context\n        workspace_info = get_workspace_info(self.workspace)\n        self.context.update(\n            {\n                \"workspace\": str(self.workspace),\n                \"run_number\": int(self.workspace.name.split(\"_run_\")[-1]),\n                \"timestamp\": datetime.now().isoformat(),\n                \"workflow_name\": workflow_name,\n                \"workflow_file\": str(\n                    self.workflow_file.absolute() if self.workflow_file else \"\"\n                ),\n            }\n        )\n\n        self.logger.info(f\"Created workspace: {self.workspace}\")\n        return self.workspace\n\n    def resolve_template(self, template_str: str) -&gt; str:\n        \"\"\"\n        Resolve template with both direct and namespaced variables.\n\n        Args:\n            template_str: Template string to resolve\n\n        Returns:\n            str: Resolved template string\n\n        Raises:\n            TemplateError: If template resolution fails\n        \"\"\"\n        return self.template_engine.process_template(template_str, self.context)\n\n    def resolve_value(self, value: Any) -&gt; Any:\n        \"\"\"\n        Resolve a single value that might contain templates.\n\n        Args:\n            value: Value to resolve, can be any type\n\n        Returns:\n            Resolved value with templates replaced\n        \"\"\"\n        if isinstance(value, str):\n            return self.template_engine.process_template(value, self.context)\n        elif isinstance(value, dict):\n            return {k: self.resolve_value(v) for k, v in value.items()}\n        elif isinstance(value, (list, tuple)):\n            return [self.resolve_value(v) for v in value]\n        return value\n\n    def resolve_inputs(self, inputs: Dict[str, Any]) -&gt; Dict[str, Any]:\n        \"\"\"\n        Resolve all inputs using Jinja2 template resolution.\n\n        Args:\n            inputs: Input dictionary\n\n        Returns:\n            Dict[str, Any]: Resolved inputs\n        \"\"\"\n        return self.template_engine.process_value(inputs, self.context)\n\n    def execute_step(self, step: Dict[str, Any], global_max_retries: int) -&gt; None:\n        \"\"\"\n        Execute a single workflow step.\n\n        Args:\n            step: Step definition dictionary\n            global_max_retries: Global default for maximum retries\n\n        Raises:\n            TaskExecutionError: If step execution ultimately fails after retries.\n            StepExecutionError: For issues preparing the step itself.\n            RetryStepException: If step should be retried.\n        \"\"\"\n        step_name = step.get(\"name\")\n        if not step_name:\n            raise StepExecutionError(\n                \"Unnamed Step\",\n                Exception(\"Step definition missing required 'name' field\"),\n            )\n\n        self.current_step = step_name\n        self.logger.info(f\"Executing step: {step_name}\")\n        self.state.set_current_step(step_name)\n\n        # Prepare task config\n        task_config = TaskConfig(\n            step=step,\n            context=self.context,\n            workspace=self.workspace,\n        )\n\n        # Find the task handler\n        task_type = step.get(\"task\")\n        if not task_type:\n            # Raise StepExecutionError for config issues before task execution attempt\n            raise StepExecutionError(\n                step_name, Exception(\"Step definition missing 'task' definition\")\n            )\n\n        handler = get_task_handler(task_type)\n        if not handler:\n            # Raise StepExecutionError for config issues before task execution attempt\n            raise StepExecutionError(\n                step_name, Exception(f\"Unknown task type: '{task_type}'\")\n            )\n\n        # --- Condition Check ---\n        condition = step.get(\"condition\")\n        should_execute = True\n        if condition:\n            try:\n                # Resolve the template; boolean True becomes string \"True\"\n                resolved_condition_str = str(self.resolve_template(condition)).strip()\n\n                # Check if the resolved string is exactly \"True\"\n                if resolved_condition_str != \"True\":\n                    should_execute = False\n\n                self.logger.debug(\n                    f\"Step '{step_name}' condition '{condition}' resolved to string '{resolved_condition_str}'. Should execute: {should_execute}\"\n                )\n            except Exception as e:\n                # Treat condition resolution errors as skip, but log a warning\n                self.logger.warning(\n                    f\"Could not resolve condition '{condition}' for step '{step_name}': {e}. Skipping step.\"\n                )\n                should_execute = False\n\n        if not should_execute:\n            self.logger.info(\n                f\"Skipping step '{step_name}' due to condition: {condition}\"\n            )\n            # NOTE: We might want to record skipped steps in the state later.\n            # For now, just return without executing or marking success/failure.\n            return\n\n        # --- Refactored Execution and Error Handling ---\n        step_failed = False\n        step_error: Optional[Exception] = None\n        result: Any = None\n\n        try:\n            # --- Execute Task Handler ---\n            result = handler(task_config)\n            self.logger.debug(f\"Step '{step_name}' completed successfully in handler.\")\n\n        except Exception as e:\n            # --- Catch ANY exception from the handler ---\n            self.logger.warning(\n                f\"Step '{step_name}' caught exception during execution: {e}\"\n            )\n            step_failed = True\n            step_error = e  # Store the caught error\n\n            # Ensure it's a TaskExecutionError, wrapping if necessary\n            if not isinstance(step_error, TaskExecutionError):\n                self.logger.debug(\n                    f\"Wrapping non-TaskExecutionError: {type(step_error).__name__}\"\n                )\n                step_error = TaskExecutionError(\n                    step_name=step_name,\n                    original_error=step_error,\n                    # Pass the raw step dict as task_config for context\n                    task_config=task_config.step,\n                )\n            else:\n                self.logger.debug(f\"Caught existing TaskExecutionError: {step_error}\")\n\n        # --- Handle Successful Execution (if not failed) ---\n        if not step_failed:\n            self.logger.debug(f\"Processing successful result for step '{step_name}'.\")\n            # Store the raw task result under the 'result' key in the steps namespace\n            self.context[\"steps\"][step_name] = {\"result\": result}\n\n            # Mark step as executed successfully in state\n            self.state.mark_step_success(step_name, self.context[\"steps\"][step_name])\n            self.state.reset_step_retries(step_name)\n            self.current_step = None\n            self.logger.info(f\"Step '{step_name}' executed successfully.\")\n            # Save state and exit method on success\n            self.state.save()\n            return\n\n        # --- Handle Failure (if caught) ---\n        # This block only runs if step_failed is True\n        # We also assert step_error is a TaskExecutionError due to wrapping above\n        assert isinstance(\n            step_error, TaskExecutionError\n        ), \"Internal error: step_error should be TaskExecutionError here\"\n\n        self.logger.debug(f\"Processing failure for step '{step_name}'.\")\n        # --- Retry and Error Flow Logic ---\n        on_error_config = step.get(\"on_error\", {})\n        max_retries_for_step = on_error_config.get(\"retry\", global_max_retries)\n        retry_count = self.state.get_step_retry_count(step_name)\n\n        error_to_propagate = step_error.original_error or step_error\n        error_str_for_message = str(error_to_propagate)\n\n        if retry_count &lt; max_retries_for_step:\n            # --- Handle Retry ---\n            self.state.increment_step_retry(step_name)\n            self.logger.info(\n                f\"Retrying step '{step_name}' (Attempt {retry_count + 1}/{max_retries_for_step})\"\n            )\n            delay = float(on_error_config.get(\"delay\", 0))\n            if delay &gt; 0:\n                self.logger.info(f\"Waiting {delay} seconds before retry...\")\n                time.sleep(delay)\n            # Save state before raising retry exception\n            self.state.save()\n            raise RetryStepException(step_name, original_error=error_to_propagate)\n        else:\n            # --- Handle Final Failure (No More Retries) ---\n            self.logger.error(f\"Step '{step_name}' failed after {retry_count} retries.\")\n            # Populate the 'error' context variable for templates\n            error_info = {\"step\": step_name, \"message\": error_str_for_message}\n            self.context[\"error\"] = error_info\n            # Store the raw exception object separately if needed (e.g., for programmatic access)\n            # self.context[\"error\"][\"raw_error\"] = error_to_propagate # Keeping this commented for now\n\n            error_message_template = on_error_config.get(\"message\")\n            final_error_message_for_state = str(\n                step_error\n            )  # Use TaskExecutionError message by default\n            if error_message_template:\n                try:\n                    formatted_message = self.resolve_template(error_message_template)\n                    self.logger.error(f\"Formatted error message: {formatted_message}\")\n                    final_error_message_for_state = formatted_message\n                except Exception as template_err:\n                    self.logger.warning(\n                        f\"Failed to resolve on_error.message template: {template_err}\"\n                    )\n                    final_error_message_for_state = (\n                        f\"{error_str_for_message} (failed to format custom message)\"\n                    )\n\n            action = on_error_config.get(\"action\", \"fail\")\n\n            if action == \"continue\":\n                self.logger.warning(\n                    f\"Step '{step_name}' failed, but workflow continues due to on_error.action='continue'\"\n                )\n                self.state.mark_step_failed(step_name, final_error_message_for_state)\n                self.state.clear_error_flow_target()\n                # Save state and return, allowing run loop to continue\n                self.state.save()\n                return  # NOTE: Execution stops here for 'continue'\n\n            error_next_step = on_error_config.get(\"next\")\n            if error_next_step:\n                self.logger.info(\n                    f\"Proceeding to error handling step: {error_next_step}\"\n                )\n                self.state.set_error_flow_target(error_next_step)\n                # Save state before raising exception for jump\n                self.state.save()\n                raise TaskExecutionError(\n                    step_name, original_error=error_to_propagate\n                )  # Re-raise TaskExecutionError for jump\n            else:\n                self.logger.error(\n                    f\"No error handling ('on_error.next' or 'continue') defined for step '{step_name}'. Halting workflow.\"\n                )\n                self.state.mark_step_failed(step_name, final_error_message_for_state)\n                # Save state before raising exception for halt\n                self.state.save()\n                raise TaskExecutionError(\n                    step_name, original_error=error_to_propagate\n                )  # Re-raise TaskExecutionError for halt\n</code></pre>"},{"location":"reference/yaml_workflow/engine/#yaml_workflow.engine.WorkflowEngine-functions","title":"Functions","text":""},{"location":"reference/yaml_workflow/engine/#yaml_workflow.engine.WorkflowEngine.execute_step","title":"<code>execute_step(step: Dict[str, Any], global_max_retries: int) -&gt; None</code>","text":"<p>Execute a single workflow step.</p> <p>Parameters:</p> Name Type Description Default <code>step</code> <code>Dict[str, Any]</code> <p>Step definition dictionary</p> required <code>global_max_retries</code> <code>int</code> <p>Global default for maximum retries</p> required <p>Raises:</p> Type Description <code>TaskExecutionError</code> <p>If step execution ultimately fails after retries.</p> <code>StepExecutionError</code> <p>For issues preparing the step itself.</p> <code>RetryStepException</code> <p>If step should be retried.</p> Source code in <code>src/yaml_workflow/engine.py</code> <pre><code>def execute_step(self, step: Dict[str, Any], global_max_retries: int) -&gt; None:\n    \"\"\"\n    Execute a single workflow step.\n\n    Args:\n        step: Step definition dictionary\n        global_max_retries: Global default for maximum retries\n\n    Raises:\n        TaskExecutionError: If step execution ultimately fails after retries.\n        StepExecutionError: For issues preparing the step itself.\n        RetryStepException: If step should be retried.\n    \"\"\"\n    step_name = step.get(\"name\")\n    if not step_name:\n        raise StepExecutionError(\n            \"Unnamed Step\",\n            Exception(\"Step definition missing required 'name' field\"),\n        )\n\n    self.current_step = step_name\n    self.logger.info(f\"Executing step: {step_name}\")\n    self.state.set_current_step(step_name)\n\n    # Prepare task config\n    task_config = TaskConfig(\n        step=step,\n        context=self.context,\n        workspace=self.workspace,\n    )\n\n    # Find the task handler\n    task_type = step.get(\"task\")\n    if not task_type:\n        # Raise StepExecutionError for config issues before task execution attempt\n        raise StepExecutionError(\n            step_name, Exception(\"Step definition missing 'task' definition\")\n        )\n\n    handler = get_task_handler(task_type)\n    if not handler:\n        # Raise StepExecutionError for config issues before task execution attempt\n        raise StepExecutionError(\n            step_name, Exception(f\"Unknown task type: '{task_type}'\")\n        )\n\n    # --- Condition Check ---\n    condition = step.get(\"condition\")\n    should_execute = True\n    if condition:\n        try:\n            # Resolve the template; boolean True becomes string \"True\"\n            resolved_condition_str = str(self.resolve_template(condition)).strip()\n\n            # Check if the resolved string is exactly \"True\"\n            if resolved_condition_str != \"True\":\n                should_execute = False\n\n            self.logger.debug(\n                f\"Step '{step_name}' condition '{condition}' resolved to string '{resolved_condition_str}'. Should execute: {should_execute}\"\n            )\n        except Exception as e:\n            # Treat condition resolution errors as skip, but log a warning\n            self.logger.warning(\n                f\"Could not resolve condition '{condition}' for step '{step_name}': {e}. Skipping step.\"\n            )\n            should_execute = False\n\n    if not should_execute:\n        self.logger.info(\n            f\"Skipping step '{step_name}' due to condition: {condition}\"\n        )\n        # NOTE: We might want to record skipped steps in the state later.\n        # For now, just return without executing or marking success/failure.\n        return\n\n    # --- Refactored Execution and Error Handling ---\n    step_failed = False\n    step_error: Optional[Exception] = None\n    result: Any = None\n\n    try:\n        # --- Execute Task Handler ---\n        result = handler(task_config)\n        self.logger.debug(f\"Step '{step_name}' completed successfully in handler.\")\n\n    except Exception as e:\n        # --- Catch ANY exception from the handler ---\n        self.logger.warning(\n            f\"Step '{step_name}' caught exception during execution: {e}\"\n        )\n        step_failed = True\n        step_error = e  # Store the caught error\n\n        # Ensure it's a TaskExecutionError, wrapping if necessary\n        if not isinstance(step_error, TaskExecutionError):\n            self.logger.debug(\n                f\"Wrapping non-TaskExecutionError: {type(step_error).__name__}\"\n            )\n            step_error = TaskExecutionError(\n                step_name=step_name,\n                original_error=step_error,\n                # Pass the raw step dict as task_config for context\n                task_config=task_config.step,\n            )\n        else:\n            self.logger.debug(f\"Caught existing TaskExecutionError: {step_error}\")\n\n    # --- Handle Successful Execution (if not failed) ---\n    if not step_failed:\n        self.logger.debug(f\"Processing successful result for step '{step_name}'.\")\n        # Store the raw task result under the 'result' key in the steps namespace\n        self.context[\"steps\"][step_name] = {\"result\": result}\n\n        # Mark step as executed successfully in state\n        self.state.mark_step_success(step_name, self.context[\"steps\"][step_name])\n        self.state.reset_step_retries(step_name)\n        self.current_step = None\n        self.logger.info(f\"Step '{step_name}' executed successfully.\")\n        # Save state and exit method on success\n        self.state.save()\n        return\n\n    # --- Handle Failure (if caught) ---\n    # This block only runs if step_failed is True\n    # We also assert step_error is a TaskExecutionError due to wrapping above\n    assert isinstance(\n        step_error, TaskExecutionError\n    ), \"Internal error: step_error should be TaskExecutionError here\"\n\n    self.logger.debug(f\"Processing failure for step '{step_name}'.\")\n    # --- Retry and Error Flow Logic ---\n    on_error_config = step.get(\"on_error\", {})\n    max_retries_for_step = on_error_config.get(\"retry\", global_max_retries)\n    retry_count = self.state.get_step_retry_count(step_name)\n\n    error_to_propagate = step_error.original_error or step_error\n    error_str_for_message = str(error_to_propagate)\n\n    if retry_count &lt; max_retries_for_step:\n        # --- Handle Retry ---\n        self.state.increment_step_retry(step_name)\n        self.logger.info(\n            f\"Retrying step '{step_name}' (Attempt {retry_count + 1}/{max_retries_for_step})\"\n        )\n        delay = float(on_error_config.get(\"delay\", 0))\n        if delay &gt; 0:\n            self.logger.info(f\"Waiting {delay} seconds before retry...\")\n            time.sleep(delay)\n        # Save state before raising retry exception\n        self.state.save()\n        raise RetryStepException(step_name, original_error=error_to_propagate)\n    else:\n        # --- Handle Final Failure (No More Retries) ---\n        self.logger.error(f\"Step '{step_name}' failed after {retry_count} retries.\")\n        # Populate the 'error' context variable for templates\n        error_info = {\"step\": step_name, \"message\": error_str_for_message}\n        self.context[\"error\"] = error_info\n        # Store the raw exception object separately if needed (e.g., for programmatic access)\n        # self.context[\"error\"][\"raw_error\"] = error_to_propagate # Keeping this commented for now\n\n        error_message_template = on_error_config.get(\"message\")\n        final_error_message_for_state = str(\n            step_error\n        )  # Use TaskExecutionError message by default\n        if error_message_template:\n            try:\n                formatted_message = self.resolve_template(error_message_template)\n                self.logger.error(f\"Formatted error message: {formatted_message}\")\n                final_error_message_for_state = formatted_message\n            except Exception as template_err:\n                self.logger.warning(\n                    f\"Failed to resolve on_error.message template: {template_err}\"\n                )\n                final_error_message_for_state = (\n                    f\"{error_str_for_message} (failed to format custom message)\"\n                )\n\n        action = on_error_config.get(\"action\", \"fail\")\n\n        if action == \"continue\":\n            self.logger.warning(\n                f\"Step '{step_name}' failed, but workflow continues due to on_error.action='continue'\"\n            )\n            self.state.mark_step_failed(step_name, final_error_message_for_state)\n            self.state.clear_error_flow_target()\n            # Save state and return, allowing run loop to continue\n            self.state.save()\n            return  # NOTE: Execution stops here for 'continue'\n\n        error_next_step = on_error_config.get(\"next\")\n        if error_next_step:\n            self.logger.info(\n                f\"Proceeding to error handling step: {error_next_step}\"\n            )\n            self.state.set_error_flow_target(error_next_step)\n            # Save state before raising exception for jump\n            self.state.save()\n            raise TaskExecutionError(\n                step_name, original_error=error_to_propagate\n            )  # Re-raise TaskExecutionError for jump\n        else:\n            self.logger.error(\n                f\"No error handling ('on_error.next' or 'continue') defined for step '{step_name}'. Halting workflow.\"\n            )\n            self.state.mark_step_failed(step_name, final_error_message_for_state)\n            # Save state before raising exception for halt\n            self.state.save()\n            raise TaskExecutionError(\n                step_name, original_error=error_to_propagate\n            )  # Re-raise TaskExecutionError for halt\n</code></pre>"},{"location":"reference/yaml_workflow/engine/#yaml_workflow.engine.WorkflowEngine.resolve_inputs","title":"<code>resolve_inputs(inputs: Dict[str, Any]) -&gt; Dict[str, Any]</code>","text":"<p>Resolve all inputs using Jinja2 template resolution.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>Dict[str, Any]</code> <p>Input dictionary</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str, Any]: Resolved inputs</p> Source code in <code>src/yaml_workflow/engine.py</code> <pre><code>def resolve_inputs(self, inputs: Dict[str, Any]) -&gt; Dict[str, Any]:\n    \"\"\"\n    Resolve all inputs using Jinja2 template resolution.\n\n    Args:\n        inputs: Input dictionary\n\n    Returns:\n        Dict[str, Any]: Resolved inputs\n    \"\"\"\n    return self.template_engine.process_value(inputs, self.context)\n</code></pre>"},{"location":"reference/yaml_workflow/engine/#yaml_workflow.engine.WorkflowEngine.resolve_template","title":"<code>resolve_template(template_str: str) -&gt; str</code>","text":"<p>Resolve template with both direct and namespaced variables.</p> <p>Parameters:</p> Name Type Description Default <code>template_str</code> <code>str</code> <p>Template string to resolve</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Resolved template string</p> <p>Raises:</p> Type Description <code>TemplateError</code> <p>If template resolution fails</p> Source code in <code>src/yaml_workflow/engine.py</code> <pre><code>def resolve_template(self, template_str: str) -&gt; str:\n    \"\"\"\n    Resolve template with both direct and namespaced variables.\n\n    Args:\n        template_str: Template string to resolve\n\n    Returns:\n        str: Resolved template string\n\n    Raises:\n        TemplateError: If template resolution fails\n    \"\"\"\n    return self.template_engine.process_template(template_str, self.context)\n</code></pre>"},{"location":"reference/yaml_workflow/engine/#yaml_workflow.engine.WorkflowEngine.resolve_value","title":"<code>resolve_value(value: Any) -&gt; Any</code>","text":"<p>Resolve a single value that might contain templates.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Any</code> <p>Value to resolve, can be any type</p> required <p>Returns:</p> Type Description <code>Any</code> <p>Resolved value with templates replaced</p> Source code in <code>src/yaml_workflow/engine.py</code> <pre><code>def resolve_value(self, value: Any) -&gt; Any:\n    \"\"\"\n    Resolve a single value that might contain templates.\n\n    Args:\n        value: Value to resolve, can be any type\n\n    Returns:\n        Resolved value with templates replaced\n    \"\"\"\n    if isinstance(value, str):\n        return self.template_engine.process_template(value, self.context)\n    elif isinstance(value, dict):\n        return {k: self.resolve_value(v) for k, v in value.items()}\n    elif isinstance(value, (list, tuple)):\n        return [self.resolve_value(v) for v in value]\n    return value\n</code></pre>"},{"location":"reference/yaml_workflow/engine/#yaml_workflow.engine.WorkflowEngine.run","title":"<code>run(params: Optional[Dict[str, Any]] = None, resume_from: Optional[str] = None, start_from: Optional[str] = None, skip_steps: Optional[List[str]] = None, flow: Optional[str] = None, max_retries: int = 3) -&gt; Dict[str, Any]</code>","text":"<p>Run the workflow.</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>Optional[Dict[str, Any]]</code> <p>Optional parameters to pass to the workflow</p> <code>None</code> <code>resume_from</code> <code>Optional[str]</code> <p>Optional step name to resume from after failure (preserves outputs)</p> <code>None</code> <code>start_from</code> <code>Optional[str]</code> <p>Optional step name to start execution from (fresh start)</p> <code>None</code> <code>skip_steps</code> <code>Optional[List[str]]</code> <p>Optional list of step names to skip during execution</p> <code>None</code> <code>flow</code> <code>Optional[str]</code> <p>Optional flow name to execute. If not specified, uses default flow.</p> <code>None</code> <code>max_retries</code> <code>int</code> <p>Global maximum number of retries for failed steps (default: 3)</p> <code>3</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>Dict[str, Any]</code> <p>Workflow results</p> Source code in <code>src/yaml_workflow/engine.py</code> <pre><code>def run(\n    self,\n    params: Optional[Dict[str, Any]] = None,\n    resume_from: Optional[str] = None,\n    start_from: Optional[str] = None,\n    skip_steps: Optional[List[str]] = None,\n    flow: Optional[str] = None,\n    max_retries: int = 3,\n) -&gt; Dict[str, Any]:\n    \"\"\"\n    Run the workflow.\n\n    Args:\n        params: Optional parameters to pass to the workflow\n        resume_from: Optional step name to resume from after failure (preserves outputs)\n        start_from: Optional step name to start execution from (fresh start)\n        skip_steps: Optional list of step names to skip during execution\n        flow: Optional flow name to execute. If not specified, uses default flow.\n        max_retries: Global maximum number of retries for failed steps (default: 3)\n\n    Returns:\n        dict: Workflow results\n    \"\"\"\n    # Update context with provided parameters (overriding defaults)\n    if params:\n        # Update both root (backward compatibility) and args namespace\n        self.context.update(params)\n        self.context[\"args\"].update(params)\n        self.logger.info(\"Parameters provided:\")\n        for name, value in params.items():\n            self.logger.info(f\"  {name}: {value}\")\n\n    # Handle resume from parameter validation failure\n    if (\n        resume_from\n        and self.state.metadata[\"execution_state\"][\"failed_step\"]\n        and self.state.metadata[\"execution_state\"][\"failed_step\"][\"step_name\"]\n        == \"parameter_validation\"\n    ):\n        # Reset state but keep the failed status\n        self.state.reset_state()\n        self.state.metadata[\"execution_state\"][\"status\"] = \"failed\"\n        resume_from = None\n\n    # Validate required parameters\n    workflow_params = self.workflow.get(\"params\", {})\n    for param_name, param_config in workflow_params.items():\n        if isinstance(param_config, dict):\n            if param_config.get(\"required\", False):\n                if (\n                    param_name not in self.context[\"args\"]\n                    or self.context[\"args\"][param_name] is None\n                ):\n                    error_msg = f\"Required parameter '{param_name}' is undefined\"\n                    self.state.mark_step_failed(\"parameter_validation\", error_msg)\n                    raise WorkflowError(error_msg)\n                if \"minLength\" in param_config:\n                    value = str(self.context[\"args\"][param_name])\n                    if len(value) &lt; param_config[\"minLength\"]:\n                        error_msg = f\"Parameter '{param_name}' must be at least {param_config['minLength']} characters long\"\n                        self.state.mark_step_failed(\n                            \"parameter_validation\", error_msg\n                        )\n                        raise WorkflowError(error_msg)\n\n    # Get flow configuration\n    flows = self.workflow.get(\"flows\", {})\n\n    # Determine which flow to use\n    if resume_from:\n        # When resuming, use the flow from the previous execution\n        saved_flow = self.state.get_flow()\n        if saved_flow and flow and saved_flow != flow:\n            raise WorkflowError(\n                f\"Cannot resume with different flow. Previous flow was '{saved_flow}', \"\n                f\"requested flow is '{flow}'\"\n            )\n        flow = saved_flow\n    else:\n        # For new runs, determine the flow to use\n        flow_to_use = flow or flows.get(\"default\", \"all\")\n\n        # Validate flow exists if specified\n        if flow and flows:\n            # Check if flow exists in definitions\n            defined_flows: Set[str] = set()\n            for flow_def in flows.get(\"definitions\", []):\n                if isinstance(flow_def, dict):\n                    defined_flows.update(flow_def.keys())\n\n            if flow != \"all\" and flow not in defined_flows:\n                raise FlowNotFoundError(flow)\n\n        # Set the flow before we start\n        if flows or (flow and flow != \"all\"):\n            self.state.set_flow(flow_to_use)\n            self.logger.info(f\"Using flow: {flow_to_use}\")\n        flow = flow_to_use\n\n    # Get steps for the specified flow\n    try:\n        steps = self._get_flow_steps(flow)\n    except WorkflowError as e:\n        self.logger.error(str(e))\n        raise\n\n    if not steps:\n        raise WorkflowError(\"No steps to execute\")\n\n    # Handle workflow resumption vs fresh start\n    if resume_from:\n        # Verify workflow is in failed state and step exists\n        state = self.state.metadata[\"execution_state\"]\n        if state[\"status\"] != \"failed\" or not state[\"failed_step\"]:\n            raise WorkflowError(\"Cannot resume: workflow is not in failed state\")\n        if not any(step.get(\"name\") == resume_from for step in steps):\n            raise WorkflowError(\n                f\"Cannot resume: step '{resume_from}' not found in workflow\"\n            )\n\n        # Restore outputs from completed steps\n        self.context.update(self.state.get_completed_outputs())\n        self.logger.info(f\"Resuming workflow from failed step: {resume_from}\")\n    else:\n        # Reset state for fresh run\n        self.state.reset_state()\n        # Set the flow for the new run (again after reset)\n        if flows or (flow and flow != \"all\"):\n            self.state.set_flow(flow)\n\n    # Initialize execution state if not resuming\n    if not resume_from:\n        self.state.initialize_execution()\n\n    # Restore step outputs from state if resuming or has previous state\n    if self.state.metadata.get(\"execution_state\", {}).get(\"step_outputs\"):\n        self.context[\"steps\"] = self.state.metadata[\"execution_state\"][\n            \"step_outputs\"\n        ].copy()\n\n    # Determine the sequence of steps to execute\n    all_steps = self._get_flow_steps()  # Get *all* defined steps for jump targets\n    step_dict = {step[\"name\"]: step for step in all_steps}\n\n    # Determine starting point based on the *flow-specific* steps list\n    flow_steps = self._get_flow_steps(flow)  # Get steps for the current flow\n    flow_step_dict = {step[\"name\"]: step for step in flow_steps}\n\n    start_index = 0\n    if resume_from:\n        if resume_from not in flow_step_dict:\n            raise StepNotInFlowError(\n                resume_from,\n                flow or \"default\",\n            )\n        start_index = next(\n            (i for i, step in enumerate(flow_steps) if step[\"name\"] == resume_from),\n            0,\n        )\n        self.logger.info(f\"Resuming workflow from step: {resume_from}\")\n    elif start_from:\n        if start_from not in flow_step_dict:\n            raise StepNotInFlowError(start_from, flow or \"default\")\n        start_index = next(\n            (i for i, step in enumerate(flow_steps) if step[\"name\"] == start_from),\n            0,\n        )\n        self.logger.info(f\"Starting workflow from step: {start_from}\")\n\n    # Apply initial skips only - runtime skips are handled in execute_step\n    steps_to_execute_initially = flow_steps[start_index:]\n    initial_skip_set = set(skip_steps or [])\n    steps_to_execute = [\n        step\n        for step in steps_to_execute_initially\n        if step[\"name\"] not in initial_skip_set\n    ]\n\n    # Main execution loop\n    current_index = 0\n    executed_step_names: Set[str] = set(self.state.get_executed_steps())\n    while current_index &lt; len(steps_to_execute):\n        step = steps_to_execute[current_index]\n        step_name = step[\"name\"]\n\n        # Skip if already executed (in case of resume/retry jumps)\n        if step_name in executed_step_names:\n            self.logger.info(f\"Skipping already executed step: {step_name}\")\n            current_index += 1\n            continue\n\n        # Execute step with retry/error handling\n        try:\n            self.execute_step(step, max_retries)\n            executed_step_names.add(step_name)\n            current_index += 1\n        except TaskExecutionError as e:\n            # Check if it was a retry request first!\n            if isinstance(e, RetryStepException):\n                self.logger.debug(\n                    f\"Caught RetryStepException for step '{step_name}'. Looping.\"\n                )\n                # Don't increment current_index, just continue the loop\n                continue\n\n            # Not a retry, so it's either a jump or a final halt\n            self.logger.debug(\n                f\"TaskExecutionError caught in run loop for step '{step_name}'. Checking for error flow.\"\n            )\n            error_flow_target = self.state.get_error_flow_target()\n            if error_flow_target:\n                # --- Handle Error Flow Jump ---\n                self.logger.info(\n                    f\"Jumping to error handling step: {error_flow_target}\"\n                )\n                # Find the index of the target step in the original *full* list of steps\n                try:\n                    target_index_in_all = next(\n                        i\n                        for i, s in enumerate(all_steps)\n                        if s[\"name\"] == error_flow_target\n                    )\n                    # Reset the execution queue to start from the target step,\n                    # using the main list of all steps and respecting skips.\n                    steps_to_execute = [\n                        s\n                        for s in all_steps[target_index_in_all:]\n                        if s[\"name\"] not in initial_skip_set\n                    ]\n                    current_index = 0  # Start from the beginning of the new list\n                    self.state.clear_error_flow_target()\n                    # Add the target step to executed_step_names *before* continuing\n                    # to prevent immediate re-execution if it was skipped initially.\n                    # However, let execute_step handle adding it after successful run.\n                    # We might need to clear executed_step_names specific to the failed branch?\n                    # For now, just continue loop.\n                    continue\n                except StopIteration:\n                    # This means the target step from on_error.next doesn't exist in the workflow steps\n                    self.logger.error(\n                        f\"Configuration error: on_error.next target '{error_flow_target}' not found in workflow steps.\"\n                    )\n                    # Mark the *original* step as failed, as the jump target is invalid\n                    self.state.mark_step_failed(\n                        step_name,\n                        f\"Invalid on_error.next target: {error_flow_target}\",\n                    )\n                    self.state.save()\n                    raise WorkflowError(\n                        f\"Invalid on_error.next target '{error_flow_target}' for step '{step_name}'\"\n                    ) from e\n            else:\n                # --- Handle Terminal Failure (No Jump Target) ---\n                # The error was already marked as terminally failed in execute_step\n                # which also sets the workflow state to failed.\n                # Re-raise a WorkflowError to signal the end of execution\n                root_cause = e.original_error or e  # Get the actual root cause\n                final_error_message = f\"Workflow halted at step '{step_name}' due to unhandled error: {root_cause}\"  # Use root cause in message\n                self.logger.error(final_error_message)\n                # No need to call mark_workflow_failed here; mark_step_failed in execute_step handles it.\n                raise WorkflowError(\n                    final_error_message, original_error=root_cause\n                ) from root_cause\n        except Exception as e:\n            # Catch unexpected errors during engine loop logic itself\n            self.logger.error(\n                f\"Unexpected engine error during step '{step_name}': {e}\",\n                exc_info=True,\n            )\n            # Mark the step as failed (which also marks workflow as failed)\n            # Use a generic error message as this is an engine-level failure\n            engine_error_msg = (\n                f\"Unexpected engine error during step '{step_name}': {e}\"\n            )\n            if (\n                self.current_step\n            ):  # current_step might be None if error happens outside a step\n                self.state.mark_step_failed(self.current_step, engine_error_msg)\n            else:\n                # If we don't know the step, mark the workflow directly (though this is less ideal)\n                # We might need a way to handle non-step-specific failures better.\n                # For now, let's just log and re-raise, assuming execute_step handled state.\n                pass  # Avoid redundant state marking if possible\n\n            # Wrap this in StepExecutionError for clarity, only passing original_error\n            raise StepExecutionError(step_name, original_error=e)\n\n    # Save final state only if no exceptions occurred during the loop\n    # Check status before marking completed\n    final_state = cast(ExecutionState, self.state.metadata[\"execution_state\"])\n    if final_state[\"status\"] != \"failed\":\n        self.state.mark_workflow_completed()\n        self.state.save()\n        self.logger.info(\"Workflow completed successfully.\")\n        self.logger.info(\"Final workflow outputs:\")\n        for key, value in self.context[\"steps\"].items():\n            self.logger.info(f\"  {key}: {value}\")\n\n    return {\n        \"status\": \"completed\",\n        \"outputs\": self.context[\"steps\"],\n        \"execution_state\": self.state.metadata[\"execution_state\"],\n    }\n</code></pre>"},{"location":"reference/yaml_workflow/engine/#yaml_workflow.engine.WorkflowEngine.setup_workspace","title":"<code>setup_workspace() -&gt; Path</code>","text":"<p>Set up the workspace for this workflow run.</p> <p>Returns:</p> Name Type Description <code>Path</code> <code>Path</code> <p>Path to the workspace directory</p> Source code in <code>src/yaml_workflow/engine.py</code> <pre><code>def setup_workspace(self) -&gt; Path:\n    \"\"\"\n    Set up the workspace for this workflow run.\n\n    Returns:\n        Path: Path to the workspace directory\n    \"\"\"\n    # Get workflow name from usage section or file name\n    workflow_name = self.workflow.get(\"usage\", {}).get(\"name\") or (\n        self.workflow_file.stem if self.workflow_file else \"unnamed_workflow\"\n    )\n\n    # Create workspace\n    self.workspace = create_workspace(\n        workflow_name=workflow_name,\n        custom_dir=getattr(self, \"workspace_dir\", None),\n        base_dir=getattr(self, \"base_dir\", \"runs\"),\n    )\n\n    # Initialize workspace info in context\n    workspace_info = get_workspace_info(self.workspace)\n    self.context.update(\n        {\n            \"workspace\": str(self.workspace),\n            \"run_number\": int(self.workspace.name.split(\"_run_\")[-1]),\n            \"timestamp\": datetime.now().isoformat(),\n            \"workflow_name\": workflow_name,\n            \"workflow_file\": str(\n                self.workflow_file.absolute() if self.workflow_file else \"\"\n            ),\n        }\n    )\n\n    self.logger.info(f\"Created workspace: {self.workspace}\")\n    return self.workspace\n</code></pre>"},{"location":"reference/yaml_workflow/engine/#yaml_workflow.engine-functions","title":"Functions","text":""},{"location":"reference/yaml_workflow/engine/#yaml_workflow.engine.setup_logging","title":"<code>setup_logging(workspace: Path, name: str) -&gt; logging.Logger</code>","text":"<p>Set up logging configuration for the workflow.</p> <p>Parameters:</p> Name Type Description Default <code>workspace</code> <code>Path</code> <p>Workspace directory</p> required <code>name</code> <code>str</code> <p>Name of the workflow</p> required <p>Returns:</p> Type Description <code>Logger</code> <p>logging.Logger: Configured logger</p> Source code in <code>src/yaml_workflow/engine.py</code> <pre><code>def setup_logging(workspace: Path, name: str) -&gt; logging.Logger:\n    \"\"\"\n    Set up logging configuration for the workflow.\n\n    Args:\n        workspace: Workspace directory\n        name: Name of the workflow\n\n    Returns:\n        logging.Logger: Configured logger\n    \"\"\"\n    # Create logs directory if it doesn't exist\n    logs_dir = workspace / \"logs\"\n    logs_dir.mkdir(exist_ok=True)\n\n    # Create log file path\n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    log_file = logs_dir / f\"{name}_{timestamp}.log\"\n\n    # Create formatters\n    file_formatter = logging.Formatter(\n        \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n    )\n    console_formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n\n    # Create file handler\n    file_handler = logging.FileHandler(log_file)\n    file_handler.setFormatter(file_formatter)\n    file_handler.setLevel(logging.DEBUG)\n\n    # Create console handler\n    console_handler = logging.StreamHandler()\n    console_handler.setFormatter(console_formatter)\n    console_handler.setLevel(logging.INFO)\n\n    # Configure root logger\n    root_logger = logging.getLogger()\n    root_logger.setLevel(logging.DEBUG)\n\n    # Remove any existing handlers\n    for handler in root_logger.handlers[:]:\n        root_logger.removeHandler(handler)\n\n    # Add handlers\n    root_logger.addHandler(file_handler)\n    root_logger.addHandler(console_handler)\n\n    # Create and return workflow logger\n    logger = logging.getLogger(\"workflow\")\n    logger.info(f\"Logging to: {log_file}\")\n    return logger\n</code></pre>"},{"location":"reference/yaml_workflow/exceptions/","title":"yaml_workflow.exceptions","text":""},{"location":"reference/yaml_workflow/exceptions/#yaml_workflow.exceptions","title":"<code>yaml_workflow.exceptions</code>","text":"<p>Custom exceptions for the YAML Workflow Engine.</p>"},{"location":"reference/yaml_workflow/exceptions/#yaml_workflow.exceptions-classes","title":"Classes","text":""},{"location":"reference/yaml_workflow/exceptions/#yaml_workflow.exceptions.FlowError","title":"<code>FlowError</code>","text":"<p>               Bases: <code>WorkflowError</code></p> <p>Base exception class for flow-related errors.</p> Source code in <code>src/yaml_workflow/exceptions.py</code> <pre><code>class FlowError(WorkflowError):\n    \"\"\"Base exception class for flow-related errors.\"\"\"\n\n    def __init__(self, message: str):\n        super().__init__(f\"Flow error: {message}\")\n</code></pre>"},{"location":"reference/yaml_workflow/exceptions/#yaml_workflow.exceptions.FlowNotFoundError","title":"<code>FlowNotFoundError</code>","text":"<p>               Bases: <code>FlowError</code></p> <p>Raised when a specified flow is not found.</p> Source code in <code>src/yaml_workflow/exceptions.py</code> <pre><code>class FlowNotFoundError(FlowError):\n    \"\"\"Raised when a specified flow is not found.\"\"\"\n\n    def __init__(self, flow_name: str):\n        super().__init__(f\"Flow '{flow_name}' not found\")\n        self.flow_name = flow_name\n</code></pre>"},{"location":"reference/yaml_workflow/exceptions/#yaml_workflow.exceptions.FunctionNotFoundError","title":"<code>FunctionNotFoundError</code>","text":"<p>               Bases: <code>StepError</code></p> <p>Raised when a function specified in a step cannot be found in the module.</p> Source code in <code>src/yaml_workflow/exceptions.py</code> <pre><code>class FunctionNotFoundError(StepError):\n    \"\"\"Raised when a function specified in a step cannot be found in the module.\"\"\"\n\n    def __init__(self, step_name: str, module_name: str, function_name: str):\n        super().__init__(\n            step_name, f\"Function '{function_name}' not found in module '{module_name}'\"\n        )\n</code></pre>"},{"location":"reference/yaml_workflow/exceptions/#yaml_workflow.exceptions.InputResolutionError","title":"<code>InputResolutionError</code>","text":"<p>               Bases: <code>WorkflowRuntimeError</code></p> <p>Raised when input variables cannot be resolved.</p> Source code in <code>src/yaml_workflow/exceptions.py</code> <pre><code>class InputResolutionError(WorkflowRuntimeError):\n    \"\"\"Raised when input variables cannot be resolved.\"\"\"\n\n    def __init__(self, step_name: str, variable_name: str, message: str):\n        self.step_name = step_name\n        self.variable_name = variable_name\n        super().__init__(\n            f\"Failed to resolve input '{variable_name}' in step '{step_name}': {message}\"\n        )\n</code></pre>"},{"location":"reference/yaml_workflow/exceptions/#yaml_workflow.exceptions.InputValidationError","title":"<code>InputValidationError</code>","text":"<p>               Bases: <code>StepError</code></p> <p>Raised when step input validation fails.</p> Source code in <code>src/yaml_workflow/exceptions.py</code> <pre><code>class InputValidationError(StepError):\n    \"\"\"Raised when step input validation fails.\"\"\"\n\n    def __init__(self, step_name: str, input_name: str, message: str):\n        super().__init__(step_name, f\"Invalid input '{input_name}': {message}\")\n</code></pre>"},{"location":"reference/yaml_workflow/exceptions/#yaml_workflow.exceptions.InvalidFlowDefinitionError","title":"<code>InvalidFlowDefinitionError</code>","text":"<p>               Bases: <code>FlowError</code></p> <p>Raised when a flow definition is invalid.</p> Source code in <code>src/yaml_workflow/exceptions.py</code> <pre><code>class InvalidFlowDefinitionError(FlowError):\n    \"\"\"Raised when a flow definition is invalid.\"\"\"\n\n    def __init__(self, flow_name: str, reason: str):\n        super().__init__(f\"Invalid flow '{flow_name}': {reason}\")\n        self.flow_name = flow_name\n        self.reason = reason\n</code></pre>"},{"location":"reference/yaml_workflow/exceptions/#yaml_workflow.exceptions.ModuleImportError","title":"<code>ModuleImportError</code>","text":"<p>               Bases: <code>WorkflowRuntimeError</code></p> <p>Raised when a module cannot be imported.</p> Source code in <code>src/yaml_workflow/exceptions.py</code> <pre><code>class ModuleImportError(WorkflowRuntimeError):\n    \"\"\"Raised when a module cannot be imported.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/yaml_workflow/exceptions/#yaml_workflow.exceptions.ModuleNotFoundError","title":"<code>ModuleNotFoundError</code>","text":"<p>               Bases: <code>StepError</code></p> <p>Raised when a module specified in a step cannot be found.</p> Source code in <code>src/yaml_workflow/exceptions.py</code> <pre><code>class ModuleNotFoundError(StepError):\n    \"\"\"Raised when a module specified in a step cannot be found.\"\"\"\n\n    def __init__(self, step_name: str, module_name: str):\n        super().__init__(step_name, f\"Module '{module_name}' not found\")\n</code></pre>"},{"location":"reference/yaml_workflow/exceptions/#yaml_workflow.exceptions.OutputHandlingError","title":"<code>OutputHandlingError</code>","text":"<p>               Bases: <code>WorkflowRuntimeError</code></p> <p>Raised when there are issues handling task outputs.</p> Source code in <code>src/yaml_workflow/exceptions.py</code> <pre><code>class OutputHandlingError(WorkflowRuntimeError):\n    \"\"\"Raised when there are issues handling task outputs.\"\"\"\n\n    def __init__(self, step_name: str, message: str):\n        self.step_name = step_name\n        super().__init__(f\"Output handling failed for step '{step_name}': {message}\")\n</code></pre>"},{"location":"reference/yaml_workflow/exceptions/#yaml_workflow.exceptions.OutputValidationError","title":"<code>OutputValidationError</code>","text":"<p>               Bases: <code>StepError</code></p> <p>Raised when step output validation fails.</p> Source code in <code>src/yaml_workflow/exceptions.py</code> <pre><code>class OutputValidationError(StepError):\n    \"\"\"Raised when step output validation fails.\"\"\"\n\n    def __init__(self, step_name: str, output_name: str, message: str):\n        super().__init__(step_name, f\"Invalid output '{output_name}': {message}\")\n</code></pre>"},{"location":"reference/yaml_workflow/exceptions/#yaml_workflow.exceptions.RequiredVariableError","title":"<code>RequiredVariableError</code>","text":"<p>               Bases: <code>WorkflowRuntimeError</code></p> <p>Raised when a required variable is missing from the context.</p> Source code in <code>src/yaml_workflow/exceptions.py</code> <pre><code>class RequiredVariableError(WorkflowRuntimeError):\n    \"\"\"Raised when a required variable is missing from the context.\"\"\"\n\n    def __init__(self, variable_name: str, step_name: Optional[str] = None):\n        self.variable_name = variable_name\n        self.step_name = step_name\n        location = f\" in step '{step_name}'\" if step_name else \"\"\n        super().__init__(f\"Required variable '{variable_name}' not found{location}\")\n</code></pre>"},{"location":"reference/yaml_workflow/exceptions/#yaml_workflow.exceptions.StepError","title":"<code>StepError</code>","text":"<p>               Bases: <code>WorkflowError</code></p> <p>Base exception class for step-related errors.</p> Source code in <code>src/yaml_workflow/exceptions.py</code> <pre><code>class StepError(WorkflowError):\n    \"\"\"Base exception class for step-related errors.\"\"\"\n\n    def __init__(self, step_name: str, message: str):\n        self.step_name = step_name\n        super().__init__(f\"Error in step '{step_name}': {message}\")\n</code></pre>"},{"location":"reference/yaml_workflow/exceptions/#yaml_workflow.exceptions.StepExecutionError","title":"<code>StepExecutionError</code>","text":"<p>               Bases: <code>StepError</code></p> <p>Raised when a step fails during execution.</p> Source code in <code>src/yaml_workflow/exceptions.py</code> <pre><code>class StepExecutionError(StepError):\n    \"\"\"Raised when a step fails during execution.\"\"\"\n\n    def __init__(self, step_name: str, original_error: Exception):\n        super().__init__(step_name, f\"Execution failed: {str(original_error)}\")\n        self.original_error = original_error\n</code></pre>"},{"location":"reference/yaml_workflow/exceptions/#yaml_workflow.exceptions.StepNotInFlowError","title":"<code>StepNotInFlowError</code>","text":"<p>               Bases: <code>FlowError</code></p> <p>Raised when trying to access a step that is not in the current flow.</p> Source code in <code>src/yaml_workflow/exceptions.py</code> <pre><code>class StepNotInFlowError(FlowError):\n    \"\"\"Raised when trying to access a step that is not in the current flow.\"\"\"\n\n    def __init__(self, step_name: str, flow_name: str):\n        super().__init__(f\"Step '{step_name}' not found in flow '{flow_name}'\")\n        self.step_name = step_name\n        self.flow_name = flow_name\n</code></pre>"},{"location":"reference/yaml_workflow/exceptions/#yaml_workflow.exceptions.TaskExecutionError","title":"<code>TaskExecutionError</code>","text":"<p>               Bases: <code>WorkflowRuntimeError</code></p> <p>Raised when a task fails during execution.</p> Source code in <code>src/yaml_workflow/exceptions.py</code> <pre><code>class TaskExecutionError(WorkflowRuntimeError):\n    \"\"\"Raised when a task fails during execution.\"\"\"\n\n    def __init__(\n        self,\n        step_name: str,\n        original_error: Exception,\n        task_config: Optional[dict] = None,\n    ):\n        self.step_name = step_name\n        self.original_error = original_error\n        self.task_config = task_config\n        super().__init__(\n            message=f\"Task '{step_name}' failed: {str(original_error)}\",\n            original_error=original_error,\n        )\n</code></pre>"},{"location":"reference/yaml_workflow/exceptions/#yaml_workflow.exceptions.TemplateError","title":"<code>TemplateError</code>","text":"<p>               Bases: <code>WorkflowError</code></p> <p>Raised when template resolution fails.</p> Source code in <code>src/yaml_workflow/exceptions.py</code> <pre><code>class TemplateError(WorkflowError):\n    \"\"\"Raised when template resolution fails.\"\"\"\n\n    def __init__(self, message: str, original_error: Optional[Exception] = None):\n        super().__init__(f\"Template error: {message}\", original_error=original_error)\n</code></pre>"},{"location":"reference/yaml_workflow/exceptions/#yaml_workflow.exceptions.VariableNotFoundError","title":"<code>VariableNotFoundError</code>","text":"<p>               Bases: <code>WorkflowError</code></p> <p>Raised when a referenced variable is not found in the workflow context.</p> Source code in <code>src/yaml_workflow/exceptions.py</code> <pre><code>class VariableNotFoundError(WorkflowError):\n    \"\"\"Raised when a referenced variable is not found in the workflow context.\"\"\"\n\n    def __init__(self, variable_name: str):\n        super().__init__(f\"Variable '{variable_name}' not found in workflow context\")\n</code></pre>"},{"location":"reference/yaml_workflow/exceptions/#yaml_workflow.exceptions.WorkflowDefinitionError","title":"<code>WorkflowDefinitionError</code>","text":"<p>               Bases: <code>WorkflowError</code></p> <p>Raised when there are issues with the workflow definition YAML.</p> Source code in <code>src/yaml_workflow/exceptions.py</code> <pre><code>class WorkflowDefinitionError(WorkflowError):\n    \"\"\"Raised when there are issues with the workflow definition YAML.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/yaml_workflow/exceptions/#yaml_workflow.exceptions.WorkflowError","title":"<code>WorkflowError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base exception class for all workflow-related errors.</p> Source code in <code>src/yaml_workflow/exceptions.py</code> <pre><code>class WorkflowError(Exception):\n    \"\"\"Base exception class for all workflow-related errors.\"\"\"\n\n    def __init__(self, message: str, original_error: Optional[Exception] = None):\n        super().__init__(message)\n        self.original_error = original_error\n</code></pre>"},{"location":"reference/yaml_workflow/exceptions/#yaml_workflow.exceptions.WorkflowNotFoundError","title":"<code>WorkflowNotFoundError</code>","text":"<p>               Bases: <code>WorkflowError</code></p> <p>Raised when a workflow file cannot be found.</p> Source code in <code>src/yaml_workflow/exceptions.py</code> <pre><code>class WorkflowNotFoundError(WorkflowError):\n    \"\"\"Raised when a workflow file cannot be found.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/yaml_workflow/exceptions/#yaml_workflow.exceptions.WorkflowRuntimeError","title":"<code>WorkflowRuntimeError</code>","text":"<p>               Bases: <code>WorkflowError</code></p> <p>Base class for runtime workflow errors.</p> Source code in <code>src/yaml_workflow/exceptions.py</code> <pre><code>class WorkflowRuntimeError(WorkflowError):\n    \"\"\"Base class for runtime workflow errors.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/yaml_workflow/exceptions/#yaml_workflow.exceptions.WorkflowTimeoutError","title":"<code>WorkflowTimeoutError</code>","text":"<p>               Bases: <code>WorkflowError</code></p> <p>Raised when a workflow exceeds its timeout limit.</p> Source code in <code>src/yaml_workflow/exceptions.py</code> <pre><code>class WorkflowTimeoutError(WorkflowError):\n    \"\"\"Raised when a workflow exceeds its timeout limit.\"\"\"\n\n    def __init__(self, timeout_seconds: float):\n        super().__init__(\n            f\"Workflow execution exceeded timeout of {timeout_seconds} seconds\"\n        )\n</code></pre>"},{"location":"reference/yaml_workflow/exceptions/#yaml_workflow.exceptions.WorkflowValidationError","title":"<code>WorkflowValidationError</code>","text":"<p>               Bases: <code>WorkflowError</code></p> <p>Raised when workflow YAML validation fails.</p> Source code in <code>src/yaml_workflow/exceptions.py</code> <pre><code>class WorkflowValidationError(WorkflowError):\n    \"\"\"Raised when workflow YAML validation fails.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/yaml_workflow/exceptions/#yaml_workflow.exceptions.WorkflowValidationSchema","title":"<code>WorkflowValidationSchema</code>","text":"<p>Schema definitions for workflow validation.</p> Source code in <code>src/yaml_workflow/exceptions.py</code> <pre><code>class WorkflowValidationSchema:\n    \"\"\"Schema definitions for workflow validation.\"\"\"\n\n    REQUIRED_STEP_FIELDS = [\"name\", \"module\", \"function\"]\n    OPTIONAL_STEP_FIELDS = [\n        \"inputs\",\n        \"outputs\",\n        \"condition\",\n        \"error_handling\",\n        \"retry\",\n        \"always_run\",\n    ]\n    VALID_ERROR_HANDLING = [\"skip\", \"fail\", \"retry\", \"notify\"]\n</code></pre>"},{"location":"reference/yaml_workflow/runner/","title":"yaml_workflow.runner","text":""},{"location":"reference/yaml_workflow/runner/#yaml_workflow.runner","title":"<code>yaml_workflow.runner</code>","text":""},{"location":"reference/yaml_workflow/runner/#yaml_workflow.runner-classes","title":"Classes","text":""},{"location":"reference/yaml_workflow/runner/#yaml_workflow.runner-functions","title":"Functions","text":""},{"location":"reference/yaml_workflow/runner/#yaml_workflow.runner.run_workflow","title":"<code>run_workflow(workflow_file: Path | str, args: dict | None = None, workspace_dir: Path | str | None = None, output_dir: Path | str | None = None, config_file: Path | str | None = None) -&gt; dict</code>","text":"<p>Runs a workflow defined in a YAML file.</p> <p>Parameters:</p> Name Type Description Default <code>workflow_file</code> <code>Path | str</code> <p>Path to the workflow YAML file.</p> required <code>args</code> <code>dict | None</code> <p>Dictionary of arguments to pass to the workflow.</p> <code>None</code> <code>workspace_dir</code> <code>Path | str | None</code> <p>Directory for temporary files and logs.</p> <code>None</code> <code>output_dir</code> <code>Path | str | None</code> <p>Directory for final output files.</p> <code>None</code> <code>config_file</code> <code>Path | str | None</code> <p>Path to a custom configuration file.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary containing the workflow result: {\"success\": bool, \"message\": str, \"stdout\": str, \"stderr\": str}</p> Source code in <code>src/yaml_workflow/runner.py</code> <pre><code>def run_workflow(\n    workflow_file: Path | str,\n    args: dict | None = None,\n    workspace_dir: Path | str | None = None,\n    output_dir: Path | str | None = None,\n    config_file: Path | str | None = None,\n) -&gt; dict:\n    \"\"\"Runs a workflow defined in a YAML file.\n\n    Args:\n        workflow_file: Path to the workflow YAML file.\n        args: Dictionary of arguments to pass to the workflow.\n        workspace_dir: Directory for temporary files and logs.\n        output_dir: Directory for final output files.\n        config_file: Path to a custom configuration file.\n\n    Returns:\n        A dictionary containing the workflow result:\n            {\"success\": bool, \"message\": str, \"stdout\": str, \"stderr\": str}\n    \"\"\"\n    workflow_file = Path(workflow_file)\n    if not workflow_file.exists():\n        return {\n            \"success\": False,\n            \"message\": f\"Workflow file not found: {workflow_file}\",\n            \"stdout\": \"\",\n            \"stderr\": \"\",\n        }\n\n    _workspace_dir = Path(workspace_dir) if workspace_dir else Path(\".\")\n    _output_dir = Path(output_dir) if output_dir else _workspace_dir / \"output\"\n    log_dir = _workspace_dir / \"logs\"\n\n    # Create directories if they don't exist\n    _workspace_dir.mkdir(parents=True, exist_ok=True)\n    _output_dir.mkdir(parents=True, exist_ok=True)\n    log_dir.mkdir(parents=True, exist_ok=True)\n\n    # --- Setup Logging ---\n    log_file = (\n        log_dir\n        / f\"workflow_{datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S_%f')}.log\"\n    )\n    file_handler = logging.FileHandler(log_file)\n    formatter = logging.Formatter(\n        \"%(asctime)s - %(name)s.%(funcName)s - %(levelname)s - %(message)s\"\n    )\n    file_handler.setFormatter(formatter)\n\n    # Add handler to the root logger to capture logs from all modules\n    root_logger = logging.getLogger()\n    # Remove existing handlers to avoid duplicate logs if run multiple times\n    # Note: This is simplistic; consider more robust handler management\n    for handler in root_logger.handlers[:]:\n        root_logger.removeHandler(handler)\n    root_logger.addHandler(file_handler)\n    root_logger.setLevel(logging.DEBUG)  # Capture DEBUG level and above in the file\n\n    # Add a basic console handler for INFO level\n    # console_handler = logging.StreamHandler()\n    # console_handler.setLevel(logging.INFO)\n    # console_handler.setFormatter(formatter)\n    # root_logger.addHandler(console_handler)\n    # --- End Logging Setup ---\n\n    logger.info(f\"Starting workflow: {workflow_file.name}\")\n    logger.info(f\"Workspace: {_workspace_dir}\")\n    logger.info(f\"Output Dir: {_output_dir}\")\n    logger.info(f\"Arguments: {args}\")\n\n    try:\n        with open(workflow_file, \"r\") as f:\n            workflow_data = yaml.safe_load(f)\n    except Exception as e:\n        logger.error(f\"Error loading workflow file: {e}\")\n        return {\n            \"success\": False,\n            \"message\": f\"Error loading workflow file: {e}\",\n            \"stdout\": \"\",\n            \"stderr\": str(e),\n        }\n\n    workflow_name = workflow_data.get(\"name\", \"Unnamed Workflow\")\n    workflow_steps = workflow_data.get(\"steps\", [])\n\n    context = {\n        \"workflow_name\": workflow_name,\n        \"workspace\": str(_workspace_dir),\n        \"output\": str(_output_dir),\n        \"args\": args or {},\n        \"steps\": {},\n        \"env\": os.environ.copy(),\n    }\n\n    template_engine = TemplateEngine()\n\n    final_status = {\n        \"success\": True,\n        \"message\": \"Workflow completed successfully\",\n        \"stdout\": \"\",\n        \"stderr\": \"\",\n    }\n    stdout_capture = io.StringIO()\n    stderr_capture = io.StringIO()\n\n    # Redirect stdout/stderr for the duration of step execution\n    with redirect_stdout(stdout_capture), redirect_stderr(stderr_capture):\n        for i, step_data in enumerate(workflow_steps):\n            step_name = step_data.get(\"name\", f\"step_{i+1}\")\n            logger.info(\n                f\"--- Running Step: {step_name} ({i+1}/{len(workflow_steps)}) ---\"\n            )\n            context[\"current_step\"] = step_name\n\n            step = Step(\n                step_data, context, _workspace_dir, _output_dir, template_engine\n            )\n\n            try:\n                should_run = step.evaluate_condition()\n                if not should_run:\n                    logger.info(f\"Skipping step: {step_name} due to condition.\")\n                    context[\"steps\"][step_name] = {\"skipped\": True, \"result\": None}\n                    continue\n\n                logger.debug(f\"Step '{step_name}' inputs before render: {step.inputs}\")\n                rendered_inputs = step.render_inputs()\n                logger.debug(\n                    f\"Step '{step_name}' inputs after render: {rendered_inputs}\"\n                )\n\n                task_func = get_task_handler(step.task)\n                if not task_func:\n                    raise ValueError(f\"Unknown task type: {step.task}\")\n\n                logger.debug(f\"Executing task: {step.task} for step: {step_name}\")\n\n                task_config = TaskConfig(\n                    step=step_data,\n                    context=context,\n                    workspace=_workspace_dir,\n                )\n                result = task_func(task_config)\n                logger.info(f\"Step '{step_name}' completed successfully.\")\n                logger.debug(f\"Step '{step_name}' result: {result}\")\n                context[\"steps\"][step_name] = {\"skipped\": False, \"result\": result}\n\n            except TemplateError as e:\n                logger.error(\n                    f\"Template error in step '{step_name}': {e}\", exc_info=True\n                )\n                final_status = step.handle_error(e, context)\n                if final_status[\"success\"] is False:\n                    logger.error(\n                        f\"Workflow aborted due to error in step '{step_name}'.\"\n                    )\n                    break  # Stop workflow execution\n                else:\n                    logger.warning(\n                        f\"Error handled in step '{step_name}', continuing workflow...\"\n                    )\n                    context[\"steps\"][step_name] = {\n                        \"skipped\": False,\n                        \"error\": str(e),\n                        \"result\": None,\n                    }  # Mark error but continue\n\n            except Exception as e:\n                logger.error(f\"Error executing step '{step_name}': {e}\", exc_info=True)\n                final_status = step.handle_error(e, context)\n                if final_status[\"success\"] is False:\n                    logger.error(\n                        f\"Workflow aborted due to error in step '{step_name}'.\"\n                    )\n                    break  # Stop workflow execution\n                else:\n                    logger.warning(\n                        f\"Error handled in step '{step_name}', continuing workflow...\"\n                    )\n                    context[\"steps\"][step_name] = {\n                        \"skipped\": False,\n                        \"error\": str(e),\n                        \"result\": None,\n                    }  # Mark error but continue\n\n            finally:\n                del context[\"current_step\"]  # Clean up current step context\n\n        if final_status[\"success\"]:\n            logger.info(\"Workflow finished successfully.\")\n        else:\n            logger.error(f\"Workflow finished with errors: {final_status['message']}\")\n\n    # Capture stdout/stderr after the context manager exits\n    final_status[\"stdout\"] = stdout_capture.getvalue()\n    final_status[\"stderr\"] = stderr_capture.getvalue()\n\n    # --- Cleanup Logging ---\n    # It might be better to close/remove handlers if the runner is long-lived\n    # For simple script execution, this might not be strictly necessary\n    # root_logger.removeHandler(file_handler)\n    # root_logger.removeHandler(console_handler)\n    # file_handler.close()\n    # --- End Cleanup Logging ---\n\n    return final_status\n</code></pre>"},{"location":"reference/yaml_workflow/state/","title":"yaml_workflow.state","text":""},{"location":"reference/yaml_workflow/state/#yaml_workflow.state","title":"<code>yaml_workflow.state</code>","text":"<p>State management for workflow execution.</p> <p>This module handles the persistence and management of workflow execution state, including step completion, outputs, and retry mechanisms.</p>"},{"location":"reference/yaml_workflow/state/#yaml_workflow.state-classes","title":"Classes","text":""},{"location":"reference/yaml_workflow/state/#yaml_workflow.state.WorkflowState","title":"<code>WorkflowState</code>","text":"<p>Manages workflow execution state and persistence.</p> Source code in <code>src/yaml_workflow/state.py</code> <pre><code>class WorkflowState:\n    \"\"\"Manages workflow execution state and persistence.\"\"\"\n\n    def __init__(self, workspace: Path, metadata: Optional[Dict[str, Any]] = None):\n        \"\"\"Initialize workflow state.\n\n        Args:\n            workspace: Path to workspace directory\n            metadata: Optional pre-loaded metadata for resuming workflows\n        \"\"\"\n        self.workspace = workspace\n        self.metadata_path = workspace / METADATA_FILE\n\n        # Initialize with empty state\n        self.metadata: Dict[str, Any] = {\n            \"execution_state\": cast(\n                ExecutionState,\n                {\n                    \"current_step_name\": None,\n                    \"completed_steps\": [],\n                    \"failed_step\": None,\n                    \"step_outputs\": {},\n                    \"last_updated\": datetime.now().isoformat(),\n                    \"status\": \"not_started\",\n                    \"flow\": None,\n                    \"retry_counts\": {},\n                    \"completed_at\": None,\n                    \"error_flow_target\": None,\n                },\n            ),\n            \"namespaces\": DEFAULT_NAMESPACES.copy(),\n        }\n\n        if metadata is not None:\n            # Update with provided metadata\n            self.metadata.update(metadata)\n            # Ensure required structures exist\n            if \"execution_state\" not in self.metadata:\n                self.metadata[\"execution_state\"] = cast(\n                    ExecutionState, self.metadata[\"execution_state\"]\n                )\n            if \"retry_counts\" not in self.metadata[\"execution_state\"]:\n                self.metadata[\"execution_state\"][\"retry_counts\"] = {}\n            if \"error_flow_target\" not in self.metadata[\"execution_state\"]:\n                self.metadata[\"execution_state\"][\"error_flow_target\"] = None\n            if \"namespaces\" not in self.metadata:\n                self.metadata[\"namespaces\"] = DEFAULT_NAMESPACES.copy()\n            self.save()\n        else:\n            self._load_state()\n\n    def _load_state(self) -&gt; None:\n        \"\"\"Load workflow state from metadata file.\"\"\"\n        if self.metadata_path.exists():\n            with open(self.metadata_path) as f:\n                loaded_metadata = json.load(f)\n                self.metadata.update(loaded_metadata)\n\n        # Ensure all required structures exist\n        if \"execution_state\" not in self.metadata:\n            self.metadata[\"execution_state\"] = cast(\n                ExecutionState,\n                {\n                    \"current_step_name\": None,\n                    \"completed_steps\": [],\n                    \"failed_step\": None,\n                    \"step_outputs\": {},\n                    \"last_updated\": datetime.now().isoformat(),\n                    \"status\": \"not_started\",\n                    \"flow\": None,\n                    \"retry_counts\": {},\n                    \"completed_at\": None,\n                    \"error_flow_target\": None,\n                },\n            )\n        if \"namespaces\" not in self.metadata:\n            self.metadata[\"namespaces\"] = DEFAULT_NAMESPACES.copy()\n        self.save()\n\n    def save(self) -&gt; None:\n        \"\"\"Save current state to metadata file.\"\"\"\n        self.metadata[\"execution_state\"][\"last_updated\"] = datetime.now().isoformat()\n        with open(self.metadata_path, \"w\") as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_state(self) -&gt; Dict[str, Any]:\n        \"\"\"Get the current workflow state.\n\n        Returns:\n            Dict[str, Any]: Current workflow state including execution state, step outputs, and namespaces\n        \"\"\"\n        exec_state = cast(ExecutionState, self.metadata[\"execution_state\"])\n        return {\n            \"execution_state\": exec_state,\n            \"namespaces\": self.metadata[\"namespaces\"],\n            \"steps\": {\n                step: {\n                    \"status\": (\n                        \"completed\"\n                        if step in exec_state[\"completed_steps\"]\n                        else (\n                            \"failed\"\n                            if exec_state[\"failed_step\"]\n                            and exec_state[\"failed_step\"][\"step_name\"] == step\n                            else \"not_started\"\n                        )\n                    ),\n                    \"outputs\": exec_state[\"step_outputs\"].get(step, {}),\n                }\n                for step in set(\n                    exec_state[\"completed_steps\"]\n                    + (\n                        [exec_state[\"failed_step\"][\"step_name\"]]\n                        if exec_state[\"failed_step\"]\n                        else []\n                    )\n                )\n            },\n        }\n\n    def update_namespace(self, namespace: str, data: Dict[str, Any]) -&gt; None:\n        \"\"\"Update a namespace with new data.\n\n        Args:\n            namespace: Name of the namespace to update\n            data: Data to update the namespace with\n        \"\"\"\n        namespaces = cast(Dict[str, Dict[str, Any]], self.metadata[\"namespaces\"])\n        if namespace not in namespaces:\n            namespaces[namespace] = {}\n        namespaces[namespace].update(data)\n        self.save()\n\n    def get_namespace(self, namespace: str) -&gt; Dict[str, Any]:\n        \"\"\"Get all data from a namespace.\n\n        Args:\n            namespace: Name of the namespace to get\n\n        Returns:\n            Dict[str, Any]: Namespace data\n        \"\"\"\n        namespaces = cast(Dict[str, Dict[str, Any]], self.metadata[\"namespaces\"])\n        return namespaces.get(namespace, {})\n\n    def get_variable(self, variable: str, namespace: str) -&gt; Any:\n        \"\"\"Get a variable from a specific namespace.\n\n        Args:\n            variable: Name of the variable to get\n            namespace: Namespace to get the variable from\n\n        Returns:\n            Any: Variable value\n        \"\"\"\n        namespaces = cast(Dict[str, Dict[str, Any]], self.metadata[\"namespaces\"])\n        return namespaces.get(namespace, {}).get(variable)\n\n    def clear_namespace(self, namespace: str) -&gt; None:\n        \"\"\"Clear all data from a namespace.\n\n        Args:\n            namespace: Name of the namespace to clear\n        \"\"\"\n        namespaces = cast(Dict[str, Dict[str, Any]], self.metadata[\"namespaces\"])\n        if namespace in namespaces:\n            namespaces[namespace] = {}\n            self.save()\n\n    def mark_step_success(self, step_name: str, outputs: Dict[str, Any]) -&gt; None:\n        \"\"\"Mark a step as completed successfully and store its outputs.\"\"\"\n        state = cast(ExecutionState, self.metadata[\"execution_state\"])\n        if step_name not in state[\"completed_steps\"]:\n            state[\"completed_steps\"].append(step_name)\n        state[\"step_outputs\"][step_name] = outputs\n        state[\"status\"] = \"in_progress\"\n        if state[\"failed_step\"] and state[\"failed_step\"][\"step_name\"] == step_name:\n            state[\"failed_step\"] = None\n        self.reset_step_retries(step_name)\n        self.save()\n\n    def mark_step_failed(self, step_name: str, error: str) -&gt; None:\n        \"\"\"Mark a step as terminally failed (retries exhausted/no error flow).\"\"\"\n        state = cast(ExecutionState, self.metadata[\"execution_state\"])\n        self.reset_step_retries(step_name)\n        state[\"failed_step\"] = {\n            \"step_name\": step_name,\n            \"error\": error,\n            \"failed_at\": datetime.now().isoformat(),\n        }\n        state[\"status\"] = \"failed\"\n        self.save()\n\n    def mark_workflow_completed(self) -&gt; None:\n        \"\"\"Mark the workflow as completed.\"\"\"\n        state = cast(ExecutionState, self.metadata[\"execution_state\"])\n        state[\"status\"] = \"completed\"\n        state[\"completed_at\"] = datetime.now().isoformat()\n        state[\"current_step_name\"] = None\n        self.save()\n\n    def set_flow(self, flow_name: Optional[str]) -&gt; None:\n        \"\"\"Set the flow being executed.\"\"\"\n        state = cast(ExecutionState, self.metadata[\"execution_state\"])\n        state[\"flow\"] = flow_name\n        self.save()\n\n    def get_flow(self) -&gt; Optional[str]:\n        \"\"\"Get the name of the flow being executed.\"\"\"\n        state = cast(ExecutionState, self.metadata[\"execution_state\"])\n        return state.get(\"flow\")\n\n    def can_resume_from_step(self, step_name: str) -&gt; bool:\n        \"\"\"Check if workflow can be resumed from a specific step.\"\"\"\n        state = cast(ExecutionState, self.metadata[\"execution_state\"])\n        # Check if workflow is in failed state and has a failed step\n        if state[\"status\"] != \"failed\" or not state[\"failed_step\"]:\n            return False\n        # Check if the failed step matches the requested step\n        if state[\"failed_step\"][\"step_name\"] != step_name:\n            return False\n        # Ensure there's no active retry state for this step\n        if \"retry_counts\" in state and step_name in state[\"retry_counts\"]:\n            return False\n        return True\n\n    def get_executed_steps(self) -&gt; List[str]:\n        \"\"\"Get a list of successfully executed step names.\"\"\"\n        state = cast(ExecutionState, self.metadata[\"execution_state\"])\n        return state[\"completed_steps\"]\n\n    def reset_state(self) -&gt; None:\n        \"\"\"Reset the entire workflow state to initial values.\"\"\"\n        self.metadata[\"execution_state\"] = cast(\n            ExecutionState,\n            {\n                \"current_step_name\": None,\n                \"completed_steps\": [],\n                \"failed_step\": None,\n                \"step_outputs\": {},\n                \"last_updated\": datetime.now().isoformat(),\n                \"status\": \"not_started\",\n                \"flow\": None,\n                \"retry_counts\": {},\n                \"completed_at\": None,\n                \"error_flow_target\": None,\n            },\n        )\n        # Create a fresh copy of empty namespaces\n        self.metadata[\"namespaces\"] = {\n            \"args\": {},\n            \"env\": {},\n            \"steps\": {},\n            \"batch\": {},\n        }\n        self.save()\n\n    def get_step_retry_count(self, step_name: str) -&gt; int:\n        \"\"\"Get the current retry count for a specific step.\"\"\"\n        state = cast(ExecutionState, self.metadata[\"execution_state\"])\n        return state.setdefault(\"retry_counts\", {}).get(step_name, 0)\n\n    def increment_step_retry(self, step_name: str) -&gt; None:\n        \"\"\"Increment the retry count for a specific step.\"\"\"\n        state = cast(ExecutionState, self.metadata[\"execution_state\"])\n        retry_counts = state.setdefault(\"retry_counts\", {})\n        current_count = retry_counts.get(step_name, 0)\n        retry_counts[step_name] = current_count + 1\n        self.save()\n\n    def reset_step_retries(self, step_name: str) -&gt; None:\n        \"\"\"Clear the retry state for a specific step.\"\"\"\n        state = cast(ExecutionState, self.metadata[\"execution_state\"])\n        state.setdefault(\"retry_counts\", {}).pop(step_name, None)\n        self.save()\n\n    def set_error_flow_target(self, target_step_name: str) -&gt; None:\n        \"\"\"Set the target step for an error flow jump.\"\"\"\n        state = cast(ExecutionState, self.metadata[\"execution_state\"])\n        state[\"error_flow_target\"] = target_step_name\n        self.save()\n\n    def get_error_flow_target(self) -&gt; Optional[str]:\n        \"\"\"Get the target step for an error flow jump, if set.\"\"\"\n        state = cast(ExecutionState, self.metadata[\"execution_state\"])\n        return state.setdefault(\"error_flow_target\", None)\n\n    def clear_error_flow_target(self) -&gt; None:\n        \"\"\"Clear the error flow target step.\"\"\"\n        state = cast(ExecutionState, self.metadata[\"execution_state\"])\n        state[\"error_flow_target\"] = None\n        self.save()\n\n    def set_current_step(self, step_name: Optional[str]) -&gt; None:\n        \"\"\"Set the name of the step currently being executed.\"\"\"\n        state = cast(ExecutionState, self.metadata[\"execution_state\"])\n        state[\"current_step_name\"] = step_name\n        if step_name:\n            state[\"status\"] = \"in_progress\"\n        self.save()\n\n    def initialize_execution(self) -&gt; None:\n        \"\"\"Reset state for a new execution run (not resume).\"\"\"\n        state = cast(ExecutionState, self.metadata[\"execution_state\"])\n        state[\"current_step_name\"] = None\n        state[\"completed_steps\"] = []\n        state[\"failed_step\"] = None\n        state[\"step_outputs\"] = {}\n        state[\"status\"] = \"not_started\"\n        state[\"retry_counts\"] = {}\n        state[\"completed_at\"] = None\n        state[\"error_flow_target\"] = None\n        self.save()\n\n    def get_completed_outputs(self) -&gt; Dict[str, Any]:\n        \"\"\"Get the outputs of all completed steps.\"\"\"\n        state = cast(ExecutionState, self.metadata[\"execution_state\"])\n        return state[\"step_outputs\"]\n</code></pre>"},{"location":"reference/yaml_workflow/state/#yaml_workflow.state.WorkflowState-functions","title":"Functions","text":""},{"location":"reference/yaml_workflow/state/#yaml_workflow.state.WorkflowState.can_resume_from_step","title":"<code>can_resume_from_step(step_name: str) -&gt; bool</code>","text":"<p>Check if workflow can be resumed from a specific step.</p> Source code in <code>src/yaml_workflow/state.py</code> <pre><code>def can_resume_from_step(self, step_name: str) -&gt; bool:\n    \"\"\"Check if workflow can be resumed from a specific step.\"\"\"\n    state = cast(ExecutionState, self.metadata[\"execution_state\"])\n    # Check if workflow is in failed state and has a failed step\n    if state[\"status\"] != \"failed\" or not state[\"failed_step\"]:\n        return False\n    # Check if the failed step matches the requested step\n    if state[\"failed_step\"][\"step_name\"] != step_name:\n        return False\n    # Ensure there's no active retry state for this step\n    if \"retry_counts\" in state and step_name in state[\"retry_counts\"]:\n        return False\n    return True\n</code></pre>"},{"location":"reference/yaml_workflow/state/#yaml_workflow.state.WorkflowState.clear_error_flow_target","title":"<code>clear_error_flow_target() -&gt; None</code>","text":"<p>Clear the error flow target step.</p> Source code in <code>src/yaml_workflow/state.py</code> <pre><code>def clear_error_flow_target(self) -&gt; None:\n    \"\"\"Clear the error flow target step.\"\"\"\n    state = cast(ExecutionState, self.metadata[\"execution_state\"])\n    state[\"error_flow_target\"] = None\n    self.save()\n</code></pre>"},{"location":"reference/yaml_workflow/state/#yaml_workflow.state.WorkflowState.clear_namespace","title":"<code>clear_namespace(namespace: str) -&gt; None</code>","text":"<p>Clear all data from a namespace.</p> <p>Parameters:</p> Name Type Description Default <code>namespace</code> <code>str</code> <p>Name of the namespace to clear</p> required Source code in <code>src/yaml_workflow/state.py</code> <pre><code>def clear_namespace(self, namespace: str) -&gt; None:\n    \"\"\"Clear all data from a namespace.\n\n    Args:\n        namespace: Name of the namespace to clear\n    \"\"\"\n    namespaces = cast(Dict[str, Dict[str, Any]], self.metadata[\"namespaces\"])\n    if namespace in namespaces:\n        namespaces[namespace] = {}\n        self.save()\n</code></pre>"},{"location":"reference/yaml_workflow/state/#yaml_workflow.state.WorkflowState.get_completed_outputs","title":"<code>get_completed_outputs() -&gt; Dict[str, Any]</code>","text":"<p>Get the outputs of all completed steps.</p> Source code in <code>src/yaml_workflow/state.py</code> <pre><code>def get_completed_outputs(self) -&gt; Dict[str, Any]:\n    \"\"\"Get the outputs of all completed steps.\"\"\"\n    state = cast(ExecutionState, self.metadata[\"execution_state\"])\n    return state[\"step_outputs\"]\n</code></pre>"},{"location":"reference/yaml_workflow/state/#yaml_workflow.state.WorkflowState.get_error_flow_target","title":"<code>get_error_flow_target() -&gt; Optional[str]</code>","text":"<p>Get the target step for an error flow jump, if set.</p> Source code in <code>src/yaml_workflow/state.py</code> <pre><code>def get_error_flow_target(self) -&gt; Optional[str]:\n    \"\"\"Get the target step for an error flow jump, if set.\"\"\"\n    state = cast(ExecutionState, self.metadata[\"execution_state\"])\n    return state.setdefault(\"error_flow_target\", None)\n</code></pre>"},{"location":"reference/yaml_workflow/state/#yaml_workflow.state.WorkflowState.get_executed_steps","title":"<code>get_executed_steps() -&gt; List[str]</code>","text":"<p>Get a list of successfully executed step names.</p> Source code in <code>src/yaml_workflow/state.py</code> <pre><code>def get_executed_steps(self) -&gt; List[str]:\n    \"\"\"Get a list of successfully executed step names.\"\"\"\n    state = cast(ExecutionState, self.metadata[\"execution_state\"])\n    return state[\"completed_steps\"]\n</code></pre>"},{"location":"reference/yaml_workflow/state/#yaml_workflow.state.WorkflowState.get_flow","title":"<code>get_flow() -&gt; Optional[str]</code>","text":"<p>Get the name of the flow being executed.</p> Source code in <code>src/yaml_workflow/state.py</code> <pre><code>def get_flow(self) -&gt; Optional[str]:\n    \"\"\"Get the name of the flow being executed.\"\"\"\n    state = cast(ExecutionState, self.metadata[\"execution_state\"])\n    return state.get(\"flow\")\n</code></pre>"},{"location":"reference/yaml_workflow/state/#yaml_workflow.state.WorkflowState.get_namespace","title":"<code>get_namespace(namespace: str) -&gt; Dict[str, Any]</code>","text":"<p>Get all data from a namespace.</p> <p>Parameters:</p> Name Type Description Default <code>namespace</code> <code>str</code> <p>Name of the namespace to get</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str, Any]: Namespace data</p> Source code in <code>src/yaml_workflow/state.py</code> <pre><code>def get_namespace(self, namespace: str) -&gt; Dict[str, Any]:\n    \"\"\"Get all data from a namespace.\n\n    Args:\n        namespace: Name of the namespace to get\n\n    Returns:\n        Dict[str, Any]: Namespace data\n    \"\"\"\n    namespaces = cast(Dict[str, Dict[str, Any]], self.metadata[\"namespaces\"])\n    return namespaces.get(namespace, {})\n</code></pre>"},{"location":"reference/yaml_workflow/state/#yaml_workflow.state.WorkflowState.get_state","title":"<code>get_state() -&gt; Dict[str, Any]</code>","text":"<p>Get the current workflow state.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str, Any]: Current workflow state including execution state, step outputs, and namespaces</p> Source code in <code>src/yaml_workflow/state.py</code> <pre><code>def get_state(self) -&gt; Dict[str, Any]:\n    \"\"\"Get the current workflow state.\n\n    Returns:\n        Dict[str, Any]: Current workflow state including execution state, step outputs, and namespaces\n    \"\"\"\n    exec_state = cast(ExecutionState, self.metadata[\"execution_state\"])\n    return {\n        \"execution_state\": exec_state,\n        \"namespaces\": self.metadata[\"namespaces\"],\n        \"steps\": {\n            step: {\n                \"status\": (\n                    \"completed\"\n                    if step in exec_state[\"completed_steps\"]\n                    else (\n                        \"failed\"\n                        if exec_state[\"failed_step\"]\n                        and exec_state[\"failed_step\"][\"step_name\"] == step\n                        else \"not_started\"\n                    )\n                ),\n                \"outputs\": exec_state[\"step_outputs\"].get(step, {}),\n            }\n            for step in set(\n                exec_state[\"completed_steps\"]\n                + (\n                    [exec_state[\"failed_step\"][\"step_name\"]]\n                    if exec_state[\"failed_step\"]\n                    else []\n                )\n            )\n        },\n    }\n</code></pre>"},{"location":"reference/yaml_workflow/state/#yaml_workflow.state.WorkflowState.get_step_retry_count","title":"<code>get_step_retry_count(step_name: str) -&gt; int</code>","text":"<p>Get the current retry count for a specific step.</p> Source code in <code>src/yaml_workflow/state.py</code> <pre><code>def get_step_retry_count(self, step_name: str) -&gt; int:\n    \"\"\"Get the current retry count for a specific step.\"\"\"\n    state = cast(ExecutionState, self.metadata[\"execution_state\"])\n    return state.setdefault(\"retry_counts\", {}).get(step_name, 0)\n</code></pre>"},{"location":"reference/yaml_workflow/state/#yaml_workflow.state.WorkflowState.get_variable","title":"<code>get_variable(variable: str, namespace: str) -&gt; Any</code>","text":"<p>Get a variable from a specific namespace.</p> <p>Parameters:</p> Name Type Description Default <code>variable</code> <code>str</code> <p>Name of the variable to get</p> required <code>namespace</code> <code>str</code> <p>Namespace to get the variable from</p> required <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>Variable value</p> Source code in <code>src/yaml_workflow/state.py</code> <pre><code>def get_variable(self, variable: str, namespace: str) -&gt; Any:\n    \"\"\"Get a variable from a specific namespace.\n\n    Args:\n        variable: Name of the variable to get\n        namespace: Namespace to get the variable from\n\n    Returns:\n        Any: Variable value\n    \"\"\"\n    namespaces = cast(Dict[str, Dict[str, Any]], self.metadata[\"namespaces\"])\n    return namespaces.get(namespace, {}).get(variable)\n</code></pre>"},{"location":"reference/yaml_workflow/state/#yaml_workflow.state.WorkflowState.increment_step_retry","title":"<code>increment_step_retry(step_name: str) -&gt; None</code>","text":"<p>Increment the retry count for a specific step.</p> Source code in <code>src/yaml_workflow/state.py</code> <pre><code>def increment_step_retry(self, step_name: str) -&gt; None:\n    \"\"\"Increment the retry count for a specific step.\"\"\"\n    state = cast(ExecutionState, self.metadata[\"execution_state\"])\n    retry_counts = state.setdefault(\"retry_counts\", {})\n    current_count = retry_counts.get(step_name, 0)\n    retry_counts[step_name] = current_count + 1\n    self.save()\n</code></pre>"},{"location":"reference/yaml_workflow/state/#yaml_workflow.state.WorkflowState.initialize_execution","title":"<code>initialize_execution() -&gt; None</code>","text":"<p>Reset state for a new execution run (not resume).</p> Source code in <code>src/yaml_workflow/state.py</code> <pre><code>def initialize_execution(self) -&gt; None:\n    \"\"\"Reset state for a new execution run (not resume).\"\"\"\n    state = cast(ExecutionState, self.metadata[\"execution_state\"])\n    state[\"current_step_name\"] = None\n    state[\"completed_steps\"] = []\n    state[\"failed_step\"] = None\n    state[\"step_outputs\"] = {}\n    state[\"status\"] = \"not_started\"\n    state[\"retry_counts\"] = {}\n    state[\"completed_at\"] = None\n    state[\"error_flow_target\"] = None\n    self.save()\n</code></pre>"},{"location":"reference/yaml_workflow/state/#yaml_workflow.state.WorkflowState.mark_step_failed","title":"<code>mark_step_failed(step_name: str, error: str) -&gt; None</code>","text":"<p>Mark a step as terminally failed (retries exhausted/no error flow).</p> Source code in <code>src/yaml_workflow/state.py</code> <pre><code>def mark_step_failed(self, step_name: str, error: str) -&gt; None:\n    \"\"\"Mark a step as terminally failed (retries exhausted/no error flow).\"\"\"\n    state = cast(ExecutionState, self.metadata[\"execution_state\"])\n    self.reset_step_retries(step_name)\n    state[\"failed_step\"] = {\n        \"step_name\": step_name,\n        \"error\": error,\n        \"failed_at\": datetime.now().isoformat(),\n    }\n    state[\"status\"] = \"failed\"\n    self.save()\n</code></pre>"},{"location":"reference/yaml_workflow/state/#yaml_workflow.state.WorkflowState.mark_step_success","title":"<code>mark_step_success(step_name: str, outputs: Dict[str, Any]) -&gt; None</code>","text":"<p>Mark a step as completed successfully and store its outputs.</p> Source code in <code>src/yaml_workflow/state.py</code> <pre><code>def mark_step_success(self, step_name: str, outputs: Dict[str, Any]) -&gt; None:\n    \"\"\"Mark a step as completed successfully and store its outputs.\"\"\"\n    state = cast(ExecutionState, self.metadata[\"execution_state\"])\n    if step_name not in state[\"completed_steps\"]:\n        state[\"completed_steps\"].append(step_name)\n    state[\"step_outputs\"][step_name] = outputs\n    state[\"status\"] = \"in_progress\"\n    if state[\"failed_step\"] and state[\"failed_step\"][\"step_name\"] == step_name:\n        state[\"failed_step\"] = None\n    self.reset_step_retries(step_name)\n    self.save()\n</code></pre>"},{"location":"reference/yaml_workflow/state/#yaml_workflow.state.WorkflowState.mark_workflow_completed","title":"<code>mark_workflow_completed() -&gt; None</code>","text":"<p>Mark the workflow as completed.</p> Source code in <code>src/yaml_workflow/state.py</code> <pre><code>def mark_workflow_completed(self) -&gt; None:\n    \"\"\"Mark the workflow as completed.\"\"\"\n    state = cast(ExecutionState, self.metadata[\"execution_state\"])\n    state[\"status\"] = \"completed\"\n    state[\"completed_at\"] = datetime.now().isoformat()\n    state[\"current_step_name\"] = None\n    self.save()\n</code></pre>"},{"location":"reference/yaml_workflow/state/#yaml_workflow.state.WorkflowState.reset_state","title":"<code>reset_state() -&gt; None</code>","text":"<p>Reset the entire workflow state to initial values.</p> Source code in <code>src/yaml_workflow/state.py</code> <pre><code>def reset_state(self) -&gt; None:\n    \"\"\"Reset the entire workflow state to initial values.\"\"\"\n    self.metadata[\"execution_state\"] = cast(\n        ExecutionState,\n        {\n            \"current_step_name\": None,\n            \"completed_steps\": [],\n            \"failed_step\": None,\n            \"step_outputs\": {},\n            \"last_updated\": datetime.now().isoformat(),\n            \"status\": \"not_started\",\n            \"flow\": None,\n            \"retry_counts\": {},\n            \"completed_at\": None,\n            \"error_flow_target\": None,\n        },\n    )\n    # Create a fresh copy of empty namespaces\n    self.metadata[\"namespaces\"] = {\n        \"args\": {},\n        \"env\": {},\n        \"steps\": {},\n        \"batch\": {},\n    }\n    self.save()\n</code></pre>"},{"location":"reference/yaml_workflow/state/#yaml_workflow.state.WorkflowState.reset_step_retries","title":"<code>reset_step_retries(step_name: str) -&gt; None</code>","text":"<p>Clear the retry state for a specific step.</p> Source code in <code>src/yaml_workflow/state.py</code> <pre><code>def reset_step_retries(self, step_name: str) -&gt; None:\n    \"\"\"Clear the retry state for a specific step.\"\"\"\n    state = cast(ExecutionState, self.metadata[\"execution_state\"])\n    state.setdefault(\"retry_counts\", {}).pop(step_name, None)\n    self.save()\n</code></pre>"},{"location":"reference/yaml_workflow/state/#yaml_workflow.state.WorkflowState.save","title":"<code>save() -&gt; None</code>","text":"<p>Save current state to metadata file.</p> Source code in <code>src/yaml_workflow/state.py</code> <pre><code>def save(self) -&gt; None:\n    \"\"\"Save current state to metadata file.\"\"\"\n    self.metadata[\"execution_state\"][\"last_updated\"] = datetime.now().isoformat()\n    with open(self.metadata_path, \"w\") as f:\n        json.dump(self.metadata, f, indent=2)\n</code></pre>"},{"location":"reference/yaml_workflow/state/#yaml_workflow.state.WorkflowState.set_current_step","title":"<code>set_current_step(step_name: Optional[str]) -&gt; None</code>","text":"<p>Set the name of the step currently being executed.</p> Source code in <code>src/yaml_workflow/state.py</code> <pre><code>def set_current_step(self, step_name: Optional[str]) -&gt; None:\n    \"\"\"Set the name of the step currently being executed.\"\"\"\n    state = cast(ExecutionState, self.metadata[\"execution_state\"])\n    state[\"current_step_name\"] = step_name\n    if step_name:\n        state[\"status\"] = \"in_progress\"\n    self.save()\n</code></pre>"},{"location":"reference/yaml_workflow/state/#yaml_workflow.state.WorkflowState.set_error_flow_target","title":"<code>set_error_flow_target(target_step_name: str) -&gt; None</code>","text":"<p>Set the target step for an error flow jump.</p> Source code in <code>src/yaml_workflow/state.py</code> <pre><code>def set_error_flow_target(self, target_step_name: str) -&gt; None:\n    \"\"\"Set the target step for an error flow jump.\"\"\"\n    state = cast(ExecutionState, self.metadata[\"execution_state\"])\n    state[\"error_flow_target\"] = target_step_name\n    self.save()\n</code></pre>"},{"location":"reference/yaml_workflow/state/#yaml_workflow.state.WorkflowState.set_flow","title":"<code>set_flow(flow_name: Optional[str]) -&gt; None</code>","text":"<p>Set the flow being executed.</p> Source code in <code>src/yaml_workflow/state.py</code> <pre><code>def set_flow(self, flow_name: Optional[str]) -&gt; None:\n    \"\"\"Set the flow being executed.\"\"\"\n    state = cast(ExecutionState, self.metadata[\"execution_state\"])\n    state[\"flow\"] = flow_name\n    self.save()\n</code></pre>"},{"location":"reference/yaml_workflow/state/#yaml_workflow.state.WorkflowState.update_namespace","title":"<code>update_namespace(namespace: str, data: Dict[str, Any]) -&gt; None</code>","text":"<p>Update a namespace with new data.</p> <p>Parameters:</p> Name Type Description Default <code>namespace</code> <code>str</code> <p>Name of the namespace to update</p> required <code>data</code> <code>Dict[str, Any]</code> <p>Data to update the namespace with</p> required Source code in <code>src/yaml_workflow/state.py</code> <pre><code>def update_namespace(self, namespace: str, data: Dict[str, Any]) -&gt; None:\n    \"\"\"Update a namespace with new data.\n\n    Args:\n        namespace: Name of the namespace to update\n        data: Data to update the namespace with\n    \"\"\"\n    namespaces = cast(Dict[str, Dict[str, Any]], self.metadata[\"namespaces\"])\n    if namespace not in namespaces:\n        namespaces[namespace] = {}\n    namespaces[namespace].update(data)\n    self.save()\n</code></pre>"},{"location":"reference/yaml_workflow/step/","title":"yaml_workflow.step","text":""},{"location":"reference/yaml_workflow/step/#yaml_workflow.step","title":"<code>yaml_workflow.step</code>","text":""},{"location":"reference/yaml_workflow/step/#yaml_workflow.step-classes","title":"Classes","text":""},{"location":"reference/yaml_workflow/step/#yaml_workflow.step.Step","title":"<code>Step</code>","text":"<p>Represents a single step in the workflow.</p> Source code in <code>src/yaml_workflow/step.py</code> <pre><code>class Step:\n    \"\"\"Represents a single step in the workflow.\"\"\"\n\n    def __init__(\n        self,\n        step_data: dict,\n        context: dict,\n        workspace_dir: Path,\n        output_dir: Path,\n        template_engine: TemplateEngine,  # Add template_engine parameter\n    ):\n        self.data = step_data\n        self.context = context\n        self.workspace_dir = workspace_dir\n        self.output_dir = output_dir\n        self.template_engine = template_engine  # Store the engine instance\n        self.name = step_data.get(\"name\", \"Unnamed Step\")\n        self.task = step_data.get(\"task\", \"\")\n        self.inputs = step_data.get(\"inputs\", {})\n        self.condition = step_data.get(\"condition\")\n        self.on_error = step_data.get(\"on_error\", {})\n\n    def evaluate_condition(self) -&gt; bool:\n        \"\"\"Evaluate the step's condition.\"\"\"\n        if not self.condition:\n            return True\n        try:\n            # Use the stored template engine instance\n            resolved_condition = self.template_engine.process_template(\n                str(self.condition), self.context\n            )\n            # Ensure strict boolean interpretation\n            return str(resolved_condition).strip().lower() == \"true\"\n        except TemplateError as e:\n            logger.warning(\n                f\"Could not resolve condition for step '{self.name}': {e}. Skipping step.\"\n            )\n            return False\n        except Exception as e:\n            logger.warning(\n                f\"Unexpected error evaluating condition for step '{self.name}': {e}. Skipping step.\"\n            )\n            return False\n\n    def render_inputs(self) -&gt; dict:\n        \"\"\"Render input values using the template engine.\"\"\"\n        try:\n            # Use the stored template engine instance\n            return self.template_engine.process_value(self.inputs, self.context)\n        except TemplateError as e:\n            logger.error(f\"Template error rendering inputs for step '{self.name}': {e}\")\n            raise\n        except Exception as e:\n            logger.error(\n                f\"Unexpected error rendering inputs for step '{self.name}': {e}\"\n            )\n            raise TemplateError(\n                f\"Unexpected error rendering inputs: {e}\", original_error=e\n            )\n\n    def handle_error(self, error: Exception, context: dict) -&gt; dict:\n        \"\"\"Handle errors based on the on_error configuration.\"\"\"\n        action = self.on_error.get(\"action\", \"fail\")\n        message_template = self.on_error.get(\"message\")\n\n        # Ensure error is in context for message rendering\n        error_context = {**context, \"error\": str(error)}\n\n        final_message = f\"Error in step '{self.name}': {error}\"\n        if message_template:\n            try:\n                # Use the stored template engine instance\n                final_message = self.template_engine.process_template(\n                    message_template, error_context\n                )\n            except Exception as template_err:\n                logger.warning(\n                    f\"Failed to render custom error message for step '{self.name}': {template_err}\"\n                )\n                final_message = f\"Error in step '{self.name}': {error} (failed to render custom message)\"\n\n        if action == \"continue\":\n            logger.warning(\n                f\"Step '{self.name}' failed but workflow continues: {final_message}\"\n            )\n            return {\"success\": True, \"message\": final_message}  # Indicate handled\n        else:  # Default to fail\n            logger.error(f\"Step '{self.name}' failed: {final_message}\")\n            return {\"success\": False, \"message\": final_message}\n</code></pre>"},{"location":"reference/yaml_workflow/step/#yaml_workflow.step.Step-functions","title":"Functions","text":""},{"location":"reference/yaml_workflow/step/#yaml_workflow.step.Step.evaluate_condition","title":"<code>evaluate_condition() -&gt; bool</code>","text":"<p>Evaluate the step's condition.</p> Source code in <code>src/yaml_workflow/step.py</code> <pre><code>def evaluate_condition(self) -&gt; bool:\n    \"\"\"Evaluate the step's condition.\"\"\"\n    if not self.condition:\n        return True\n    try:\n        # Use the stored template engine instance\n        resolved_condition = self.template_engine.process_template(\n            str(self.condition), self.context\n        )\n        # Ensure strict boolean interpretation\n        return str(resolved_condition).strip().lower() == \"true\"\n    except TemplateError as e:\n        logger.warning(\n            f\"Could not resolve condition for step '{self.name}': {e}. Skipping step.\"\n        )\n        return False\n    except Exception as e:\n        logger.warning(\n            f\"Unexpected error evaluating condition for step '{self.name}': {e}. Skipping step.\"\n        )\n        return False\n</code></pre>"},{"location":"reference/yaml_workflow/step/#yaml_workflow.step.Step.handle_error","title":"<code>handle_error(error: Exception, context: dict) -&gt; dict</code>","text":"<p>Handle errors based on the on_error configuration.</p> Source code in <code>src/yaml_workflow/step.py</code> <pre><code>def handle_error(self, error: Exception, context: dict) -&gt; dict:\n    \"\"\"Handle errors based on the on_error configuration.\"\"\"\n    action = self.on_error.get(\"action\", \"fail\")\n    message_template = self.on_error.get(\"message\")\n\n    # Ensure error is in context for message rendering\n    error_context = {**context, \"error\": str(error)}\n\n    final_message = f\"Error in step '{self.name}': {error}\"\n    if message_template:\n        try:\n            # Use the stored template engine instance\n            final_message = self.template_engine.process_template(\n                message_template, error_context\n            )\n        except Exception as template_err:\n            logger.warning(\n                f\"Failed to render custom error message for step '{self.name}': {template_err}\"\n            )\n            final_message = f\"Error in step '{self.name}': {error} (failed to render custom message)\"\n\n    if action == \"continue\":\n        logger.warning(\n            f\"Step '{self.name}' failed but workflow continues: {final_message}\"\n        )\n        return {\"success\": True, \"message\": final_message}  # Indicate handled\n    else:  # Default to fail\n        logger.error(f\"Step '{self.name}' failed: {final_message}\")\n        return {\"success\": False, \"message\": final_message}\n</code></pre>"},{"location":"reference/yaml_workflow/step/#yaml_workflow.step.Step.render_inputs","title":"<code>render_inputs() -&gt; dict</code>","text":"<p>Render input values using the template engine.</p> Source code in <code>src/yaml_workflow/step.py</code> <pre><code>def render_inputs(self) -&gt; dict:\n    \"\"\"Render input values using the template engine.\"\"\"\n    try:\n        # Use the stored template engine instance\n        return self.template_engine.process_value(self.inputs, self.context)\n    except TemplateError as e:\n        logger.error(f\"Template error rendering inputs for step '{self.name}': {e}\")\n        raise\n    except Exception as e:\n        logger.error(\n            f\"Unexpected error rendering inputs for step '{self.name}': {e}\"\n        )\n        raise TemplateError(\n            f\"Unexpected error rendering inputs: {e}\", original_error=e\n        )\n</code></pre>"},{"location":"reference/yaml_workflow/template/","title":"yaml_workflow.template","text":""},{"location":"reference/yaml_workflow/template/#yaml_workflow.template","title":"<code>yaml_workflow.template</code>","text":"<p>Template engine implementation using Jinja2.</p>"},{"location":"reference/yaml_workflow/template/#yaml_workflow.template-classes","title":"Classes","text":""},{"location":"reference/yaml_workflow/template/#yaml_workflow.template.AttrDict","title":"<code>AttrDict</code>","text":"<p>               Bases: <code>dict</code></p> <p>A dictionary that allows attribute access to its keys.</p> Source code in <code>src/yaml_workflow/template.py</code> <pre><code>class AttrDict(dict):\n    \"\"\"A dictionary that allows attribute access to its keys.\"\"\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        for k, v in list(super().items()):\n            if isinstance(v, dict) and not isinstance(v, AttrDict):\n                self[k] = AttrDict(v)\n            elif isinstance(v, (list, tuple)):\n                self[k] = [AttrDict(i) if isinstance(i, dict) else i for i in v]\n\n    def __getattr__(self, key: str) -&gt; Any:\n        try:\n            # Always check the dictionary first\n            if key in self:\n                return self[key]\n            # If the key doesn't exist, try to get it as a method\n            if key in dir(dict):\n                method = getattr(super(), key)\n                # If it's a callable method, call it immediately\n                if callable(method):\n                    result = method()\n                    return result\n                return method\n            raise KeyError(key)\n        except KeyError as e:\n            raise AttributeError(key)\n\n    def __setattr__(self, key: str, value: Any) -&gt; None:\n        self[key] = value\n\n    def items(self):\n        \"\"\"Override items to ensure it returns a list of tuples.\"\"\"\n        return list(super().items())\n</code></pre>"},{"location":"reference/yaml_workflow/template/#yaml_workflow.template.AttrDict-functions","title":"Functions","text":""},{"location":"reference/yaml_workflow/template/#yaml_workflow.template.AttrDict.items","title":"<code>items()</code>","text":"<p>Override items to ensure it returns a list of tuples.</p> Source code in <code>src/yaml_workflow/template.py</code> <pre><code>def items(self):\n    \"\"\"Override items to ensure it returns a list of tuples.\"\"\"\n    return list(super().items())\n</code></pre>"},{"location":"reference/yaml_workflow/template/#yaml_workflow.template.TemplateEngine","title":"<code>TemplateEngine</code>","text":"<p>Template engine for processing Jinja2 templates.</p> Source code in <code>src/yaml_workflow/template.py</code> <pre><code>class TemplateEngine:\n    \"\"\"Template engine for processing Jinja2 templates.\"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize the template engine with strict undefined behavior.\"\"\"\n        self.env = Environment(\n            undefined=StrictUndefined,\n            autoescape=False,\n            trim_blocks=True,\n            lstrip_blocks=True,\n        )\n\n    def _extract_variable_path(self, template_str: str, error_msg: str) -&gt; str:\n        \"\"\"Extract the full variable path from the template string.\n\n        Args:\n            template_str: The template string being processed\n            error_msg: The error message from Jinja2\n\n        Returns:\n            str: The full variable path\n        \"\"\"\n        # Extract the undefined variable name from the error message\n        if \"'is undefined'\" in error_msg:\n            var_name = error_msg.split(\"'\")[1]\n        else:\n            # Handle attribute error\n            var_parts = error_msg.split(\"'\")\n            if len(var_parts) &gt;= 2:\n                var_name = var_parts[-2]\n            else:\n                var_name = \"unknown\"\n\n        # Find the variable in the template string\n        pattern = r\"{{\\s*([^}]+)\\s*}}\"\n        matches = re.findall(pattern, template_str)\n        for match in matches:\n            if var_name in match:\n                return match.strip()\n        return var_name\n\n    def process_template(\n        self, template_str: str, variables: Optional[Dict[str, Any]] = None\n    ) -&gt; Any:\n        \"\"\"Process a template string with the given variables.\n\n        Args:\n            template_str (str): The template string to process.\n            variables (Optional[Dict[str, Any]], optional): Variables to use in template processing.\n                Defaults to None.\n\n        Returns:\n            Any: The processed template value, preserving the original type.\n\n        Raises:\n            TemplateError: If there is an error processing the template.\n        \"\"\"\n        try:\n            # Initialize variables to empty dict if None\n            vars_dict: Dict[str, Any] = variables if variables is not None else {}\n\n            # If the template is just a variable reference, try to return the raw value\n            if template_str.strip().startswith(\"{{\") and template_str.strip().endswith(\n                \"}}\"\n            ):\n                var_path = template_str.strip()[2:-2].strip()\n                if \".\" in var_path:\n                    parts = var_path.split(\".\")\n                    current: Optional[Dict[str, Any]] = vars_dict\n                    for part in parts:\n                        if current is None or not isinstance(current, dict):\n                            break\n                        current = current.get(part)  # type: ignore\n                    if current is not None:\n                        return current\n\n            # Create a new template with the configured environment\n            template = self.env.from_string(template_str)\n\n            # Convert variables to AttrDict for proper attribute access\n            context = AttrDict(vars_dict)\n\n            # Process the template with the wrapped variables\n            return template.render(**context)\n\n        except UndefinedError as e:\n            # Get the full variable path from the template\n            var_path = self._extract_variable_path(template_str, str(e))\n            parts = var_path.split(\".\")\n\n            # Handle invalid namespace\n            if len(parts) &gt; 0:\n                namespace = parts[0]\n                if namespace not in vars_dict:\n                    error_msg = (\n                        f\"Template error: Invalid namespace '{namespace}'\\n\"\n                        f\"Available namespaces:\\n\"\n                    )\n                    for ns in sorted(vars_dict.keys()):\n                        if isinstance(vars_dict[ns], dict):\n                            error_msg += f\"  - {ns}\\n\"\n                    raise TemplateError(error_msg)\n\n                # Handle invalid attribute access\n                if len(parts) &gt; 2:\n                    try:\n                        current = vars_dict[namespace]\n                        if not isinstance(current, dict):\n                            raise TemplateError(\n                                f\"Template error: Cannot access attributes of non-dictionary value '{namespace}'\"\n                            )\n                        for part in parts[1:-1]:\n                            if not isinstance(current, dict):\n                                raise TemplateError(\n                                    f\"Template error: Cannot access attributes of non-dictionary value '{'.'.join(parts[:-1])}'\"\n                                )\n                            current = current[part]\n                        error_msg = (\n                            f\"Template error: Invalid attribute '{parts[-1]}' on {type(current).__name__}\\n\"\n                            f\"Type of '{'.'.join(parts[:-1])}' is '{type(current).__name__}'\"\n                        )\n                        raise TemplateError(error_msg)\n                    except (KeyError, AttributeError):\n                        pass\n\n                # Handle undefined variable in namespace\n                error_msg = (\n                    f\"Template error: Undefined variable '{var_path}'\\n\"\n                    f\"Available variables in '{namespace}' namespace:\\n\"\n                )\n                if namespace in vars_dict and isinstance(vars_dict[namespace], dict):\n                    for key in sorted(vars_dict[namespace].keys()):\n                        error_msg += f\"  - {key}\\n\"\n                raise TemplateError(error_msg)\n\n            # Handle root level undefined variable\n            error_msg = f\"Template error: Undefined variable '{var_path}'\\n\"\n            if vars_dict:\n                error_msg += \"Available variables:\\n\"\n                for key in sorted(vars_dict.keys()):\n                    error_msg += f\"  - {key}\\n\"\n            raise TemplateError(error_msg)\n\n        except TemplateSyntaxError as e:\n            raise TemplateError(f\"Template syntax error: {str(e)}\")\n        except Exception as e:\n            raise TemplateError(f\"Error processing template: {str(e)}\")\n\n    def process_value(self, value: Any, variables: Dict[str, Any]) -&gt; Any:\n        \"\"\"Process a value that may contain templates.\n\n        Args:\n            value: The value to process\n            variables: Dictionary of variables to use in template processing\n\n        Returns:\n            Any: The processed value\n        \"\"\"\n        if isinstance(value, str):\n            return self.process_template(value, variables)\n        elif isinstance(value, dict):\n            return {k: self.process_value(v, variables) for k, v in value.items()}\n        elif isinstance(value, list):\n            return [self.process_value(item, variables) for item in value]\n        return value\n</code></pre>"},{"location":"reference/yaml_workflow/template/#yaml_workflow.template.TemplateEngine-functions","title":"Functions","text":""},{"location":"reference/yaml_workflow/template/#yaml_workflow.template.TemplateEngine.process_template","title":"<code>process_template(template_str: str, variables: Optional[Dict[str, Any]] = None) -&gt; Any</code>","text":"<p>Process a template string with the given variables.</p> <p>Parameters:</p> Name Type Description Default <code>template_str</code> <code>str</code> <p>The template string to process.</p> required <code>variables</code> <code>Optional[Dict[str, Any]]</code> <p>Variables to use in template processing. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The processed template value, preserving the original type.</p> <p>Raises:</p> Type Description <code>TemplateError</code> <p>If there is an error processing the template.</p> Source code in <code>src/yaml_workflow/template.py</code> <pre><code>def process_template(\n    self, template_str: str, variables: Optional[Dict[str, Any]] = None\n) -&gt; Any:\n    \"\"\"Process a template string with the given variables.\n\n    Args:\n        template_str (str): The template string to process.\n        variables (Optional[Dict[str, Any]], optional): Variables to use in template processing.\n            Defaults to None.\n\n    Returns:\n        Any: The processed template value, preserving the original type.\n\n    Raises:\n        TemplateError: If there is an error processing the template.\n    \"\"\"\n    try:\n        # Initialize variables to empty dict if None\n        vars_dict: Dict[str, Any] = variables if variables is not None else {}\n\n        # If the template is just a variable reference, try to return the raw value\n        if template_str.strip().startswith(\"{{\") and template_str.strip().endswith(\n            \"}}\"\n        ):\n            var_path = template_str.strip()[2:-2].strip()\n            if \".\" in var_path:\n                parts = var_path.split(\".\")\n                current: Optional[Dict[str, Any]] = vars_dict\n                for part in parts:\n                    if current is None or not isinstance(current, dict):\n                        break\n                    current = current.get(part)  # type: ignore\n                if current is not None:\n                    return current\n\n        # Create a new template with the configured environment\n        template = self.env.from_string(template_str)\n\n        # Convert variables to AttrDict for proper attribute access\n        context = AttrDict(vars_dict)\n\n        # Process the template with the wrapped variables\n        return template.render(**context)\n\n    except UndefinedError as e:\n        # Get the full variable path from the template\n        var_path = self._extract_variable_path(template_str, str(e))\n        parts = var_path.split(\".\")\n\n        # Handle invalid namespace\n        if len(parts) &gt; 0:\n            namespace = parts[0]\n            if namespace not in vars_dict:\n                error_msg = (\n                    f\"Template error: Invalid namespace '{namespace}'\\n\"\n                    f\"Available namespaces:\\n\"\n                )\n                for ns in sorted(vars_dict.keys()):\n                    if isinstance(vars_dict[ns], dict):\n                        error_msg += f\"  - {ns}\\n\"\n                raise TemplateError(error_msg)\n\n            # Handle invalid attribute access\n            if len(parts) &gt; 2:\n                try:\n                    current = vars_dict[namespace]\n                    if not isinstance(current, dict):\n                        raise TemplateError(\n                            f\"Template error: Cannot access attributes of non-dictionary value '{namespace}'\"\n                        )\n                    for part in parts[1:-1]:\n                        if not isinstance(current, dict):\n                            raise TemplateError(\n                                f\"Template error: Cannot access attributes of non-dictionary value '{'.'.join(parts[:-1])}'\"\n                            )\n                        current = current[part]\n                    error_msg = (\n                        f\"Template error: Invalid attribute '{parts[-1]}' on {type(current).__name__}\\n\"\n                        f\"Type of '{'.'.join(parts[:-1])}' is '{type(current).__name__}'\"\n                    )\n                    raise TemplateError(error_msg)\n                except (KeyError, AttributeError):\n                    pass\n\n            # Handle undefined variable in namespace\n            error_msg = (\n                f\"Template error: Undefined variable '{var_path}'\\n\"\n                f\"Available variables in '{namespace}' namespace:\\n\"\n            )\n            if namespace in vars_dict and isinstance(vars_dict[namespace], dict):\n                for key in sorted(vars_dict[namespace].keys()):\n                    error_msg += f\"  - {key}\\n\"\n            raise TemplateError(error_msg)\n\n        # Handle root level undefined variable\n        error_msg = f\"Template error: Undefined variable '{var_path}'\\n\"\n        if vars_dict:\n            error_msg += \"Available variables:\\n\"\n            for key in sorted(vars_dict.keys()):\n                error_msg += f\"  - {key}\\n\"\n        raise TemplateError(error_msg)\n\n    except TemplateSyntaxError as e:\n        raise TemplateError(f\"Template syntax error: {str(e)}\")\n    except Exception as e:\n        raise TemplateError(f\"Error processing template: {str(e)}\")\n</code></pre>"},{"location":"reference/yaml_workflow/template/#yaml_workflow.template.TemplateEngine.process_value","title":"<code>process_value(value: Any, variables: Dict[str, Any]) -&gt; Any</code>","text":"<p>Process a value that may contain templates.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Any</code> <p>The value to process</p> required <code>variables</code> <code>Dict[str, Any]</code> <p>Dictionary of variables to use in template processing</p> required <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The processed value</p> Source code in <code>src/yaml_workflow/template.py</code> <pre><code>def process_value(self, value: Any, variables: Dict[str, Any]) -&gt; Any:\n    \"\"\"Process a value that may contain templates.\n\n    Args:\n        value: The value to process\n        variables: Dictionary of variables to use in template processing\n\n    Returns:\n        Any: The processed value\n    \"\"\"\n    if isinstance(value, str):\n        return self.process_template(value, variables)\n    elif isinstance(value, dict):\n        return {k: self.process_value(v, variables) for k, v in value.items()}\n    elif isinstance(value, list):\n        return [self.process_value(item, variables) for item in value]\n    return value\n</code></pre>"},{"location":"reference/yaml_workflow/types/","title":"yaml_workflow.types","text":""},{"location":"reference/yaml_workflow/types/#yaml_workflow.types","title":"<code>yaml_workflow.types</code>","text":"<p>Type definitions for the workflow engine.</p>"},{"location":"reference/yaml_workflow/types/#yaml_workflow.types-classes","title":"Classes","text":""},{"location":"reference/yaml_workflow/workspace/","title":"yaml_workflow.workspace","text":""},{"location":"reference/yaml_workflow/workspace/#yaml_workflow.workspace","title":"<code>yaml_workflow.workspace</code>","text":"<p>Workspace management for workflow execution.</p>"},{"location":"reference/yaml_workflow/workspace/#yaml_workflow.workspace-classes","title":"Classes","text":""},{"location":"reference/yaml_workflow/workspace/#yaml_workflow.workspace.BatchState","title":"<code>BatchState</code>","text":"<p>Manages batch processing state.</p> Source code in <code>src/yaml_workflow/workspace.py</code> <pre><code>class BatchState:\n    \"\"\"Manages batch processing state.\"\"\"\n\n    def __init__(self, workspace: Path, name: str):\n        \"\"\"Initialize batch state.\n\n        Args:\n            workspace: Workspace directory\n            name: Name of the batch\n        \"\"\"\n        self.workspace = workspace\n        self.name = name\n        self.state_dir = workspace / \"temp\" / \"batch_state\"\n        self.state_file = self.state_dir / f\"{name}.json\"\n\n        # Initialize with empty state\n        self.state: Dict[str, Any] = {\n            \"processed\": [],  # List[str]\n            \"failed\": {},  # Dict[str, Dict[str, str]]\n            \"template_errors\": {},  # Dict[str, Dict[str, str]]\n            \"namespaces\": {  # Dict[str, Dict[str, Any]]\n                \"args\": {},\n                \"env\": {},\n                \"steps\": {},\n                \"batch\": {},\n            },\n            \"stats\": {  # Dict[str, int]\n                \"total\": 0,\n                \"processed\": 0,\n                \"failed\": 0,\n                \"template_failures\": 0,\n                \"retried\": 0,\n            },\n        }\n\n        # Load existing state if available\n        if self.state_file.exists():\n            self._load_state()\n\n    def _load_state(self) -&gt; None:\n        \"\"\"Load state from file.\"\"\"\n        try:\n            state_data = json.loads(self.state_file.read_text())\n            self.state.update(state_data)\n        except Exception as e:\n            raise WorkflowError(f\"Failed to load batch state: {e}\")\n\n    def save(self) -&gt; None:\n        \"\"\"Save current state to file.\"\"\"\n        self.state_dir.mkdir(parents=True, exist_ok=True)\n        self.state_file.write_text(json.dumps(self.state, indent=2))\n\n    def mark_processed(self, item: Any, result: Dict[str, Any]) -&gt; None:\n        \"\"\"Mark an item as successfully processed.\n\n        Args:\n            item: The processed item\n            result: Processing result\n        \"\"\"\n        processed_items = cast(List[str], self.state[\"processed\"])\n        if str(item) not in processed_items:\n            processed_items.append(str(item))\n            self.state[\"stats\"][\"processed\"] += 1\n\n    def mark_failed(self, item: Any, error: str) -&gt; None:\n        \"\"\"Mark an item as failed.\n\n        Args:\n            item: The failed item\n            error: Error message\n        \"\"\"\n        failed_items = cast(Dict[str, Dict[str, str]], self.state[\"failed\"])\n        failed_items[str(item)] = {\n            \"error\": error,\n            \"timestamp\": str(datetime.now()),\n        }\n        self.state[\"stats\"][\"failed\"] += 1\n\n    def mark_template_error(self, item: Any, error: str) -&gt; None:\n        \"\"\"Mark an item as having a template error.\n\n        Args:\n            item: The item with template error\n            error: Template error message\n        \"\"\"\n        template_errors = cast(Dict[str, Dict[str, str]], self.state[\"template_errors\"])\n        template_errors[str(item)] = {\n            \"error\": error,\n            \"timestamp\": str(datetime.now()),\n        }\n        self.state[\"stats\"][\"template_failures\"] += 1\n\n    def update_namespace(self, namespace: str, data: Dict[str, Any]) -&gt; None:\n        \"\"\"Update namespace data.\n\n        Args:\n            namespace: Name of the namespace\n            data: Namespace data to update\n        \"\"\"\n        namespaces = cast(Dict[str, Dict[str, Any]], self.state[\"namespaces\"])\n        if namespace in namespaces:\n            namespaces[namespace].update(data)\n\n    def get_stats(self) -&gt; Dict[str, int]:\n        \"\"\"Get processing statistics.\n\n        Returns:\n            Dict containing processing statistics\n        \"\"\"\n        return cast(Dict[str, int], self.state[\"stats\"])\n\n    def reset(self) -&gt; None:\n        \"\"\"Reset batch state.\"\"\"\n        self.state = {\n            \"processed\": [],  # List[str]\n            \"failed\": {},  # Dict[str, Dict[str, str]]\n            \"template_errors\": {},  # Dict[str, Dict[str, str]]\n            \"namespaces\": {  # Dict[str, Dict[str, Any]]\n                \"args\": {},\n                \"env\": {},\n                \"steps\": {},\n                \"batch\": {},\n            },\n            \"stats\": {  # Dict[str, int]\n                \"total\": 0,\n                \"processed\": 0,\n                \"failed\": 0,\n                \"template_failures\": 0,\n                \"retried\": 0,\n            },\n        }\n        if self.state_file.exists():\n            self.state_file.unlink()\n</code></pre>"},{"location":"reference/yaml_workflow/workspace/#yaml_workflow.workspace.BatchState-functions","title":"Functions","text":""},{"location":"reference/yaml_workflow/workspace/#yaml_workflow.workspace.BatchState.get_stats","title":"<code>get_stats() -&gt; Dict[str, int]</code>","text":"<p>Get processing statistics.</p> <p>Returns:</p> Type Description <code>Dict[str, int]</code> <p>Dict containing processing statistics</p> Source code in <code>src/yaml_workflow/workspace.py</code> <pre><code>def get_stats(self) -&gt; Dict[str, int]:\n    \"\"\"Get processing statistics.\n\n    Returns:\n        Dict containing processing statistics\n    \"\"\"\n    return cast(Dict[str, int], self.state[\"stats\"])\n</code></pre>"},{"location":"reference/yaml_workflow/workspace/#yaml_workflow.workspace.BatchState.mark_failed","title":"<code>mark_failed(item: Any, error: str) -&gt; None</code>","text":"<p>Mark an item as failed.</p> <p>Parameters:</p> Name Type Description Default <code>item</code> <code>Any</code> <p>The failed item</p> required <code>error</code> <code>str</code> <p>Error message</p> required Source code in <code>src/yaml_workflow/workspace.py</code> <pre><code>def mark_failed(self, item: Any, error: str) -&gt; None:\n    \"\"\"Mark an item as failed.\n\n    Args:\n        item: The failed item\n        error: Error message\n    \"\"\"\n    failed_items = cast(Dict[str, Dict[str, str]], self.state[\"failed\"])\n    failed_items[str(item)] = {\n        \"error\": error,\n        \"timestamp\": str(datetime.now()),\n    }\n    self.state[\"stats\"][\"failed\"] += 1\n</code></pre>"},{"location":"reference/yaml_workflow/workspace/#yaml_workflow.workspace.BatchState.mark_processed","title":"<code>mark_processed(item: Any, result: Dict[str, Any]) -&gt; None</code>","text":"<p>Mark an item as successfully processed.</p> <p>Parameters:</p> Name Type Description Default <code>item</code> <code>Any</code> <p>The processed item</p> required <code>result</code> <code>Dict[str, Any]</code> <p>Processing result</p> required Source code in <code>src/yaml_workflow/workspace.py</code> <pre><code>def mark_processed(self, item: Any, result: Dict[str, Any]) -&gt; None:\n    \"\"\"Mark an item as successfully processed.\n\n    Args:\n        item: The processed item\n        result: Processing result\n    \"\"\"\n    processed_items = cast(List[str], self.state[\"processed\"])\n    if str(item) not in processed_items:\n        processed_items.append(str(item))\n        self.state[\"stats\"][\"processed\"] += 1\n</code></pre>"},{"location":"reference/yaml_workflow/workspace/#yaml_workflow.workspace.BatchState.mark_template_error","title":"<code>mark_template_error(item: Any, error: str) -&gt; None</code>","text":"<p>Mark an item as having a template error.</p> <p>Parameters:</p> Name Type Description Default <code>item</code> <code>Any</code> <p>The item with template error</p> required <code>error</code> <code>str</code> <p>Template error message</p> required Source code in <code>src/yaml_workflow/workspace.py</code> <pre><code>def mark_template_error(self, item: Any, error: str) -&gt; None:\n    \"\"\"Mark an item as having a template error.\n\n    Args:\n        item: The item with template error\n        error: Template error message\n    \"\"\"\n    template_errors = cast(Dict[str, Dict[str, str]], self.state[\"template_errors\"])\n    template_errors[str(item)] = {\n        \"error\": error,\n        \"timestamp\": str(datetime.now()),\n    }\n    self.state[\"stats\"][\"template_failures\"] += 1\n</code></pre>"},{"location":"reference/yaml_workflow/workspace/#yaml_workflow.workspace.BatchState.reset","title":"<code>reset() -&gt; None</code>","text":"<p>Reset batch state.</p> Source code in <code>src/yaml_workflow/workspace.py</code> <pre><code>def reset(self) -&gt; None:\n    \"\"\"Reset batch state.\"\"\"\n    self.state = {\n        \"processed\": [],  # List[str]\n        \"failed\": {},  # Dict[str, Dict[str, str]]\n        \"template_errors\": {},  # Dict[str, Dict[str, str]]\n        \"namespaces\": {  # Dict[str, Dict[str, Any]]\n            \"args\": {},\n            \"env\": {},\n            \"steps\": {},\n            \"batch\": {},\n        },\n        \"stats\": {  # Dict[str, int]\n            \"total\": 0,\n            \"processed\": 0,\n            \"failed\": 0,\n            \"template_failures\": 0,\n            \"retried\": 0,\n        },\n    }\n    if self.state_file.exists():\n        self.state_file.unlink()\n</code></pre>"},{"location":"reference/yaml_workflow/workspace/#yaml_workflow.workspace.BatchState.save","title":"<code>save() -&gt; None</code>","text":"<p>Save current state to file.</p> Source code in <code>src/yaml_workflow/workspace.py</code> <pre><code>def save(self) -&gt; None:\n    \"\"\"Save current state to file.\"\"\"\n    self.state_dir.mkdir(parents=True, exist_ok=True)\n    self.state_file.write_text(json.dumps(self.state, indent=2))\n</code></pre>"},{"location":"reference/yaml_workflow/workspace/#yaml_workflow.workspace.BatchState.update_namespace","title":"<code>update_namespace(namespace: str, data: Dict[str, Any]) -&gt; None</code>","text":"<p>Update namespace data.</p> <p>Parameters:</p> Name Type Description Default <code>namespace</code> <code>str</code> <p>Name of the namespace</p> required <code>data</code> <code>Dict[str, Any]</code> <p>Namespace data to update</p> required Source code in <code>src/yaml_workflow/workspace.py</code> <pre><code>def update_namespace(self, namespace: str, data: Dict[str, Any]) -&gt; None:\n    \"\"\"Update namespace data.\n\n    Args:\n        namespace: Name of the namespace\n        data: Namespace data to update\n    \"\"\"\n    namespaces = cast(Dict[str, Dict[str, Any]], self.state[\"namespaces\"])\n    if namespace in namespaces:\n        namespaces[namespace].update(data)\n</code></pre>"},{"location":"reference/yaml_workflow/workspace/#yaml_workflow.workspace-functions","title":"Functions","text":""},{"location":"reference/yaml_workflow/workspace/#yaml_workflow.workspace.create_workspace","title":"<code>create_workspace(workflow_name: str, custom_dir: Optional[str] = None, base_dir: str = 'runs') -&gt; Path</code>","text":"<p>Create a workspace directory for a workflow run.</p> <p>Parameters:</p> Name Type Description Default <code>workflow_name</code> <code>str</code> <p>Name of the workflow</p> required <code>custom_dir</code> <code>Optional[str]</code> <p>Optional custom directory path</p> <code>None</code> <code>base_dir</code> <code>str</code> <p>Base directory for workflow runs</p> <code>'runs'</code> <p>Returns:</p> Name Type Description <code>Path</code> <code>Path</code> <p>Path to the workspace directory</p> Source code in <code>src/yaml_workflow/workspace.py</code> <pre><code>def create_workspace(\n    workflow_name: str, custom_dir: Optional[str] = None, base_dir: str = \"runs\"\n) -&gt; Path:\n    \"\"\"\n    Create a workspace directory for a workflow run.\n\n    Args:\n        workflow_name: Name of the workflow\n        custom_dir: Optional custom directory path\n        base_dir: Base directory for workflow runs\n\n    Returns:\n        Path: Path to the workspace directory\n    \"\"\"\n    base_path = Path(base_dir)\n    base_path.mkdir(exist_ok=True)\n\n    sanitized_name = sanitize_name(workflow_name)\n\n    if custom_dir:\n        workspace = Path(custom_dir)\n    else:\n        # Get run number\n        run_number = get_next_run_number(base_path, sanitized_name)\n        workspace = base_path / f\"{sanitized_name}_run_{run_number}\"\n\n    # Create workspace directories\n    workspace.mkdir(parents=True, exist_ok=True)\n    (workspace / \"logs\").mkdir(exist_ok=True)\n    (workspace / \"output\").mkdir(exist_ok=True)\n    (workspace / \"temp\").mkdir(exist_ok=True)\n\n    # Create new metadata\n    metadata = {\n        \"workflow_name\": workflow_name,\n        \"created_at\": datetime.now().isoformat(),\n        \"run_number\": run_number if not custom_dir else 1,\n        \"custom_dir\": bool(custom_dir),\n        \"base_dir\": str(base_path.absolute()),\n    }\n\n    save_metadata(workspace, metadata)\n\n    return workspace\n</code></pre>"},{"location":"reference/yaml_workflow/workspace/#yaml_workflow.workspace.get_next_run_number","title":"<code>get_next_run_number(base_dir: Path, workflow_name: str) -&gt; int</code>","text":"<p>Get the next available run number for a workflow by checking metadata files.</p> <p>Parameters:</p> Name Type Description Default <code>base_dir</code> <code>Path</code> <p>Base directory containing workflow runs</p> required <code>workflow_name</code> <code>str</code> <p>Name of the workflow</p> required <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Next available run number</p> Source code in <code>src/yaml_workflow/workspace.py</code> <pre><code>def get_next_run_number(base_dir: Path, workflow_name: str) -&gt; int:\n    \"\"\"\n    Get the next available run number for a workflow by checking metadata files.\n\n    Args:\n        base_dir: Base directory containing workflow runs\n        workflow_name: Name of the workflow\n\n    Returns:\n        int: Next available run number\n    \"\"\"\n    sanitized_name = sanitize_name(workflow_name)\n    workspace = base_dir / sanitized_name\n\n    if not workspace.is_dir():\n        return 1\n\n    # Check metadata file\n    metadata_path = workspace / METADATA_FILE\n    if metadata_path.exists():\n        try:\n            with open(metadata_path) as f:\n                metadata = json.load(f)\n                run_number = metadata.get(\"run_number\", 0)\n                if run_number and isinstance(run_number, int):\n                    return run_number + 1\n        except (json.JSONDecodeError, IOError):\n            pass\n\n    return 1\n</code></pre>"},{"location":"reference/yaml_workflow/workspace/#yaml_workflow.workspace.get_run_number_from_metadata","title":"<code>get_run_number_from_metadata(workspace: Path) -&gt; Optional[int]</code>","text":"<p>Get run number from workspace metadata file.</p> <p>Parameters:</p> Name Type Description Default <code>workspace</code> <code>Path</code> <p>Workspace directory</p> required <p>Returns:</p> Type Description <code>Optional[int]</code> <p>Optional[int]: Run number if found in metadata, None otherwise</p> Source code in <code>src/yaml_workflow/workspace.py</code> <pre><code>def get_run_number_from_metadata(workspace: Path) -&gt; Optional[int]:\n    \"\"\"\n    Get run number from workspace metadata file.\n\n    Args:\n        workspace: Workspace directory\n\n    Returns:\n        Optional[int]: Run number if found in metadata, None otherwise\n    \"\"\"\n    metadata_path = workspace / METADATA_FILE\n    if metadata_path.exists():\n        try:\n            with open(metadata_path) as f:\n                metadata = json.load(f)\n                run_number = metadata.get(\"run_number\")\n                if isinstance(run_number, int):\n                    return run_number\n        except (json.JSONDecodeError, IOError):\n            pass\n    return None\n</code></pre>"},{"location":"reference/yaml_workflow/workspace/#yaml_workflow.workspace.get_workspace_info","title":"<code>get_workspace_info(workspace: Path) -&gt; Dict[str, Any]</code>","text":"<p>Get information about a workspace.</p> <p>Parameters:</p> Name Type Description Default <code>workspace</code> <code>Path</code> <p>Workspace directory</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>Dict[str, Any]</code> <p>Workspace information</p> Source code in <code>src/yaml_workflow/workspace.py</code> <pre><code>def get_workspace_info(workspace: Path) -&gt; Dict[str, Any]:\n    \"\"\"\n    Get information about a workspace.\n\n    Args:\n        workspace: Workspace directory\n\n    Returns:\n        dict: Workspace information\n    \"\"\"\n    metadata_path = workspace / METADATA_FILE\n    metadata = {}\n    if metadata_path.exists():\n        with open(metadata_path) as f:\n            metadata = json.load(f)\n\n    # Calculate size and file count\n    total_size = 0\n    file_count = 0\n    for root, _, files in os.walk(workspace):\n        for file in files:\n            file_path = Path(root) / file\n            total_size += file_path.stat().st_size\n            file_count += 1\n\n    return {\n        **metadata,\n        \"path\": str(workspace.absolute()),\n        \"size\": total_size,\n        \"files\": file_count,\n    }\n</code></pre>"},{"location":"reference/yaml_workflow/workspace/#yaml_workflow.workspace.resolve_path","title":"<code>resolve_path(workspace: Path, file_path: str, use_output_dir: bool = True) -&gt; Path</code>","text":"<p>Resolve a file path relative to the workspace directory.</p> <p>Parameters:</p> Name Type Description Default <code>workspace</code> <code>Path</code> <p>Workspace directory</p> required <code>file_path</code> <code>str</code> <p>File path to resolve</p> required <code>use_output_dir</code> <code>bool</code> <p>Whether to place files in the output directory by default</p> <code>True</code> <p>Returns:</p> Name Type Description <code>Path</code> <code>Path</code> <p>Resolved absolute path</p> <p>The function handles paths in the following way: 1. If the path is absolute, return it as is 2. If the path starts with output/, logs/, or temp/, resolve it relative to workspace 3. If use_output_dir is True and path doesn't start with a known directory, resolve relative to workspace/output/ 4. Otherwise, resolve relative to workspace</p> Source code in <code>src/yaml_workflow/workspace.py</code> <pre><code>def resolve_path(workspace: Path, file_path: str, use_output_dir: bool = True) -&gt; Path:\n    \"\"\"\n    Resolve a file path relative to the workspace directory.\n\n    Args:\n        workspace: Workspace directory\n        file_path: File path to resolve\n        use_output_dir: Whether to place files in the output directory by default\n\n    Returns:\n        Path: Resolved absolute path\n\n    The function handles paths in the following way:\n    1. If the path is absolute, return it as is\n    2. If the path starts with output/, logs/, or temp/, resolve it relative to workspace\n    3. If use_output_dir is True and path doesn't start with a known directory, resolve relative to workspace/output/\n    4. Otherwise, resolve relative to workspace\n    \"\"\"\n    path = Path(file_path)\n\n    # If path is absolute, return it as is\n    if path.is_absolute():\n        return path\n\n    # If path starts with a known workspace subdirectory, resolve relative to workspace\n    if any(file_path.startswith(prefix) for prefix in [\"output/\", \"logs/\", \"temp/\"]):\n        return workspace / path\n\n    # If use_output_dir is True and path doesn't start with a known directory, resolve relative to workspace/output/\n    if use_output_dir:\n        return workspace / \"output\" / path\n\n    # Otherwise, resolve relative to workspace\n    return workspace / path\n</code></pre>"},{"location":"reference/yaml_workflow/workspace/#yaml_workflow.workspace.sanitize_name","title":"<code>sanitize_name(name: str) -&gt; str</code>","text":"<p>Sanitize a name for use in file paths.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name to sanitize</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Sanitized name</p> Source code in <code>src/yaml_workflow/workspace.py</code> <pre><code>def sanitize_name(name: str) -&gt; str:\n    \"\"\"\n    Sanitize a name for use in file paths.\n\n    Args:\n        name: Name to sanitize\n\n    Returns:\n        str: Sanitized name\n    \"\"\"\n    # Replace spaces and special characters with underscores\n    return re.sub(r\"[^\\w\\-_]\", \"_\", name)\n</code></pre>"},{"location":"reference/yaml_workflow/workspace/#yaml_workflow.workspace.save_metadata","title":"<code>save_metadata(workspace: Path, metadata: Dict[str, Any]) -&gt; None</code>","text":"<p>Save metadata to the workspace directory.</p> Source code in <code>src/yaml_workflow/workspace.py</code> <pre><code>def save_metadata(workspace: Path, metadata: Dict[str, Any]) -&gt; None:\n    \"\"\"Save metadata to the workspace directory.\"\"\"\n    metadata_path = workspace / METADATA_FILE\n    with open(metadata_path, \"w\") as f:\n        json.dump(metadata, f, indent=2)\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/","title":"yaml_workflow.tasks","text":""},{"location":"reference/yaml_workflow/tasks/#yaml_workflow.tasks","title":"<code>yaml_workflow.tasks</code>","text":"<p>Task modules for the YAML Workflow Engine.</p> <p>This package contains various task modules that can be used in workflows. Each module provides specific functionality that can be referenced in workflow YAML files.</p>"},{"location":"reference/yaml_workflow/tasks/#yaml_workflow.tasks-classes","title":"Classes","text":""},{"location":"reference/yaml_workflow/tasks/#yaml_workflow.tasks.TaskConfig","title":"<code>TaskConfig</code>","text":"<p>Configuration class for task handlers with namespace support.</p> Source code in <code>src/yaml_workflow/tasks/config.py</code> <pre><code>class TaskConfig:\n    \"\"\"Configuration class for task handlers with namespace support.\"\"\"\n\n    def __init__(self, step: Dict[str, Any], context: Dict[str, Any], workspace: Path):\n        \"\"\"\n        Initialize task configuration.\n\n        Args:\n            step: Step configuration from workflow\n            context: Execution context with namespaces\n            workspace: Workspace path\n        \"\"\"\n        self.step = step  # Store the full step configuration\n        self.name = step.get(\"name\")\n        self.type = step.get(\"task\")\n        self.inputs = step.get(\"inputs\", {})\n        self._context = context\n        self.workspace = workspace\n        self._processed_inputs: Dict[str, Any] = {}\n        self._template_engine = TemplateEngine()\n\n    def get_variable(self, name: str, namespace: Optional[str] = None) -&gt; Any:\n        \"\"\"\n        Get a variable with namespace support.\n\n        Args:\n            name: Variable name\n            namespace: Optional namespace (args, env, steps)\n\n        Returns:\n            Any: Variable value if found\n        \"\"\"\n        if namespace:\n            return self._context.get(namespace, {}).get(name)\n        return self._context.get(name)\n\n    def get_available_variables(self) -&gt; Dict[str, List[str]]:\n        \"\"\"\n        Get available variables by namespace.\n\n        Returns:\n            Dict[str, List[str]]: Available variables in each namespace\n        \"\"\"\n        return {\n            \"args\": list(self._context.get(\"args\", {}).keys()),\n            \"env\": list(self._context.get(\"env\", {}).keys()),\n            \"steps\": list(self._context.get(\"steps\", {}).keys()),\n            \"root\": [\n                k for k in self._context.keys() if k not in [\"args\", \"env\", \"steps\"]\n            ],\n        }\n\n    def process_inputs(self) -&gt; Dict[str, Any]:\n        \"\"\"\n        Process task inputs with template resolution.\n\n        Recursively processes all string values in the inputs dictionary,\n        including nested dictionaries and lists.\n\n        Returns:\n            Dict[str, Any]: Processed inputs with resolved templates\n        \"\"\"\n        if not self._processed_inputs:\n            # Create a flattened context for template processing\n            template_context = {\n                \"args\": self._context.get(\"args\", {}),\n                \"env\": self._context.get(\"env\", {}),\n                \"steps\": self._context.get(\"steps\", {}),\n                **{\n                    k: v\n                    for k, v in self._context.items()\n                    if k not in [\"args\", \"env\", \"steps\"]\n                },\n            }\n\n            self._processed_inputs = self._process_value(self.inputs, template_context)\n        return self._processed_inputs\n\n    def _process_value(self, value: Any, template_context: Dict[str, Any]) -&gt; Any:\n        \"\"\"\n        Recursively process a value with template resolution.\n\n        Args:\n            value: Value to process\n            template_context: Template context for variable resolution\n\n        Returns:\n            Any: Processed value with resolved templates\n\n        Raises:\n            TaskExecutionError: If template processing fails due to undefined variables.\n        \"\"\"\n        if isinstance(value, str):\n            try:\n                result = self._template_engine.process_template(value, template_context)\n                # Try to convert string results back to their original type\n                if result == \"True\":\n                    return True\n                elif result == \"False\":\n                    return False\n                try:\n                    # First try to evaluate as a Python literal (for lists, dicts, etc.)\n                    import ast\n\n                    try:\n                        return ast.literal_eval(result)\n                    except (ValueError, SyntaxError):\n                        # If not a valid Python literal, try numeric conversion\n                        if \".\" in result:\n                            return float(result)\n                        return int(result)\n                except (ValueError, TypeError, SyntaxError):\n                    return result\n            except UndefinedError as e:\n                # Use the new centralized error handler\n                context = ErrorContext(\n                    step_name=str(self.name),\n                    task_type=str(self.type),\n                    error=e,\n                    task_config=self.step,\n                    template_context=template_context,\n                )\n                handle_task_error(context)\n        elif isinstance(value, dict):\n            return {\n                k: self._process_value(v, template_context) for k, v in value.items()\n            }\n        elif isinstance(value, list):\n            return [self._process_value(item, template_context) for item in value]\n        return value\n\n    def _get_undefined_namespace(self, error_msg: str) -&gt; str:\n        \"\"\"\n        Extract namespace from undefined variable error.\n\n        Args:\n            error_msg: Error message from UndefinedError\n\n        Returns:\n            str: Namespace name or 'root' if not found\n        \"\"\"\n        # Check for direct variable access pattern (e.g., args.undefined)\n        for namespace in [\"args\", \"env\", \"steps\"]:\n            if f\"{namespace}.\" in error_msg:\n                return namespace\n\n        # Check for dictionary access pattern (e.g., 'dict object' has no attribute 'undefined')\n        # Extract the undefined attribute name from the error message\n        match = re.search(r\"no attribute '(\\w+)'\", error_msg)\n        if match:\n            undefined_attr = match.group(1)\n            # Find which namespace was trying to access this attribute\n            for namespace in [\"args\", \"env\", \"steps\"]:\n                if namespace in self._context:\n                    template_str = next(\n                        (\n                            v\n                            for v in self.inputs.values()\n                            if isinstance(v, str)\n                            and f\"{namespace}.{undefined_attr}\" in v\n                        ),\n                        \"\",\n                    )\n                    if template_str:\n                        return namespace\n\n        return \"root\"\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/#yaml_workflow.tasks.TaskConfig-functions","title":"Functions","text":""},{"location":"reference/yaml_workflow/tasks/#yaml_workflow.tasks.TaskConfig.get_available_variables","title":"<code>get_available_variables() -&gt; Dict[str, List[str]]</code>","text":"<p>Get available variables by namespace.</p> <p>Returns:</p> Type Description <code>Dict[str, List[str]]</code> <p>Dict[str, List[str]]: Available variables in each namespace</p> Source code in <code>src/yaml_workflow/tasks/config.py</code> <pre><code>def get_available_variables(self) -&gt; Dict[str, List[str]]:\n    \"\"\"\n    Get available variables by namespace.\n\n    Returns:\n        Dict[str, List[str]]: Available variables in each namespace\n    \"\"\"\n    return {\n        \"args\": list(self._context.get(\"args\", {}).keys()),\n        \"env\": list(self._context.get(\"env\", {}).keys()),\n        \"steps\": list(self._context.get(\"steps\", {}).keys()),\n        \"root\": [\n            k for k in self._context.keys() if k not in [\"args\", \"env\", \"steps\"]\n        ],\n    }\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/#yaml_workflow.tasks.TaskConfig.get_variable","title":"<code>get_variable(name: str, namespace: Optional[str] = None) -&gt; Any</code>","text":"<p>Get a variable with namespace support.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Variable name</p> required <code>namespace</code> <code>Optional[str]</code> <p>Optional namespace (args, env, steps)</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>Variable value if found</p> Source code in <code>src/yaml_workflow/tasks/config.py</code> <pre><code>def get_variable(self, name: str, namespace: Optional[str] = None) -&gt; Any:\n    \"\"\"\n    Get a variable with namespace support.\n\n    Args:\n        name: Variable name\n        namespace: Optional namespace (args, env, steps)\n\n    Returns:\n        Any: Variable value if found\n    \"\"\"\n    if namespace:\n        return self._context.get(namespace, {}).get(name)\n    return self._context.get(name)\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/#yaml_workflow.tasks.TaskConfig.process_inputs","title":"<code>process_inputs() -&gt; Dict[str, Any]</code>","text":"<p>Process task inputs with template resolution.</p> <p>Recursively processes all string values in the inputs dictionary, including nested dictionaries and lists.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str, Any]: Processed inputs with resolved templates</p> Source code in <code>src/yaml_workflow/tasks/config.py</code> <pre><code>def process_inputs(self) -&gt; Dict[str, Any]:\n    \"\"\"\n    Process task inputs with template resolution.\n\n    Recursively processes all string values in the inputs dictionary,\n    including nested dictionaries and lists.\n\n    Returns:\n        Dict[str, Any]: Processed inputs with resolved templates\n    \"\"\"\n    if not self._processed_inputs:\n        # Create a flattened context for template processing\n        template_context = {\n            \"args\": self._context.get(\"args\", {}),\n            \"env\": self._context.get(\"env\", {}),\n            \"steps\": self._context.get(\"steps\", {}),\n            **{\n                k: v\n                for k, v in self._context.items()\n                if k not in [\"args\", \"env\", \"steps\"]\n            },\n        }\n\n        self._processed_inputs = self._process_value(self.inputs, template_context)\n    return self._processed_inputs\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/#yaml_workflow.tasks-functions","title":"Functions","text":""},{"location":"reference/yaml_workflow/tasks/#yaml_workflow.tasks.add_numbers","title":"<code>add_numbers(a: float, b: float) -&gt; float</code>","text":"<p>Add two numbers together.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>float</code> <p>First number</p> required <code>b</code> <code>float</code> <p>Second number</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>Sum of the numbers</p> Source code in <code>src/yaml_workflow/tasks/basic_tasks.py</code> <pre><code>@register_task()\ndef add_numbers(a: float, b: float) -&gt; float:\n    \"\"\"\n    Add two numbers together.\n\n    Args:\n        a: First number\n        b: Second number\n\n    Returns:\n        float: Sum of the numbers\n    \"\"\"\n    return a + b\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/#yaml_workflow.tasks.append_file_task","title":"<code>append_file_task(config: TaskConfig) -&gt; Optional[Dict[str, Any]]</code>","text":"<p>Append content to a file.</p> Source code in <code>src/yaml_workflow/tasks/file_tasks.py</code> <pre><code>@register_task(\"append_file\")\ndef append_file_task(config: TaskConfig) -&gt; Optional[Dict[str, Any]]:\n    \"\"\"Append content to a file.\"\"\"\n    task_name = str(config.name or \"append_file\")\n    task_type = config.type or \"append_file\"\n    logger = get_task_logger(config.workspace, task_name)\n    log_task_execution(logger, config.step, config._context, config.workspace)\n    try:\n        processed = config.process_inputs()\n        file_path = processed.get(\"file\")\n        content = processed.get(\"content\")\n        encoding = processed.get(\"encoding\", \"utf-8\")\n\n        if not file_path:\n            raise ValueError(\"No file path provided\")\n        if content is None:\n            raise ValueError(\"No content provided\")\n\n        result = append_file_direct(\n            file_path, str(content), config.workspace, encoding, task_name\n        )\n        output = {\"path\": result, \"content\": content}\n        log_task_result(logger, output)\n        return output\n    except Exception as e:\n        context = ErrorContext(\n            step_name=task_name,\n            task_type=task_type,\n            error=e,\n            task_config=config.step,\n            template_context=config._context,\n        )\n        handle_task_error(context)\n        return None\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/#yaml_workflow.tasks.batch_task","title":"<code>batch_task(config: TaskConfig) -&gt; Dict[str, Any]</code>","text":"<p>Process a batch of items using specified task configuration.</p> <p>This task processes a list of items in parallel chunks using the specified task configuration. Each item is passed to the task as an argument.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>TaskConfig</code> <p>TaskConfig object containing: - items: List of items to process - task: Task configuration for processing each item - arg_name: Name of the argument to use for each item (default: \"item\") - chunk_size: Optional size of chunks (default: 10) - max_workers: Optional maximum worker threads</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict containing: - processed: List of successfully processed items - failed: List of failed items with errors - results: List of processing results - stats: Processing statistics</p> Example YAML usage <pre><code>steps:\n  - name: process_data\n    task: batch\n    inputs:\n      items: [5, 7, 12]\n      arg_name: x  # Name items will be passed as\n      chunk_size: 2\n      max_workers: 2\n      task:\n        task: python\n        inputs:\n          operation: multiply\n          factor: 2\n</code></pre> Source code in <code>src/yaml_workflow/tasks/batch.py</code> <pre><code>@register_task(\"batch\")\ndef batch_task(config: TaskConfig) -&gt; Dict[str, Any]:\n    \"\"\"\n    Process a batch of items using specified task configuration.\n\n    This task processes a list of items in parallel chunks using the specified\n    task configuration. Each item is passed to the task as an argument.\n\n    Args:\n        config: TaskConfig object containing:\n            - items: List of items to process\n            - task: Task configuration for processing each item\n            - arg_name: Name of the argument to use for each item (default: \"item\")\n            - chunk_size: Optional size of chunks (default: 10)\n            - max_workers: Optional maximum worker threads\n\n    Returns:\n        Dict containing:\n            - processed: List of successfully processed items\n            - failed: List of failed items with errors\n            - results: List of processing results\n            - stats: Processing statistics\n\n    Example YAML usage:\n        ```yaml\n        steps:\n          - name: process_data\n            task: batch\n            inputs:\n              items: [5, 7, 12]\n              arg_name: x  # Name items will be passed as\n              chunk_size: 2\n              max_workers: 2\n              task:\n                task: python\n                inputs:\n                  operation: multiply\n                  factor: 2\n        ```\n    \"\"\"\n    task_name = config.name or \"batch_task\"\n    task_type = config.type or \"batch\"\n\n    try:\n        # Process inputs with template resolution\n        processed = config.process_inputs()\n\n        # Get required parameters\n        items = processed.get(\"items\")\n        if items is None:\n            raise ValueError(\"'items' parameter is required for batch task\")\n\n        # Ensure items is a list\n        if not isinstance(items, list):\n            raise ValueError(\"'items' must resolve to a list after template processing\")\n\n        task_config = processed.get(\"task\")\n        if not task_config:\n            raise ValueError(\n                \"'task' configuration is required within batch task inputs\"\n            )\n\n        # Get optional parameters with defaults\n        chunk_size = int(processed.get(\"chunk_size\", 10))\n        if chunk_size &lt;= 0:\n            raise ValueError(\"'chunk_size' must be greater than 0\")\n\n        max_workers = int(\n            processed.get(\"max_workers\", min(chunk_size, os.cpu_count() or 1))\n        )\n        if max_workers &lt;= 0:\n            raise ValueError(\"'max_workers' must be greater than 0\")\n\n        # Handle case where items list is empty after processing\n        if not items:\n            return {\n                \"processed\": [],\n                \"failed\": [],\n                \"results\": [],\n                \"stats\": {\n                    \"total\": 0,\n                    \"processed\": 0,\n                    \"failed\": 0,\n                    \"start_time\": datetime.now().isoformat(),\n                    \"end_time\": datetime.now().isoformat(),\n                    \"success_rate\": 100.0,\n                },\n            }\n\n        # Get argument name to use for items, defaulting to \"item\"\n        arg_name = processed.get(\"arg_name\", \"item\")\n\n        # Initialize state\n        state: Dict[str, Any] = {\n            \"processed\": [],\n            \"failed\": [],\n            \"results\": [],\n            \"stats\": {\n                \"total\": len(items),\n                \"processed\": 0,\n                \"failed\": 0,\n                \"start_time\": datetime.now().isoformat(),\n            },\n        }\n\n        # Store results with their indices for ordering\n        ordered_results: List[Tuple[int, Any]] = []\n        ordered_processed: List[Tuple[int, Any]] = []\n        ordered_failed: List[Tuple[int, Dict[str, Any]]] = []\n\n        # Process items in chunks\n        for chunk_index, chunk_start in enumerate(range(0, len(items), chunk_size)):\n            chunk = cast(List[Any], items[chunk_start : chunk_start + chunk_size])\n\n            with ThreadPoolExecutor(max_workers=max_workers) as executor:\n                futures = {}\n\n                # Submit tasks for chunk\n                for item_index, item in enumerate(chunk):\n                    # Pass the sub-task config, not the main batch config inputs\n                    sub_task_config_for_item = task_config\n                    future = executor.submit(\n                        process_item,\n                        item,  # item: Any\n                        sub_task_config_for_item,  # task_config: Dict[str, Any]\n                        config._context,  # context: Dict[str, Any]\n                        config.workspace,  # workspace: Path\n                        arg_name,  # arg_name: str\n                        chunk_index,  # chunk_index: int\n                        chunk_start + item_index,  # item_index: int\n                        len(items),  # total: int\n                        chunk_size,  # chunk_size: int\n                    )\n                    futures[future] = (item, chunk_start + item_index)\n\n                # Process completed futures\n                for future in as_completed(futures):\n                    item, index = futures[future]\n                    try:\n                        result = future.result()\n                        ordered_processed.append((index, item))\n                        ordered_results.append((index, result))\n                        state[\"stats\"][\"processed\"] += 1\n                    except Exception as e:\n                        # Capture the error from process_item (already wrapped if needed)\n                        error_info = {\"item\": item, \"error\": str(e)}\n                        # If it's a TaskExecutionError, add more details if possible\n                        if isinstance(e, TaskExecutionError):\n                            error_info[\"step_name\"] = e.step_name\n                            if e.task_config:\n                                error_info[\"task_config\"] = e.task_config\n                        ordered_failed.append((index, error_info))\n                        state[\"stats\"][\"failed\"] += 1\n\n        # Sort results by index and extract values\n        state[\"processed\"] = [item for _, item in sorted(ordered_processed)]\n        state[\"results\"] = [result for _, result in sorted(ordered_results)]\n        state[\"failed\"] = [error for _, error in sorted(ordered_failed)]\n\n        # Add completion statistics\n        state[\"stats\"][\"end_time\"] = datetime.now().isoformat()\n        total_items = state[\"stats\"][\"total\"]\n        processed_items = state[\"stats\"][\"processed\"]\n        state[\"stats\"][\"success_rate\"] = (\n            (processed_items / total_items) * 100.0\n            if total_items &gt; 0\n            else 100.0  # Avoid division by zero if total is 0\n        )\n\n        return state\n\n    except Exception as e:\n        # Centralized error handling for exceptions during batch setup/config\n        err_context = ErrorContext(\n            step_name=str(task_name),\n            task_type=str(task_type),\n            error=e,\n            task_config=config.step,\n            template_context=config._context,\n        )\n        handle_task_error(err_context)\n        # handle_task_error always raises, so return is unreachable but satisfies type checker\n        return {}\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/#yaml_workflow.tasks.create_greeting","title":"<code>create_greeting(name: str, context: Dict[str, Any]) -&gt; str</code>","text":"<p>Create a greeting message.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name to greet</p> required <code>context</code> <code>Dict[str, Any]</code> <p>Template context</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Greeting message</p> <p>Raises:</p> Type Description <code>TemplateError</code> <p>If template resolution fails</p> Source code in <code>src/yaml_workflow/tasks/basic_tasks.py</code> <pre><code>@register_task()\ndef create_greeting(name: str, context: Dict[str, Any]) -&gt; str:\n    \"\"\"\n    Create a greeting message.\n\n    Args:\n        name: Name to greet\n        context: Template context\n\n    Returns:\n        str: Greeting message\n\n    Raises:\n        TemplateError: If template resolution fails\n    \"\"\"\n    try:\n        template = Template(\"Hello {{ name }}!\", undefined=StrictUndefined)\n        return template.render(name=name, **context)\n    except UndefinedError as e:\n        available = {\n            \"name\": name,\n            \"args\": list(context[\"args\"].keys()) if \"args\" in context else [],\n            \"env\": list(context[\"env\"].keys()) if \"env\" in context else [],\n            \"steps\": list(context[\"steps\"].keys()) if \"steps\" in context else [],\n        }\n        raise TemplateError(f\"{str(e)}. Available variables: {available}\")\n    except Exception as e:\n        raise TemplateError(f\"Failed to create greeting: {str(e)}\")\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/#yaml_workflow.tasks.echo","title":"<code>echo(message: str) -&gt; str</code>","text":"<p>Echo back the input message.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Message to echo</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The input message</p> Source code in <code>src/yaml_workflow/tasks/basic_tasks.py</code> <pre><code>@register_task()\ndef echo(message: str) -&gt; str:\n    \"\"\"\n    Echo back the input message.\n\n    Args:\n        message: Message to echo\n\n    Returns:\n        str: The input message\n    \"\"\"\n    return message\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/#yaml_workflow.tasks.fail","title":"<code>fail(message: str = 'Task failed') -&gt; None</code>","text":"<p>A task that always fails.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Error message</p> <code>'Task failed'</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>Always raises this error</p> Source code in <code>src/yaml_workflow/tasks/basic_tasks.py</code> <pre><code>@register_task()\ndef fail(message: str = \"Task failed\") -&gt; None:\n    \"\"\"\n    A task that always fails.\n\n    Args:\n        message: Error message\n\n    Raises:\n        RuntimeError: Always raises this error\n    \"\"\"\n    raise RuntimeError(message)\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/#yaml_workflow.tasks.get_task_handler","title":"<code>get_task_handler(name: str) -&gt; Optional[TaskHandler]</code>","text":"<p>Get a task handler by name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Task name</p> required <p>Returns:</p> Type Description <code>Optional[TaskHandler]</code> <p>Optional[TaskHandler]: Task handler if found</p> Source code in <code>src/yaml_workflow/tasks/__init__.py</code> <pre><code>def get_task_handler(name: str) -&gt; Optional[TaskHandler]:\n    \"\"\"Get a task handler by name.\n\n    Args:\n        name: Task name\n\n    Returns:\n        Optional[TaskHandler]: Task handler if found\n    \"\"\"\n    handler = _task_registry.get(name)\n    # print(f\"--- get_task_handler requested: '{name}', found: {handler} ---\") # DEBUG\n    logging.debug(f\"Retrieved handler for task '{name}': {handler}\")\n    return handler\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/#yaml_workflow.tasks.hello_world","title":"<code>hello_world(name: str = 'World') -&gt; str</code>","text":"<p>A simple hello world function.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name to include in greeting. Defaults to \"World\".</p> <code>'World'</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The greeting message</p> Source code in <code>src/yaml_workflow/tasks/basic_tasks.py</code> <pre><code>@register_task()\ndef hello_world(name: str = \"World\") -&gt; str:\n    \"\"\"\n    A simple hello world function.\n\n    Args:\n        name: Name to include in greeting. Defaults to \"World\".\n\n    Returns:\n        str: The greeting message\n    \"\"\"\n    return f\"Hello, {name}!\"\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/#yaml_workflow.tasks.join_strings","title":"<code>join_strings(*strings: str, separator: str = ' ') -&gt; str</code>","text":"<p>Join multiple strings together.</p> <p>Parameters:</p> Name Type Description Default <code>*strings</code> <code>str</code> <p>Variable number of strings to join</p> <code>()</code> <code>separator</code> <code>str</code> <p>String to use as separator. Defaults to space.</p> <code>' '</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Joined string</p> Source code in <code>src/yaml_workflow/tasks/basic_tasks.py</code> <pre><code>@register_task()\ndef join_strings(*strings: str, separator: str = \" \") -&gt; str:\n    \"\"\"\n    Join multiple strings together.\n\n    Args:\n        *strings: Variable number of strings to join\n        separator: String to use as separator. Defaults to space.\n\n    Returns:\n        str: Joined string\n    \"\"\"\n    return separator.join(strings)\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/#yaml_workflow.tasks.print_vars_task","title":"<code>print_vars_task(config: TaskConfig) -&gt; dict</code>","text":"<p>Prints selected variables from the context for debugging.</p> Source code in <code>src/yaml_workflow/tasks/python_tasks.py</code> <pre><code>@register_task()\ndef print_vars_task(config: TaskConfig) -&gt; dict:\n    \"\"\"Prints selected variables from the context for debugging.\"\"\"\n    inputs = config.process_inputs()\n    context = config._context\n    message = inputs.get(\"message\", \"Current Context Variables:\")\n\n    print(f\"\\n--- {message} ---\")  # Prints directly to runner's stdout\n\n    # Select variables to print (add more as needed)\n    print(\"Workflow Variables:\")\n    print(\"==================\")\n    # Use direct context access via config.context\n    print(f\"args: {context.get('args')}\")\n    print(f\"workflow_name: {context.get('workflow_name')}\")\n    print(f\"workspace: {context.get('workspace')}\")\n    print(f\"output: {context.get('output')}\")\n    print(f\"run_number: {context.get('run_number')}\")\n    print(f\"timestamp: {context.get('timestamp')}\")\n\n    # Safely access nested step results\n    print(\"\\nStep Results:\")\n    print(\"=============\")\n    steps_context = context.get(\"steps\", {})\n    if steps_context:\n        # Use pprint for potentially large/nested step results\n        pprint.pprint(steps_context, indent=2)\n        # for name, step_info in steps_context.items():\n        #     if step_info.get(\"skipped\"):\n        #         print(f\"  - {name}: (skipped)\")\n        #     else:\n        #         # Truncate long results for clarity\n        #         result_repr = repr(step_info.get('result', 'N/A'))\n        #         if len(result_repr) &gt; 100:\n        #             result_repr = result_repr[:100] + \"...\"\n        #         print(f\"  - {name}: {result_repr}\")\n    else:\n        print(\"  (No step results yet)\")\n\n    print(\"--------------------\\n\")\n    sys.stdout.flush()  # Flush after printing\n    return {\"success\": True}  # Indicate task success\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/#yaml_workflow.tasks.read_file_task","title":"<code>read_file_task(config: TaskConfig) -&gt; Optional[Dict[str, Any]]</code>","text":"<p>Read content from a file.</p> Source code in <code>src/yaml_workflow/tasks/file_tasks.py</code> <pre><code>@register_task(\"read_file\")\ndef read_file_task(config: TaskConfig) -&gt; Optional[Dict[str, Any]]:\n    \"\"\"Read content from a file.\"\"\"\n    task_name = str(config.name or \"read_file\")\n    task_type = config.type or \"read_file\"\n    logger = get_task_logger(config.workspace, task_name)\n    log_task_execution(logger, config.step, config._context, config.workspace)\n    try:\n        processed = config.process_inputs()\n        file_path_input = processed.get(\"file\")\n        encoding = processed.get(\"encoding\", \"utf-8\")\n\n        if not file_path_input:\n            raise ValueError(\"No file path provided\")\n\n        content = read_file_direct(\n            file_path_input, config.workspace, encoding, task_name\n        )\n        output = {\"path\": file_path_input, \"content\": content}\n        log_task_result(logger, output)\n        return output\n    except Exception as e:\n        context = ErrorContext(\n            step_name=task_name,\n            task_type=task_type,\n            error=e,\n            task_config=config.step,\n            template_context=config._context,\n        )\n        handle_task_error(context)\n        return None\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/#yaml_workflow.tasks.read_json_task","title":"<code>read_json_task(config: TaskConfig) -&gt; Optional[Dict[str, Any]]</code>","text":"<p>Task handler for reading JSON files.</p> Source code in <code>src/yaml_workflow/tasks/file_tasks.py</code> <pre><code>@register_task(\"read_json\")\ndef read_json_task(config: TaskConfig) -&gt; Optional[Dict[str, Any]]:\n    \"\"\"Task handler for reading JSON files.\"\"\"\n    task_name = str(config.name or \"read_json\")\n    task_type = config.type or \"read_json\"\n    logger = get_task_logger(config.workspace, task_name)\n    log_task_execution(logger, config.step, config._context, config.workspace)\n\n    try:\n        processed = config.process_inputs()\n        file_path = processed.get(\"file\")\n        encoding = processed.get(\"encoding\", \"utf-8\")\n\n        if not file_path:\n            raise ValueError(\"No file path provided\")\n\n        result_data = read_json(file_path, config.workspace, encoding=encoding)\n        output = {\"data\": result_data}\n        log_task_result(logger, output)\n        return output\n    except Exception as e:\n        context = ErrorContext(\n            step_name=task_name,\n            task_type=task_type,\n            error=e,\n            task_config=config.step,\n            template_context=config._context,\n        )\n        handle_task_error(context)\n        return None\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/#yaml_workflow.tasks.read_yaml_task","title":"<code>read_yaml_task(config: TaskConfig) -&gt; Optional[Dict[str, Any]]</code>","text":"<p>Task handler for reading YAML files.</p> Source code in <code>src/yaml_workflow/tasks/file_tasks.py</code> <pre><code>@register_task(\"read_yaml\")\ndef read_yaml_task(config: TaskConfig) -&gt; Optional[Dict[str, Any]]:\n    \"\"\"Task handler for reading YAML files.\"\"\"\n    task_name = str(config.name or \"read_yaml\")\n    task_type = config.type or \"read_yaml\"\n    logger = get_task_logger(config.workspace, task_name)\n    log_task_execution(logger, config.step, config._context, config.workspace)\n\n    try:\n        processed = config.process_inputs()\n        file_path = processed.get(\"file\")\n        encoding = processed.get(\"encoding\", \"utf-8\")\n\n        if not file_path:\n            raise ValueError(\"No file path provided\")\n\n        result_data = read_yaml(file_path, config.workspace, encoding=encoding)\n        output = {\"data\": result_data}\n        log_task_result(logger, output)\n        return output\n    except Exception as e:\n        context = ErrorContext(\n            step_name=task_name,\n            task_type=task_type,\n            error=e,\n            task_config=config.step,\n            template_context=config._context,\n        )\n        handle_task_error(context)\n        return None\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/#yaml_workflow.tasks.register_task","title":"<code>register_task(name: Optional[str] = None) -&gt; Callable[..., Callable[[TaskConfig], R]]</code>","text":"<p>Decorator to register a function as a workflow task.</p> Source code in <code>src/yaml_workflow/tasks/__init__.py</code> <pre><code>def register_task(\n    name: Optional[str] = None,\n) -&gt; Callable[..., Callable[[TaskConfig], R]]:\n    \"\"\"Decorator to register a function as a workflow task.\"\"\"\n\n    def task_wrapper(func: Callable[..., R]) -&gt; Callable[[TaskConfig], R]:\n        task_name = name or func.__name__\n\n        @wraps(func)\n        def wrapper(config: TaskConfig) -&gt; R:\n            sig = inspect.signature(func)\n            params = sig.parameters\n\n            # Simplified Check: Handle tasks taking only TaskConfig first\n            if (\n                list(params.keys()) == [\"config\"]\n                and params[\"config\"].annotation is TaskConfig\n            ):\n                return func(config)\n\n            processed = config.process_inputs()\n            kwargs = {}\n            pos_args = []\n            extra_kwargs: Dict[str, Any] = {}  # For **kwargs\n            unmapped_inputs = (\n                processed.copy()\n            )  # Track inputs not mapped to named params\n\n            # Identify special parameter names (*args, **kwargs, config, context)\n            var_arg_name: Optional[str] = None\n            kw_arg_name: Optional[str] = None\n            config_param_name: Optional[str] = None\n            context_param_name: Optional[str] = None\n\n            for name, param in params.items():\n                if param.annotation is TaskConfig:\n                    config_param_name = name\n                elif name == \"context\" and param.annotation in (\n                    Dict[str, Any],\n                    dict,\n                    Any,\n                ):\n                    context_param_name = name\n                elif param.kind == param.VAR_POSITIONAL:\n                    var_arg_name = name\n                elif param.kind == param.VAR_KEYWORD:\n                    kw_arg_name = name\n\n            # Map processed inputs to function arguments\n            for name, param in params.items():\n                if name == config_param_name or name == context_param_name:\n                    continue  # Skip special params for now\n                if name == var_arg_name or name == kw_arg_name:\n                    continue  # Skip *args/**kwargs for now\n\n                if name in processed:\n                    kwargs[name] = processed[name]\n                    del unmapped_inputs[name]  # Mark as mapped\n                elif param.default is inspect.Parameter.empty:\n                    # Check if required named param is missing from inputs\n                    raise ValueError(f\"Missing required parameter: {name}\")\n                # else: use default value (implicitly handled by function call)\n\n            # Handle remaining unmapped inputs\n            if var_arg_name and var_arg_name in processed:\n                # If *args name exists as an input key (e.g., join_strings(strings=...))\n                arg_input = processed[var_arg_name]\n                pos_args = (\n                    list(arg_input)\n                    if isinstance(arg_input, (list, tuple))\n                    else [arg_input]\n                )\n                if var_arg_name in unmapped_inputs:\n                    del unmapped_inputs[var_arg_name]\n            elif var_arg_name:\n                # If *args exists but no input key matches, maybe map remaining unmapped inputs?\n                # This is ambiguous. Let's require explicit mapping for now.\n                # If len(unmapped_inputs) == 1 and var_arg_name:\n                #      pos_args = list(unmapped_inputs.values())[0]\n                #      if not isinstance(pos_args, list): pos_args = [pos_args]\n                #      unmapped_inputs.clear()\n                pass  # Requires explicit input name for *args mapping\n\n            # Assign remaining unmapped inputs to **kwargs if available\n            if kw_arg_name and unmapped_inputs:\n                kwargs[kw_arg_name] = unmapped_inputs\n            elif unmapped_inputs and not var_arg_name:\n                # If unmapped inputs remain and there's no **kwargs or *args to catch them,\n                # it might indicate an issue (e.g., typo in YAML input name).\n                # However, the function call itself will raise TypeError if unexpected args are passed.\n                # Let the function call handle the final validation for unexpected kwargs.\n                pass\n\n            # Inject config and context if needed\n            if config_param_name:\n                kwargs[config_param_name] = config\n            if context_param_name:\n                # Access the protected context member\n                kwargs[context_param_name] = (\n                    config._context\n                )  # Pass the full context dict\n\n            # Call the function\n            try:\n                return func(*pos_args, **kwargs)\n            except TypeError as e:\n                arg_summary = f\"pos_args={pos_args}, kwargs={list(kwargs.keys())}\"\n                logging.error(\n                    f\"TypeError calling task '{task_name}': {e}. Call info: {arg_summary}\"\n                )\n                raise\n\n        _task_registry[task_name] = wrapper\n        return wrapper\n\n    return task_wrapper\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/#yaml_workflow.tasks.render_template","title":"<code>render_template(config: TaskConfig) -&gt; Dict[str, Any]</code>","text":"<p>Render a template and save it to a file.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>TaskConfig</code> <p>Task configuration object</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str, Any]: Dictionary containing the path to the output file</p> <p>Raises:</p> Type Description <code>TaskExecutionError</code> <p>If template resolution fails or file cannot be written (via handle_task_error)</p> Source code in <code>src/yaml_workflow/tasks/template_tasks.py</code> <pre><code>@register_task(\"template\")\ndef render_template(config: TaskConfig) -&gt; Dict[str, Any]:\n    \"\"\"\n    Render a template and save it to a file.\n\n    Args:\n        config: Task configuration object\n\n    Returns:\n        Dict[str, Any]: Dictionary containing the path to the output file\n\n    Raises:\n        TaskExecutionError: If template resolution fails or file cannot be written (via handle_task_error)\n    \"\"\"\n    task_name = str(config.name or \"template_task\")\n    task_type = str(config.type or \"template\")\n    logger = get_task_logger(config.workspace, task_name)\n\n    try:\n        log_task_execution(logger, config.step, config._context, config.workspace)\n\n        # Process inputs with template resolution\n        processed = config.process_inputs()\n\n        template_str = processed.get(\"template\")\n        if not template_str:\n            raise ValueError(\"No template provided\")\n\n        output_file = processed.get(\"output\")\n        if not output_file:\n            raise ValueError(\"No output file specified\")\n\n        # Render template with strict undefined handling\n        template = Template(template_str, undefined=StrictUndefined)\n        rendered = template.render(**config._context)\n\n        # Save to file\n        # Assuming output_file is relative to workspace\n        output_path = config.workspace / output_file\n        output_path.parent.mkdir(parents=True, exist_ok=True)\n        output_path.write_text(rendered)\n\n        result = {\"output_path\": str(output_path)}\n        log_task_result(logger, result)\n        return result\n\n    except Exception as e:\n        # Centralized error handling\n        context = ErrorContext(\n            step_name=task_name,\n            task_type=task_type,\n            error=e,\n            task_config=config.step,\n            template_context=config._context,\n        )\n        handle_task_error(context)\n        return {}  # Unreachable\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/#yaml_workflow.tasks.shell_task","title":"<code>shell_task(config: TaskConfig) -&gt; Dict[str, Any]</code>","text":"<p>Run a shell command with namespace support.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>TaskConfig</code> <p>Task configuration with namespace support</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str, Any]: Command execution results</p> <p>Raises:</p> Type Description <code>TaskExecutionError</code> <p>If command execution fails or template resolution fails</p> Source code in <code>src/yaml_workflow/tasks/shell_tasks.py</code> <pre><code>@register_task(\"shell\")\ndef shell_task(config: TaskConfig) -&gt; Dict[str, Any]:\n    \"\"\"\n    Run a shell command with namespace support.\n\n    Args:\n        config: Task configuration with namespace support\n\n    Returns:\n        Dict[str, Any]: Command execution results\n\n    Raises:\n        TaskExecutionError: If command execution fails or template resolution fails\n    \"\"\"\n    # Use str() to handle None safely, default to 'shell_task' if name is None\n    task_name = str(config.name or \"shell_task\")\n    task_type = str(config.type or \"shell\")\n    logger = get_task_logger(config.workspace, task_name)\n\n    try:\n        log_task_execution(logger, config.step, config._context, config.workspace)\n\n        # Process inputs with template support\n        # process_inputs now uses handle_task_error internally\n        processed = config.process_inputs()\n        config._processed_inputs = processed  # Store for potential future use\n\n        # Get command (required)\n        if \"command\" not in processed:\n            # Raise ValueError for config issue, will be caught by outer handler\n            missing_cmd_error = ValueError(\"command parameter is required\")\n            raise missing_cmd_error\n        command = processed[\"command\"]\n\n        # Handle working directory\n        cwd = config.workspace\n        if \"working_dir\" in processed:\n            working_dir = processed[\"working_dir\"]\n            if not os.path.isabs(working_dir):\n                cwd = config.workspace / working_dir\n            else:\n                cwd = Path(working_dir)\n\n        # Get environment variables\n        env = get_environment()\n        if \"env\" in processed:\n            env.update(processed[\"env\"])\n\n        # Get shell mode - default to True for better script compatibility\n        shell = processed.get(\"shell\", True)\n\n        # Get timeout\n        timeout = processed.get(\"timeout\", None)\n\n        # Process command template - process_command now uses handle_task_error\n        # Pass necessary context for error reporting within process_command\n        command_context = {\n            **config._context,\n            \"step_name\": task_name,\n            \"task_type\": task_type,\n            \"task_config\": config.step,\n        }\n        command = process_command(command, command_context)\n\n        # Run command\n        returncode, stdout, stderr = run_command(\n            command, cwd=str(cwd), env=env, shell=shell, timeout=timeout\n        )\n\n        # Check return code\n        if returncode != 0:\n            # Create specific error for non-zero exit code\n            error_message = f\"Command failed with exit code {returncode}\"\n            if stderr:\n                error_message += f\"\\nStderr:\\n{stderr}\"\n            # Use CalledProcessError for consistency, even though we caught it manually\n            cmd_error = subprocess.CalledProcessError(\n                returncode, cmd=command, output=stdout, stderr=stderr\n            )\n            # Let the central handler wrap this\n            raise cmd_error\n\n        # Log successful execution\n        result = {\"return_code\": returncode, \"stdout\": stdout, \"stderr\": stderr}\n        log_task_result(logger, result)\n        return result\n\n    except Exception as e:\n        # Centralized error handling for any exception during setup or execution\n        context = ErrorContext(\n            step_name=task_name,\n            task_type=task_type,\n            error=e,\n            task_config=config.step,\n            template_context=config._context,\n        )\n        handle_task_error(context)\n        return {}  # Unreachable\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/#yaml_workflow.tasks.write_file_task","title":"<code>write_file_task(config: TaskConfig) -&gt; Optional[Dict[str, Any]]</code>","text":"<p>Write content to a file.</p> Source code in <code>src/yaml_workflow/tasks/file_tasks.py</code> <pre><code>@register_task(\"write_file\")\ndef write_file_task(config: TaskConfig) -&gt; Optional[Dict[str, Any]]:\n    \"\"\"Write content to a file.\"\"\"\n    task_name = str(config.name or \"write_file\")\n    task_type = config.type or \"write_file\"\n    logger = get_task_logger(config.workspace, task_name)\n    log_task_execution(logger, config.step, config._context, config.workspace)\n    try:\n        processed = config.process_inputs()\n        file_path = processed.get(\"file\")\n        content = processed.get(\"content\")\n        encoding = processed.get(\"encoding\", \"utf-8\")\n\n        if not file_path:\n            raise ValueError(\"No file path provided\")\n        if content is None:\n            raise ValueError(\"No content provided\")\n\n        result = write_file_direct(\n            file_path, str(content), config.workspace, encoding, task_name\n        )\n        output = {\"path\": result, \"content\": content}\n        log_task_result(logger, output)\n        return output\n    except Exception as e:\n        context = ErrorContext(\n            step_name=task_name,\n            task_type=task_type,\n            error=e,\n            task_config=config.step,\n            template_context=config._context,\n        )\n        handle_task_error(context)\n        return None\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/#yaml_workflow.tasks.write_json_task","title":"<code>write_json_task(config: TaskConfig) -&gt; Optional[Dict[str, Any]]</code>","text":"<p>Write JSON data to a file.</p> Source code in <code>src/yaml_workflow/tasks/file_tasks.py</code> <pre><code>@register_task(\"write_json\")\ndef write_json_task(config: TaskConfig) -&gt; Optional[Dict[str, Any]]:\n    \"\"\"Write JSON data to a file.\"\"\"\n    task_name = str(config.name or \"write_json\")\n    task_type = config.type or \"write_json\"\n    logger = get_task_logger(config.workspace, task_name)\n    log_task_execution(logger, config.step, config._context, config.workspace)\n    try:\n        processed = config.process_inputs()\n        file_path = processed.get(\"file\")\n        data = processed.get(\"data\")\n        indent = int(processed.get(\"indent\", 2))\n        encoding = processed.get(\"encoding\", \"utf-8\")\n\n        if not file_path:\n            raise ValueError(\"No file path provided\")\n        if data is None:\n            raise ValueError(\"No data provided\")\n\n        result_path = write_json_direct(\n            file_path,\n            data,\n            indent=indent,\n            workspace=config.workspace,\n            encoding=encoding,\n            step_name=task_name,\n        )\n        output = {\"path\": result_path}\n        log_task_result(logger, output)\n        return output\n    except Exception as e:\n        context = ErrorContext(\n            step_name=task_name,\n            task_type=task_type,\n            error=e,\n            task_config=config.step,\n            template_context=config._context,\n        )\n        handle_task_error(context)\n        return None\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/#yaml_workflow.tasks.write_yaml_task","title":"<code>write_yaml_task(config: TaskConfig) -&gt; Optional[Dict[str, Any]]</code>","text":"<p>Write YAML data to a file.</p> Source code in <code>src/yaml_workflow/tasks/file_tasks.py</code> <pre><code>@register_task(\"write_yaml\")\ndef write_yaml_task(config: TaskConfig) -&gt; Optional[Dict[str, Any]]:\n    \"\"\"Write YAML data to a file.\"\"\"\n    task_name = str(config.name or \"write_yaml\")\n    task_type = config.type or \"write_yaml\"\n    logger = get_task_logger(config.workspace, task_name)\n    log_task_execution(logger, config.step, config._context, config.workspace)\n    try:\n        processed = config.process_inputs()\n        file_path = processed.get(\"file\")\n        data = processed.get(\"data\")\n        encoding = processed.get(\"encoding\", \"utf-8\")\n\n        if not file_path:\n            raise ValueError(\"No file path provided\")\n        if data is None:\n            raise ValueError(\"No data provided\")\n\n        result_path = write_yaml_direct(\n            file_path,\n            data,\n            workspace=config.workspace,\n            encoding=encoding,\n            step_name=task_name,\n        )\n        output = {\"path\": result_path}\n        log_task_result(logger, output)\n        return output\n    except Exception as e:\n        context = ErrorContext(\n            step_name=task_name,\n            task_type=task_type,\n            error=e,\n            task_config=config.step,\n            template_context=config._context,\n        )\n        handle_task_error(context)\n        return None\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/base/","title":"yaml_workflow.tasks.base","text":""},{"location":"reference/yaml_workflow/tasks/base/#yaml_workflow.tasks.base","title":"<code>yaml_workflow.tasks.base</code>","text":"<p>Base functionality for task handlers.</p>"},{"location":"reference/yaml_workflow/tasks/base/#yaml_workflow.tasks.base-functions","title":"Functions","text":""},{"location":"reference/yaml_workflow/tasks/base/#yaml_workflow.tasks.base.get_task_logger","title":"<code>get_task_logger(workspace: Union[str, Path], task_name: str) -&gt; logging.Logger</code>","text":"<p>Get a logger for a task that logs to the workspace logs directory.</p> <p>Parameters:</p> Name Type Description Default <code>workspace</code> <code>Union[str, Path]</code> <p>Workspace directory (can be string or Path)</p> required <code>task_name</code> <code>str</code> <p>Name of the task</p> required <p>Returns:</p> Type Description <code>Logger</code> <p>logging.Logger: Configured logger</p> Source code in <code>src/yaml_workflow/tasks/base.py</code> <pre><code>def get_task_logger(workspace: Union[str, Path], task_name: str) -&gt; logging.Logger:\n    \"\"\"\n    Get a logger for a task that logs to the workspace logs directory.\n\n    Args:\n        workspace: Workspace directory (can be string or Path)\n        task_name: Name of the task\n\n    Returns:\n        logging.Logger: Configured logger\n    \"\"\"\n    # Get logger for task\n    logger = logging.getLogger(f\"task.{task_name}\")\n\n    # Logger is already configured if it has handlers\n    if logger.handlers:\n        return logger\n\n    # Create formatters\n    formatter = logging.Formatter(\n        \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n    )\n\n    # Create file handler\n    workspace_path = Path(workspace) if isinstance(workspace, str) else workspace\n    logs_dir = workspace_path / \"logs\"\n    logs_dir.mkdir(parents=True, exist_ok=True)\n\n    # Create task-specific log file\n    log_file = logs_dir / f\"{task_name}.log\"\n    file_handler = logging.FileHandler(log_file)\n    file_handler.setFormatter(formatter)\n    file_handler.setLevel(logging.DEBUG)\n\n    # Create console handler\n    console_handler = logging.StreamHandler()\n    console_handler.setFormatter(formatter)\n    console_handler.setLevel(logging.INFO)\n\n    # Add handlers\n    logger.addHandler(file_handler)\n    logger.addHandler(console_handler)\n    logger.setLevel(logging.DEBUG)\n\n    return logger\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/base/#yaml_workflow.tasks.base.log_task_error","title":"<code>log_task_error(logger: logging.Logger, error: Exception) -&gt; None</code>","text":"<p>Log task execution error.</p> <p>Parameters:</p> Name Type Description Default <code>logger</code> <code>Logger</code> <p>Task logger</p> required <code>error</code> <code>Exception</code> <p>Exception that occurred</p> required Source code in <code>src/yaml_workflow/tasks/base.py</code> <pre><code>def log_task_error(logger: logging.Logger, error: Exception) -&gt; None:\n    \"\"\"\n    Log task execution error.\n\n    Args:\n        logger: Task logger\n        error: Exception that occurred\n    \"\"\"\n    logger.error(f\"Task failed: {str(error)}\", exc_info=True)\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/base/#yaml_workflow.tasks.base.log_task_execution","title":"<code>log_task_execution(logger: logging.Logger, step: Dict[str, Any], context: Dict[str, Any], workspace: Path) -&gt; None</code>","text":"<p>Log task execution details.</p> <p>Parameters:</p> Name Type Description Default <code>logger</code> <code>Logger</code> <p>Task logger</p> required <code>step</code> <code>Dict[str, Any]</code> <p>Step configuration</p> required <code>context</code> <code>Dict[str, Any]</code> <p>Workflow context</p> required <code>workspace</code> <code>Path</code> <p>Workspace directory</p> required Source code in <code>src/yaml_workflow/tasks/base.py</code> <pre><code>def log_task_execution(\n    logger: logging.Logger,\n    step: Dict[str, Any],\n    context: Dict[str, Any],\n    workspace: Path,\n) -&gt; None:\n    \"\"\"\n    Log task execution details.\n\n    Args:\n        logger: Task logger\n        step: Step configuration\n        context: Workflow context\n        workspace: Workspace directory\n    \"\"\"\n    task_name = step.get(\"name\", \"unnamed_task\")\n    task_type = step.get(\"task\", \"unknown\")  # Changed from \"type\" to \"task\"\n\n    logger.info(f\"Executing task '{task_name}' of type '{task_type}'\")\n    logger.debug(f\"Step configuration: {step}\")\n    logger.debug(f\"Context: {context}\")\n    logger.debug(f\"Workspace: {workspace}\")\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/base/#yaml_workflow.tasks.base.log_task_result","title":"<code>log_task_result(logger: logging.Logger, result: Any) -&gt; None</code>","text":"<p>Log task execution result.</p> <p>Parameters:</p> Name Type Description Default <code>logger</code> <code>Logger</code> <p>Task logger</p> required <code>result</code> <code>Any</code> <p>Task result</p> required Source code in <code>src/yaml_workflow/tasks/base.py</code> <pre><code>def log_task_result(logger: logging.Logger, result: Any) -&gt; None:\n    \"\"\"\n    Log task execution result.\n\n    Args:\n        logger: Task logger\n        result: Task result\n    \"\"\"\n    logger.info(\"Task completed successfully\")\n    logger.debug(f\"Result: {result}\")\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/basic_tasks/","title":"yaml_workflow.tasks.basic_tasks","text":""},{"location":"reference/yaml_workflow/tasks/basic_tasks/#yaml_workflow.tasks.basic_tasks","title":"<code>yaml_workflow.tasks.basic_tasks</code>","text":"<p>Basic task functions for demonstration and testing.</p>"},{"location":"reference/yaml_workflow/tasks/basic_tasks/#yaml_workflow.tasks.basic_tasks-classes","title":"Classes","text":""},{"location":"reference/yaml_workflow/tasks/basic_tasks/#yaml_workflow.tasks.basic_tasks-functions","title":"Functions","text":""},{"location":"reference/yaml_workflow/tasks/basic_tasks/#yaml_workflow.tasks.basic_tasks.add_numbers","title":"<code>add_numbers(a: float, b: float) -&gt; float</code>","text":"<p>Add two numbers together.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>float</code> <p>First number</p> required <code>b</code> <code>float</code> <p>Second number</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>Sum of the numbers</p> Source code in <code>src/yaml_workflow/tasks/basic_tasks.py</code> <pre><code>@register_task()\ndef add_numbers(a: float, b: float) -&gt; float:\n    \"\"\"\n    Add two numbers together.\n\n    Args:\n        a: First number\n        b: Second number\n\n    Returns:\n        float: Sum of the numbers\n    \"\"\"\n    return a + b\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/basic_tasks/#yaml_workflow.tasks.basic_tasks.create_greeting","title":"<code>create_greeting(name: str, context: Dict[str, Any]) -&gt; str</code>","text":"<p>Create a greeting message.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name to greet</p> required <code>context</code> <code>Dict[str, Any]</code> <p>Template context</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Greeting message</p> <p>Raises:</p> Type Description <code>TemplateError</code> <p>If template resolution fails</p> Source code in <code>src/yaml_workflow/tasks/basic_tasks.py</code> <pre><code>@register_task()\ndef create_greeting(name: str, context: Dict[str, Any]) -&gt; str:\n    \"\"\"\n    Create a greeting message.\n\n    Args:\n        name: Name to greet\n        context: Template context\n\n    Returns:\n        str: Greeting message\n\n    Raises:\n        TemplateError: If template resolution fails\n    \"\"\"\n    try:\n        template = Template(\"Hello {{ name }}!\", undefined=StrictUndefined)\n        return template.render(name=name, **context)\n    except UndefinedError as e:\n        available = {\n            \"name\": name,\n            \"args\": list(context[\"args\"].keys()) if \"args\" in context else [],\n            \"env\": list(context[\"env\"].keys()) if \"env\" in context else [],\n            \"steps\": list(context[\"steps\"].keys()) if \"steps\" in context else [],\n        }\n        raise TemplateError(f\"{str(e)}. Available variables: {available}\")\n    except Exception as e:\n        raise TemplateError(f\"Failed to create greeting: {str(e)}\")\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/basic_tasks/#yaml_workflow.tasks.basic_tasks.echo","title":"<code>echo(message: str) -&gt; str</code>","text":"<p>Echo back the input message.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Message to echo</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The input message</p> Source code in <code>src/yaml_workflow/tasks/basic_tasks.py</code> <pre><code>@register_task()\ndef echo(message: str) -&gt; str:\n    \"\"\"\n    Echo back the input message.\n\n    Args:\n        message: Message to echo\n\n    Returns:\n        str: The input message\n    \"\"\"\n    return message\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/basic_tasks/#yaml_workflow.tasks.basic_tasks.fail","title":"<code>fail(message: str = 'Task failed') -&gt; None</code>","text":"<p>A task that always fails.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Error message</p> <code>'Task failed'</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>Always raises this error</p> Source code in <code>src/yaml_workflow/tasks/basic_tasks.py</code> <pre><code>@register_task()\ndef fail(message: str = \"Task failed\") -&gt; None:\n    \"\"\"\n    A task that always fails.\n\n    Args:\n        message: Error message\n\n    Raises:\n        RuntimeError: Always raises this error\n    \"\"\"\n    raise RuntimeError(message)\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/basic_tasks/#yaml_workflow.tasks.basic_tasks.hello_world","title":"<code>hello_world(name: str = 'World') -&gt; str</code>","text":"<p>A simple hello world function.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name to include in greeting. Defaults to \"World\".</p> <code>'World'</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The greeting message</p> Source code in <code>src/yaml_workflow/tasks/basic_tasks.py</code> <pre><code>@register_task()\ndef hello_world(name: str = \"World\") -&gt; str:\n    \"\"\"\n    A simple hello world function.\n\n    Args:\n        name: Name to include in greeting. Defaults to \"World\".\n\n    Returns:\n        str: The greeting message\n    \"\"\"\n    return f\"Hello, {name}!\"\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/basic_tasks/#yaml_workflow.tasks.basic_tasks.join_strings","title":"<code>join_strings(*strings: str, separator: str = ' ') -&gt; str</code>","text":"<p>Join multiple strings together.</p> <p>Parameters:</p> Name Type Description Default <code>*strings</code> <code>str</code> <p>Variable number of strings to join</p> <code>()</code> <code>separator</code> <code>str</code> <p>String to use as separator. Defaults to space.</p> <code>' '</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Joined string</p> Source code in <code>src/yaml_workflow/tasks/basic_tasks.py</code> <pre><code>@register_task()\ndef join_strings(*strings: str, separator: str = \" \") -&gt; str:\n    \"\"\"\n    Join multiple strings together.\n\n    Args:\n        *strings: Variable number of strings to join\n        separator: String to use as separator. Defaults to space.\n\n    Returns:\n        str: Joined string\n    \"\"\"\n    return separator.join(strings)\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/batch/","title":"yaml_workflow.tasks.batch","text":""},{"location":"reference/yaml_workflow/tasks/batch/#yaml_workflow.tasks.batch","title":"<code>yaml_workflow.tasks.batch</code>","text":"<p>Batch processing task for handling multiple items in parallel.</p>"},{"location":"reference/yaml_workflow/tasks/batch/#yaml_workflow.tasks.batch-classes","title":"Classes","text":""},{"location":"reference/yaml_workflow/tasks/batch/#yaml_workflow.tasks.batch-functions","title":"Functions","text":""},{"location":"reference/yaml_workflow/tasks/batch/#yaml_workflow.tasks.batch.batch_task","title":"<code>batch_task(config: TaskConfig) -&gt; Dict[str, Any]</code>","text":"<p>Process a batch of items using specified task configuration.</p> <p>This task processes a list of items in parallel chunks using the specified task configuration. Each item is passed to the task as an argument.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>TaskConfig</code> <p>TaskConfig object containing: - items: List of items to process - task: Task configuration for processing each item - arg_name: Name of the argument to use for each item (default: \"item\") - chunk_size: Optional size of chunks (default: 10) - max_workers: Optional maximum worker threads</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict containing: - processed: List of successfully processed items - failed: List of failed items with errors - results: List of processing results - stats: Processing statistics</p> Example YAML usage <pre><code>steps:\n  - name: process_data\n    task: batch\n    inputs:\n      items: [5, 7, 12]\n      arg_name: x  # Name items will be passed as\n      chunk_size: 2\n      max_workers: 2\n      task:\n        task: python\n        inputs:\n          operation: multiply\n          factor: 2\n</code></pre> Source code in <code>src/yaml_workflow/tasks/batch.py</code> <pre><code>@register_task(\"batch\")\ndef batch_task(config: TaskConfig) -&gt; Dict[str, Any]:\n    \"\"\"\n    Process a batch of items using specified task configuration.\n\n    This task processes a list of items in parallel chunks using the specified\n    task configuration. Each item is passed to the task as an argument.\n\n    Args:\n        config: TaskConfig object containing:\n            - items: List of items to process\n            - task: Task configuration for processing each item\n            - arg_name: Name of the argument to use for each item (default: \"item\")\n            - chunk_size: Optional size of chunks (default: 10)\n            - max_workers: Optional maximum worker threads\n\n    Returns:\n        Dict containing:\n            - processed: List of successfully processed items\n            - failed: List of failed items with errors\n            - results: List of processing results\n            - stats: Processing statistics\n\n    Example YAML usage:\n        ```yaml\n        steps:\n          - name: process_data\n            task: batch\n            inputs:\n              items: [5, 7, 12]\n              arg_name: x  # Name items will be passed as\n              chunk_size: 2\n              max_workers: 2\n              task:\n                task: python\n                inputs:\n                  operation: multiply\n                  factor: 2\n        ```\n    \"\"\"\n    task_name = config.name or \"batch_task\"\n    task_type = config.type or \"batch\"\n\n    try:\n        # Process inputs with template resolution\n        processed = config.process_inputs()\n\n        # Get required parameters\n        items = processed.get(\"items\")\n        if items is None:\n            raise ValueError(\"'items' parameter is required for batch task\")\n\n        # Ensure items is a list\n        if not isinstance(items, list):\n            raise ValueError(\"'items' must resolve to a list after template processing\")\n\n        task_config = processed.get(\"task\")\n        if not task_config:\n            raise ValueError(\n                \"'task' configuration is required within batch task inputs\"\n            )\n\n        # Get optional parameters with defaults\n        chunk_size = int(processed.get(\"chunk_size\", 10))\n        if chunk_size &lt;= 0:\n            raise ValueError(\"'chunk_size' must be greater than 0\")\n\n        max_workers = int(\n            processed.get(\"max_workers\", min(chunk_size, os.cpu_count() or 1))\n        )\n        if max_workers &lt;= 0:\n            raise ValueError(\"'max_workers' must be greater than 0\")\n\n        # Handle case where items list is empty after processing\n        if not items:\n            return {\n                \"processed\": [],\n                \"failed\": [],\n                \"results\": [],\n                \"stats\": {\n                    \"total\": 0,\n                    \"processed\": 0,\n                    \"failed\": 0,\n                    \"start_time\": datetime.now().isoformat(),\n                    \"end_time\": datetime.now().isoformat(),\n                    \"success_rate\": 100.0,\n                },\n            }\n\n        # Get argument name to use for items, defaulting to \"item\"\n        arg_name = processed.get(\"arg_name\", \"item\")\n\n        # Initialize state\n        state: Dict[str, Any] = {\n            \"processed\": [],\n            \"failed\": [],\n            \"results\": [],\n            \"stats\": {\n                \"total\": len(items),\n                \"processed\": 0,\n                \"failed\": 0,\n                \"start_time\": datetime.now().isoformat(),\n            },\n        }\n\n        # Store results with their indices for ordering\n        ordered_results: List[Tuple[int, Any]] = []\n        ordered_processed: List[Tuple[int, Any]] = []\n        ordered_failed: List[Tuple[int, Dict[str, Any]]] = []\n\n        # Process items in chunks\n        for chunk_index, chunk_start in enumerate(range(0, len(items), chunk_size)):\n            chunk = cast(List[Any], items[chunk_start : chunk_start + chunk_size])\n\n            with ThreadPoolExecutor(max_workers=max_workers) as executor:\n                futures = {}\n\n                # Submit tasks for chunk\n                for item_index, item in enumerate(chunk):\n                    # Pass the sub-task config, not the main batch config inputs\n                    sub_task_config_for_item = task_config\n                    future = executor.submit(\n                        process_item,\n                        item,  # item: Any\n                        sub_task_config_for_item,  # task_config: Dict[str, Any]\n                        config._context,  # context: Dict[str, Any]\n                        config.workspace,  # workspace: Path\n                        arg_name,  # arg_name: str\n                        chunk_index,  # chunk_index: int\n                        chunk_start + item_index,  # item_index: int\n                        len(items),  # total: int\n                        chunk_size,  # chunk_size: int\n                    )\n                    futures[future] = (item, chunk_start + item_index)\n\n                # Process completed futures\n                for future in as_completed(futures):\n                    item, index = futures[future]\n                    try:\n                        result = future.result()\n                        ordered_processed.append((index, item))\n                        ordered_results.append((index, result))\n                        state[\"stats\"][\"processed\"] += 1\n                    except Exception as e:\n                        # Capture the error from process_item (already wrapped if needed)\n                        error_info = {\"item\": item, \"error\": str(e)}\n                        # If it's a TaskExecutionError, add more details if possible\n                        if isinstance(e, TaskExecutionError):\n                            error_info[\"step_name\"] = e.step_name\n                            if e.task_config:\n                                error_info[\"task_config\"] = e.task_config\n                        ordered_failed.append((index, error_info))\n                        state[\"stats\"][\"failed\"] += 1\n\n        # Sort results by index and extract values\n        state[\"processed\"] = [item for _, item in sorted(ordered_processed)]\n        state[\"results\"] = [result for _, result in sorted(ordered_results)]\n        state[\"failed\"] = [error for _, error in sorted(ordered_failed)]\n\n        # Add completion statistics\n        state[\"stats\"][\"end_time\"] = datetime.now().isoformat()\n        total_items = state[\"stats\"][\"total\"]\n        processed_items = state[\"stats\"][\"processed\"]\n        state[\"stats\"][\"success_rate\"] = (\n            (processed_items / total_items) * 100.0\n            if total_items &gt; 0\n            else 100.0  # Avoid division by zero if total is 0\n        )\n\n        return state\n\n    except Exception as e:\n        # Centralized error handling for exceptions during batch setup/config\n        err_context = ErrorContext(\n            step_name=str(task_name),\n            task_type=str(task_type),\n            error=e,\n            task_config=config.step,\n            template_context=config._context,\n        )\n        handle_task_error(err_context)\n        # handle_task_error always raises, so return is unreachable but satisfies type checker\n        return {}\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/batch/#yaml_workflow.tasks.batch.process_item","title":"<code>process_item(item: Any, task_config: Dict[str, Any], context: Dict[str, Any], workspace: Path, arg_name: str, chunk_index: int = 0, item_index: int = 0, total: int = 0, chunk_size: int = 0) -&gt; Any</code>","text":"<p>Process a single batch item using its task configuration.</p> <p>Parameters:</p> Name Type Description Default <code>item</code> <code>Any</code> <p>The item to process</p> required <code>task_config</code> <code>Dict[str, Any]</code> <p>Task configuration</p> required <code>context</code> <code>Dict[str, Any]</code> <p>Task context</p> required <code>workspace</code> <code>Path</code> <p>Workspace path</p> required <code>arg_name</code> <code>str</code> <p>Name of the argument to use for the item</p> required <code>chunk_index</code> <code>int</code> <p>Index of the current chunk</p> <code>0</code> <code>item_index</code> <code>int</code> <p>Index of the item in the overall batch</p> <code>0</code> <code>total</code> <code>int</code> <p>Total number of items in batch</p> <code>0</code> <code>chunk_size</code> <code>int</code> <p>Size of each chunk</p> <code>0</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>Result of processing the item</p> <p>Raises:</p> Type Description <code>TaskExecutionError</code> <p>If item processing fails</p> <code>ValueError</code> <p>If task type is invalid</p> Source code in <code>src/yaml_workflow/tasks/batch.py</code> <pre><code>def process_item(\n    item: Any,\n    task_config: Dict[str, Any],\n    context: Dict[str, Any],\n    workspace: Path,\n    arg_name: str,\n    chunk_index: int = 0,\n    item_index: int = 0,\n    total: int = 0,\n    chunk_size: int = 0,\n) -&gt; Any:\n    \"\"\"\n    Process a single batch item using its task configuration.\n\n    Args:\n        item: The item to process\n        task_config: Task configuration\n        context: Task context\n        workspace: Workspace path\n        arg_name: Name of the argument to use for the item\n        chunk_index: Index of the current chunk\n        item_index: Index of the item in the overall batch\n        total: Total number of items in batch\n        chunk_size: Size of each chunk\n\n    Returns:\n        Any: Result of processing the item\n\n    Raises:\n        TaskExecutionError: If item processing fails\n        ValueError: If task type is invalid\n    \"\"\"\n    try:\n        task_type = task_config.get(\"task\")\n        if not task_type:\n            # Raise ValueError for config issue before task execution attempt\n            raise ValueError(\n                \"Task type is required within the batch task configuration\"\n            )\n\n        handler = get_task_handler(task_type)\n        if not handler:\n            # Raise ValueError for config issue before task execution attempt\n            raise ValueError(\n                f\"Unknown task type specified in batch task config: {task_type}\"\n            )\n\n        # Create task config with item in inputs using specified arg name\n        step = {\n            # Use a more informative name including original step name if available\n            \"name\": f\"batch_item_{item}_in_{task_config.get('name', 'batch')}\",\n            \"task\": task_type,\n            \"inputs\": {**task_config.get(\"inputs\", {}), arg_name: item},\n        }\n\n        # Create task config with item in args namespace using specified arg name\n        # and batch-specific variables in batch namespace\n        item_context = {\n            **context,\n            \"args\": {**context.get(\"args\", {}), arg_name: item},\n            \"batch\": {\n                \"item\": item,\n                \"chunk_index\": chunk_index,\n                \"index\": item_index,\n                \"total\": total,\n                \"chunk_size\": chunk_size,\n            },\n        }\n\n        config = TaskConfig(step, item_context, workspace)\n        result = handler(config)\n        # Remove unwrapping logic - return the full result dict from the handler\n        # if isinstance(result, dict) and len(result) == 1 and \"result\" in result:\n        #     return result[\"result\"]\n        return result\n    except Exception as e:\n        # Centralized error handling for exceptions during item processing\n        err_context = ErrorContext(\n            # Use the specific item step name generated above\n            step_name=step[\"name\"],\n            task_type=str(task_type),  # Ensure type is str\n            error=e,\n            # Pass the sub-task config, not the main batch config\n            task_config=step,\n            # Include the item context used for this specific item\n            template_context=item_context,\n        )\n        handle_task_error(err_context)\n        # handle_task_error always raises, so return is unreachable but satisfies type checker\n        return None\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/batch_context/","title":"yaml_workflow.tasks.batch_context","text":""},{"location":"reference/yaml_workflow/tasks/batch_context/#yaml_workflow.tasks.batch_context","title":"<code>yaml_workflow.tasks.batch_context</code>","text":"<p>Batch processing context management.</p>"},{"location":"reference/yaml_workflow/tasks/batch_context/#yaml_workflow.tasks.batch_context-classes","title":"Classes","text":""},{"location":"reference/yaml_workflow/tasks/batch_context/#yaml_workflow.tasks.batch_context.BatchContext","title":"<code>BatchContext</code>","text":"<p>Context manager for batch processing with namespace support.</p> Source code in <code>src/yaml_workflow/tasks/batch_context.py</code> <pre><code>class BatchContext:\n    \"\"\"Context manager for batch processing with namespace support.\"\"\"\n\n    def __init__(self, config: TaskConfig):\n        \"\"\"Initialize batch context.\n\n        Args:\n            config: Task configuration with namespace support\n        \"\"\"\n        self.name = config.name\n        self.engine = config.get_variable(\"engine\")\n        self.workspace = config.workspace\n        self.retry_config = config.inputs.get(\"retry\", {})\n        self._context = config._context\n\n    def create_item_context(self, item: Any, index: int) -&gt; Dict[str, Any]:\n        \"\"\"Create context for a batch item while preserving namespaces.\n\n        Args:\n            item: The batch item being processed\n            index: Index of the item in the batch\n\n        Returns:\n            Dict containing the item context with namespace support\n        \"\"\"\n        return {\n            \"args\": self._context.get(\"args\", {}),\n            \"env\": self._context.get(\"env\", {}),\n            \"steps\": self._context.get(\"steps\", {}),\n            \"batch\": {\"item\": item, \"index\": index, \"name\": self.name},\n        }\n\n    def get_error_context(self, error: Exception) -&gt; Dict[str, Any]:\n        \"\"\"Get error context with namespace information.\n\n        Args:\n            error: The exception that occurred\n\n        Returns:\n            Dict containing error context with namespace information\n        \"\"\"\n        return {\n            \"error\": str(error),\n            \"available_variables\": self.get_available_variables(),\n            \"namespaces\": list(self._context.keys()),\n        }\n\n    def get_available_variables(self) -&gt; Dict[str, List[str]]:\n        \"\"\"Get available variables by namespace.\n\n        Returns:\n            Dict mapping namespace names to lists of available variables\n        \"\"\"\n        return {\n            \"args\": list(self._context.get(\"args\", {}).keys()),\n            \"env\": list(self._context.get(\"env\", {}).keys()),\n            \"steps\": list(self._context.get(\"steps\", {}).keys()),\n            \"batch\": [\"item\", \"index\", \"name\"],\n        }\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/batch_context/#yaml_workflow.tasks.batch_context.BatchContext-functions","title":"Functions","text":""},{"location":"reference/yaml_workflow/tasks/batch_context/#yaml_workflow.tasks.batch_context.BatchContext.create_item_context","title":"<code>create_item_context(item: Any, index: int) -&gt; Dict[str, Any]</code>","text":"<p>Create context for a batch item while preserving namespaces.</p> <p>Parameters:</p> Name Type Description Default <code>item</code> <code>Any</code> <p>The batch item being processed</p> required <code>index</code> <code>int</code> <p>Index of the item in the batch</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict containing the item context with namespace support</p> Source code in <code>src/yaml_workflow/tasks/batch_context.py</code> <pre><code>def create_item_context(self, item: Any, index: int) -&gt; Dict[str, Any]:\n    \"\"\"Create context for a batch item while preserving namespaces.\n\n    Args:\n        item: The batch item being processed\n        index: Index of the item in the batch\n\n    Returns:\n        Dict containing the item context with namespace support\n    \"\"\"\n    return {\n        \"args\": self._context.get(\"args\", {}),\n        \"env\": self._context.get(\"env\", {}),\n        \"steps\": self._context.get(\"steps\", {}),\n        \"batch\": {\"item\": item, \"index\": index, \"name\": self.name},\n    }\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/batch_context/#yaml_workflow.tasks.batch_context.BatchContext.get_available_variables","title":"<code>get_available_variables() -&gt; Dict[str, List[str]]</code>","text":"<p>Get available variables by namespace.</p> <p>Returns:</p> Type Description <code>Dict[str, List[str]]</code> <p>Dict mapping namespace names to lists of available variables</p> Source code in <code>src/yaml_workflow/tasks/batch_context.py</code> <pre><code>def get_available_variables(self) -&gt; Dict[str, List[str]]:\n    \"\"\"Get available variables by namespace.\n\n    Returns:\n        Dict mapping namespace names to lists of available variables\n    \"\"\"\n    return {\n        \"args\": list(self._context.get(\"args\", {}).keys()),\n        \"env\": list(self._context.get(\"env\", {}).keys()),\n        \"steps\": list(self._context.get(\"steps\", {}).keys()),\n        \"batch\": [\"item\", \"index\", \"name\"],\n    }\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/batch_context/#yaml_workflow.tasks.batch_context.BatchContext.get_error_context","title":"<code>get_error_context(error: Exception) -&gt; Dict[str, Any]</code>","text":"<p>Get error context with namespace information.</p> <p>Parameters:</p> Name Type Description Default <code>error</code> <code>Exception</code> <p>The exception that occurred</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict containing error context with namespace information</p> Source code in <code>src/yaml_workflow/tasks/batch_context.py</code> <pre><code>def get_error_context(self, error: Exception) -&gt; Dict[str, Any]:\n    \"\"\"Get error context with namespace information.\n\n    Args:\n        error: The exception that occurred\n\n    Returns:\n        Dict containing error context with namespace information\n    \"\"\"\n    return {\n        \"error\": str(error),\n        \"available_variables\": self.get_available_variables(),\n        \"namespaces\": list(self._context.keys()),\n    }\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/config/","title":"yaml_workflow.tasks.config","text":""},{"location":"reference/yaml_workflow/tasks/config/#yaml_workflow.tasks.config","title":"<code>yaml_workflow.tasks.config</code>","text":"<p>Configuration classes for task handlers with namespace support.</p>"},{"location":"reference/yaml_workflow/tasks/config/#yaml_workflow.tasks.config-classes","title":"Classes","text":""},{"location":"reference/yaml_workflow/tasks/config/#yaml_workflow.tasks.config.TaskConfig","title":"<code>TaskConfig</code>","text":"<p>Configuration class for task handlers with namespace support.</p> Source code in <code>src/yaml_workflow/tasks/config.py</code> <pre><code>class TaskConfig:\n    \"\"\"Configuration class for task handlers with namespace support.\"\"\"\n\n    def __init__(self, step: Dict[str, Any], context: Dict[str, Any], workspace: Path):\n        \"\"\"\n        Initialize task configuration.\n\n        Args:\n            step: Step configuration from workflow\n            context: Execution context with namespaces\n            workspace: Workspace path\n        \"\"\"\n        self.step = step  # Store the full step configuration\n        self.name = step.get(\"name\")\n        self.type = step.get(\"task\")\n        self.inputs = step.get(\"inputs\", {})\n        self._context = context\n        self.workspace = workspace\n        self._processed_inputs: Dict[str, Any] = {}\n        self._template_engine = TemplateEngine()\n\n    def get_variable(self, name: str, namespace: Optional[str] = None) -&gt; Any:\n        \"\"\"\n        Get a variable with namespace support.\n\n        Args:\n            name: Variable name\n            namespace: Optional namespace (args, env, steps)\n\n        Returns:\n            Any: Variable value if found\n        \"\"\"\n        if namespace:\n            return self._context.get(namespace, {}).get(name)\n        return self._context.get(name)\n\n    def get_available_variables(self) -&gt; Dict[str, List[str]]:\n        \"\"\"\n        Get available variables by namespace.\n\n        Returns:\n            Dict[str, List[str]]: Available variables in each namespace\n        \"\"\"\n        return {\n            \"args\": list(self._context.get(\"args\", {}).keys()),\n            \"env\": list(self._context.get(\"env\", {}).keys()),\n            \"steps\": list(self._context.get(\"steps\", {}).keys()),\n            \"root\": [\n                k for k in self._context.keys() if k not in [\"args\", \"env\", \"steps\"]\n            ],\n        }\n\n    def process_inputs(self) -&gt; Dict[str, Any]:\n        \"\"\"\n        Process task inputs with template resolution.\n\n        Recursively processes all string values in the inputs dictionary,\n        including nested dictionaries and lists.\n\n        Returns:\n            Dict[str, Any]: Processed inputs with resolved templates\n        \"\"\"\n        if not self._processed_inputs:\n            # Create a flattened context for template processing\n            template_context = {\n                \"args\": self._context.get(\"args\", {}),\n                \"env\": self._context.get(\"env\", {}),\n                \"steps\": self._context.get(\"steps\", {}),\n                **{\n                    k: v\n                    for k, v in self._context.items()\n                    if k not in [\"args\", \"env\", \"steps\"]\n                },\n            }\n\n            self._processed_inputs = self._process_value(self.inputs, template_context)\n        return self._processed_inputs\n\n    def _process_value(self, value: Any, template_context: Dict[str, Any]) -&gt; Any:\n        \"\"\"\n        Recursively process a value with template resolution.\n\n        Args:\n            value: Value to process\n            template_context: Template context for variable resolution\n\n        Returns:\n            Any: Processed value with resolved templates\n\n        Raises:\n            TaskExecutionError: If template processing fails due to undefined variables.\n        \"\"\"\n        if isinstance(value, str):\n            try:\n                result = self._template_engine.process_template(value, template_context)\n                # Try to convert string results back to their original type\n                if result == \"True\":\n                    return True\n                elif result == \"False\":\n                    return False\n                try:\n                    # First try to evaluate as a Python literal (for lists, dicts, etc.)\n                    import ast\n\n                    try:\n                        return ast.literal_eval(result)\n                    except (ValueError, SyntaxError):\n                        # If not a valid Python literal, try numeric conversion\n                        if \".\" in result:\n                            return float(result)\n                        return int(result)\n                except (ValueError, TypeError, SyntaxError):\n                    return result\n            except UndefinedError as e:\n                # Use the new centralized error handler\n                context = ErrorContext(\n                    step_name=str(self.name),\n                    task_type=str(self.type),\n                    error=e,\n                    task_config=self.step,\n                    template_context=template_context,\n                )\n                handle_task_error(context)\n        elif isinstance(value, dict):\n            return {\n                k: self._process_value(v, template_context) for k, v in value.items()\n            }\n        elif isinstance(value, list):\n            return [self._process_value(item, template_context) for item in value]\n        return value\n\n    def _get_undefined_namespace(self, error_msg: str) -&gt; str:\n        \"\"\"\n        Extract namespace from undefined variable error.\n\n        Args:\n            error_msg: Error message from UndefinedError\n\n        Returns:\n            str: Namespace name or 'root' if not found\n        \"\"\"\n        # Check for direct variable access pattern (e.g., args.undefined)\n        for namespace in [\"args\", \"env\", \"steps\"]:\n            if f\"{namespace}.\" in error_msg:\n                return namespace\n\n        # Check for dictionary access pattern (e.g., 'dict object' has no attribute 'undefined')\n        # Extract the undefined attribute name from the error message\n        match = re.search(r\"no attribute '(\\w+)'\", error_msg)\n        if match:\n            undefined_attr = match.group(1)\n            # Find which namespace was trying to access this attribute\n            for namespace in [\"args\", \"env\", \"steps\"]:\n                if namespace in self._context:\n                    template_str = next(\n                        (\n                            v\n                            for v in self.inputs.values()\n                            if isinstance(v, str)\n                            and f\"{namespace}.{undefined_attr}\" in v\n                        ),\n                        \"\",\n                    )\n                    if template_str:\n                        return namespace\n\n        return \"root\"\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/config/#yaml_workflow.tasks.config.TaskConfig-functions","title":"Functions","text":""},{"location":"reference/yaml_workflow/tasks/config/#yaml_workflow.tasks.config.TaskConfig.get_available_variables","title":"<code>get_available_variables() -&gt; Dict[str, List[str]]</code>","text":"<p>Get available variables by namespace.</p> <p>Returns:</p> Type Description <code>Dict[str, List[str]]</code> <p>Dict[str, List[str]]: Available variables in each namespace</p> Source code in <code>src/yaml_workflow/tasks/config.py</code> <pre><code>def get_available_variables(self) -&gt; Dict[str, List[str]]:\n    \"\"\"\n    Get available variables by namespace.\n\n    Returns:\n        Dict[str, List[str]]: Available variables in each namespace\n    \"\"\"\n    return {\n        \"args\": list(self._context.get(\"args\", {}).keys()),\n        \"env\": list(self._context.get(\"env\", {}).keys()),\n        \"steps\": list(self._context.get(\"steps\", {}).keys()),\n        \"root\": [\n            k for k in self._context.keys() if k not in [\"args\", \"env\", \"steps\"]\n        ],\n    }\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/config/#yaml_workflow.tasks.config.TaskConfig.get_variable","title":"<code>get_variable(name: str, namespace: Optional[str] = None) -&gt; Any</code>","text":"<p>Get a variable with namespace support.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Variable name</p> required <code>namespace</code> <code>Optional[str]</code> <p>Optional namespace (args, env, steps)</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>Variable value if found</p> Source code in <code>src/yaml_workflow/tasks/config.py</code> <pre><code>def get_variable(self, name: str, namespace: Optional[str] = None) -&gt; Any:\n    \"\"\"\n    Get a variable with namespace support.\n\n    Args:\n        name: Variable name\n        namespace: Optional namespace (args, env, steps)\n\n    Returns:\n        Any: Variable value if found\n    \"\"\"\n    if namespace:\n        return self._context.get(namespace, {}).get(name)\n    return self._context.get(name)\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/config/#yaml_workflow.tasks.config.TaskConfig.process_inputs","title":"<code>process_inputs() -&gt; Dict[str, Any]</code>","text":"<p>Process task inputs with template resolution.</p> <p>Recursively processes all string values in the inputs dictionary, including nested dictionaries and lists.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str, Any]: Processed inputs with resolved templates</p> Source code in <code>src/yaml_workflow/tasks/config.py</code> <pre><code>def process_inputs(self) -&gt; Dict[str, Any]:\n    \"\"\"\n    Process task inputs with template resolution.\n\n    Recursively processes all string values in the inputs dictionary,\n    including nested dictionaries and lists.\n\n    Returns:\n        Dict[str, Any]: Processed inputs with resolved templates\n    \"\"\"\n    if not self._processed_inputs:\n        # Create a flattened context for template processing\n        template_context = {\n            \"args\": self._context.get(\"args\", {}),\n            \"env\": self._context.get(\"env\", {}),\n            \"steps\": self._context.get(\"steps\", {}),\n            **{\n                k: v\n                for k, v in self._context.items()\n                if k not in [\"args\", \"env\", \"steps\"]\n            },\n        }\n\n        self._processed_inputs = self._process_value(self.inputs, template_context)\n    return self._processed_inputs\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/config/#yaml_workflow.tasks.config-functions","title":"Functions","text":""},{"location":"reference/yaml_workflow/tasks/error_handling/","title":"yaml_workflow.tasks.error_handling","text":""},{"location":"reference/yaml_workflow/tasks/error_handling/#yaml_workflow.tasks.error_handling","title":"<code>yaml_workflow.tasks.error_handling</code>","text":"<p>Centralized error handling utilities for tasks.</p>"},{"location":"reference/yaml_workflow/tasks/error_handling/#yaml_workflow.tasks.error_handling-classes","title":"Classes","text":""},{"location":"reference/yaml_workflow/tasks/error_handling/#yaml_workflow.tasks.error_handling.ErrorContext","title":"<code>ErrorContext</code>  <code>dataclass</code>","text":"<p>Data class to hold context information about a task error.</p> Source code in <code>src/yaml_workflow/tasks/error_handling.py</code> <pre><code>@dataclass\nclass ErrorContext:\n    \"\"\"Data class to hold context information about a task error.\"\"\"\n\n    step_name: str\n    task_type: str\n    error: Exception\n    retry_count: int = 0\n    task_config: Optional[Dict[str, Any]] = None\n    template_context: Optional[Dict[str, Any]] = None\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/error_handling/#yaml_workflow.tasks.error_handling-functions","title":"Functions","text":""},{"location":"reference/yaml_workflow/tasks/error_handling/#yaml_workflow.tasks.error_handling.handle_task_error","title":"<code>handle_task_error(context: ErrorContext) -&gt; None</code>","text":"<p>Centralized error handling logic for tasks.</p> <p>Logs the error and re-raises it, wrapping non-TaskExecutionErrors.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>ErrorContext</code> <p>An ErrorContext object containing details about the error.</p> required <p>Raises:</p> Type Description <code>TaskExecutionError</code> <p>Always raises a TaskExecutionError, either the                original one or a newly created wrapper.</p> Source code in <code>src/yaml_workflow/tasks/error_handling.py</code> <pre><code>def handle_task_error(context: ErrorContext) -&gt; None:\n    \"\"\"Centralized error handling logic for tasks.\n\n    Logs the error and re-raises it, wrapping non-TaskExecutionErrors.\n\n    Args:\n        context: An ErrorContext object containing details about the error.\n\n    Raises:\n        TaskExecutionError: Always raises a TaskExecutionError, either the\n                           original one or a newly created wrapper.\n    \"\"\"\n    # Attempt to get workspace from task_config, default to '.' if missing\n    workspace = \".\"\n    if context.task_config and isinstance(\n        context.task_config.get(\"workspace\"), (str, Path)\n    ):\n        workspace = context.task_config[\"workspace\"]\n    elif context.task_config:\n        # Log a warning if workspace exists but is not the expected type or is None\n        logging.warning(\n            f\"Invalid or missing 'workspace' in task_config for step '{context.step_name}'. Defaulting to '.'\"\n        )\n\n    logger = get_task_logger(workspace, context.step_name)\n    log_task_error(logger, context.error)\n\n    if isinstance(context.error, TaskExecutionError):\n        # If it's already a TaskExecutionError, just re-raise it.\n        # Its original_error should have been set correctly when it was created.\n        raise context.error\n    else:\n        # Wrap the original standard error in a TaskExecutionError\n        raise TaskExecutionError(\n            step_name=context.step_name,\n            original_error=context.error,\n            # Pass task_config if available, otherwise None\n            task_config=context.task_config,\n        )\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/file_tasks/","title":"yaml_workflow.tasks.file_tasks","text":""},{"location":"reference/yaml_workflow/tasks/file_tasks/#yaml_workflow.tasks.file_tasks","title":"<code>yaml_workflow.tasks.file_tasks</code>","text":"<p>File operation tasks for working with files and directories.</p>"},{"location":"reference/yaml_workflow/tasks/file_tasks/#yaml_workflow.tasks.file_tasks-classes","title":"Classes","text":""},{"location":"reference/yaml_workflow/tasks/file_tasks/#yaml_workflow.tasks.file_tasks-functions","title":"Functions","text":""},{"location":"reference/yaml_workflow/tasks/file_tasks/#yaml_workflow.tasks.file_tasks.append_file_direct","title":"<code>append_file_direct(file_path: str, content: str, workspace: Path, encoding: str = 'utf-8', step_name: str = 'append_file') -&gt; str</code>","text":"<p>Append content to a file.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>Path to the file</p> required <code>content</code> <code>str</code> <p>Content to append</p> required <code>workspace</code> <code>Path</code> <p>Workspace directory</p> required <code>encoding</code> <code>str</code> <p>File encoding (default: utf-8)</p> <code>'utf-8'</code> <code>step_name</code> <code>str</code> <p>Name of the step for error reporting</p> <code>'append_file'</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Path to the file</p> <p>Raises:</p> Type Description <code>TaskExecutionError</code> <p>If file cannot be appended to</p> Source code in <code>src/yaml_workflow/tasks/file_tasks.py</code> <pre><code>def append_file_direct(\n    file_path: str,\n    content: str,\n    workspace: Path,\n    encoding: str = \"utf-8\",\n    step_name: str = \"append_file\",\n) -&gt; str:\n    \"\"\"Append content to a file.\n\n    Args:\n        file_path: Path to the file\n        content: Content to append\n        workspace: Workspace directory\n        encoding: File encoding (default: utf-8)\n        step_name: Name of the step for error reporting\n\n    Returns:\n        str: Path to the file\n\n    Raises:\n        TaskExecutionError: If file cannot be appended to\n    \"\"\"\n    try:\n        resolved_path = resolve_path(workspace, file_path)\n        ensure_directory(resolved_path, step_name)\n        with open(resolved_path, \"a\", encoding=encoding) as f:\n            f.write(content)\n        return str(resolved_path)\n    except (IOError, UnicodeEncodeError) as e:\n        raise TaskExecutionError(step_name=step_name, original_error=e)\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/file_tasks/#yaml_workflow.tasks.file_tasks.append_file_task","title":"<code>append_file_task(config: TaskConfig) -&gt; Optional[Dict[str, Any]]</code>","text":"<p>Append content to a file.</p> Source code in <code>src/yaml_workflow/tasks/file_tasks.py</code> <pre><code>@register_task(\"append_file\")\ndef append_file_task(config: TaskConfig) -&gt; Optional[Dict[str, Any]]:\n    \"\"\"Append content to a file.\"\"\"\n    task_name = str(config.name or \"append_file\")\n    task_type = config.type or \"append_file\"\n    logger = get_task_logger(config.workspace, task_name)\n    log_task_execution(logger, config.step, config._context, config.workspace)\n    try:\n        processed = config.process_inputs()\n        file_path = processed.get(\"file\")\n        content = processed.get(\"content\")\n        encoding = processed.get(\"encoding\", \"utf-8\")\n\n        if not file_path:\n            raise ValueError(\"No file path provided\")\n        if content is None:\n            raise ValueError(\"No content provided\")\n\n        result = append_file_direct(\n            file_path, str(content), config.workspace, encoding, task_name\n        )\n        output = {\"path\": result, \"content\": content}\n        log_task_result(logger, output)\n        return output\n    except Exception as e:\n        context = ErrorContext(\n            step_name=task_name,\n            task_type=task_type,\n            error=e,\n            task_config=config.step,\n            template_context=config._context,\n        )\n        handle_task_error(context)\n        return None\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/file_tasks/#yaml_workflow.tasks.file_tasks.copy_file_direct","title":"<code>copy_file_direct(source: str, destination: str, workspace: Path, step_name: str = 'copy_file') -&gt; str</code>","text":"<p>Copy a file from source to destination.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str</code> <p>Source file path</p> required <code>destination</code> <code>str</code> <p>Destination file path</p> required <code>workspace</code> <code>Path</code> <p>Workspace directory</p> required <code>step_name</code> <code>str</code> <p>Name of the step for error reporting</p> <code>'copy_file'</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Path to destination file</p> <p>Raises:</p> Type Description <code>TaskExecutionError</code> <p>If file cannot be copied</p> Source code in <code>src/yaml_workflow/tasks/file_tasks.py</code> <pre><code>def copy_file_direct(\n    source: str, destination: str, workspace: Path, step_name: str = \"copy_file\"\n) -&gt; str:\n    \"\"\"Copy a file from source to destination.\n\n    Args:\n        source: Source file path\n        destination: Destination file path\n        workspace: Workspace directory\n        step_name: Name of the step for error reporting\n\n    Returns:\n        str: Path to destination file\n\n    Raises:\n        TaskExecutionError: If file cannot be copied\n    \"\"\"\n    try:\n        source_path = resolve_path(workspace, source)\n        dest_path = resolve_path(workspace, destination)\n        ensure_directory(dest_path, step_name)\n        shutil.copy2(source_path, dest_path)\n        return str(dest_path)\n    except (IOError, shutil.Error) as e:\n        raise TaskExecutionError(step_name=step_name, original_error=e)\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/file_tasks/#yaml_workflow.tasks.file_tasks.copy_file_task","title":"<code>copy_file_task(config: TaskConfig) -&gt; Optional[Dict[str, Any]]</code>","text":"<p>Copy a file from source to destination.</p> Source code in <code>src/yaml_workflow/tasks/file_tasks.py</code> <pre><code>@register_task(\"copy_file\")\ndef copy_file_task(config: TaskConfig) -&gt; Optional[Dict[str, Any]]:\n    \"\"\"Copy a file from source to destination.\"\"\"\n    task_name = str(config.name or \"copy_file\")\n    task_type = config.type or \"copy_file\"\n    logger = get_task_logger(config.workspace, task_name)\n    log_task_execution(logger, config.step, config._context, config.workspace)\n    try:\n        processed = config.process_inputs()\n        source = processed.get(\"source\")\n        destination = processed.get(\"destination\")\n\n        if not source:\n            raise ValueError(\"No source file provided\")\n        if not destination:\n            raise ValueError(\"No destination file provided\")\n\n        result = copy_file_direct(source, destination, config.workspace, task_name)\n        output = {\"source\": source, \"destination\": result}\n        log_task_result(logger, output)\n        return output\n    except Exception as e:\n        context = ErrorContext(\n            step_name=task_name,\n            task_type=task_type,\n            error=e,\n            task_config=config.step,\n            template_context=config._context,\n        )\n        handle_task_error(context)\n        return None\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/file_tasks/#yaml_workflow.tasks.file_tasks.delete_file_direct","title":"<code>delete_file_direct(file_path: str, workspace: Path, step_name: str = 'delete_file') -&gt; str</code>","text":"<p>Delete a file.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>Path to the file</p> required <code>workspace</code> <code>Path</code> <p>Workspace directory</p> required <code>step_name</code> <code>str</code> <p>Name of the step for error reporting</p> <code>'delete_file'</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Path to deleted file</p> <p>Raises:</p> Type Description <code>TaskExecutionError</code> <p>If file cannot be deleted</p> Source code in <code>src/yaml_workflow/tasks/file_tasks.py</code> <pre><code>def delete_file_direct(\n    file_path: str, workspace: Path, step_name: str = \"delete_file\"\n) -&gt; str:\n    \"\"\"Delete a file.\n\n    Args:\n        file_path: Path to the file\n        workspace: Workspace directory\n        step_name: Name of the step for error reporting\n\n    Returns:\n        str: Path to deleted file\n\n    Raises:\n        TaskExecutionError: If file cannot be deleted\n    \"\"\"\n    try:\n        resolved_path = resolve_path(workspace, file_path)\n        if resolved_path.exists():\n            resolved_path.unlink()\n        return str(resolved_path)\n    except IOError as e:\n        raise TaskExecutionError(step_name=step_name, original_error=e)\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/file_tasks/#yaml_workflow.tasks.file_tasks.delete_file_task","title":"<code>delete_file_task(config: TaskConfig) -&gt; Optional[Dict[str, Any]]</code>","text":"<p>Delete a file.</p> Source code in <code>src/yaml_workflow/tasks/file_tasks.py</code> <pre><code>@register_task(\"delete_file\")\ndef delete_file_task(config: TaskConfig) -&gt; Optional[Dict[str, Any]]:\n    \"\"\"Delete a file.\"\"\"\n    task_name = str(config.name or \"delete_file\")\n    task_type = config.type or \"delete_file\"\n    logger = get_task_logger(config.workspace, task_name)\n    log_task_execution(logger, config.step, config._context, config.workspace)\n    try:\n        processed = config.process_inputs()\n        file_path = processed.get(\"file\")\n\n        if not file_path:\n            raise ValueError(\"No file path provided\")\n\n        result = delete_file_direct(file_path, config.workspace, task_name)\n        output = {\"path\": result}\n        log_task_result(logger, output)\n        return output\n    except Exception as e:\n        context = ErrorContext(\n            step_name=task_name,\n            task_type=task_type,\n            error=e,\n            task_config=config.step,\n            template_context=config._context,\n        )\n        handle_task_error(context)\n        return None\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/file_tasks/#yaml_workflow.tasks.file_tasks.ensure_directory","title":"<code>ensure_directory(file_path: Path, step_name: str) -&gt; None</code>","text":"<p>Ensure the directory exists for the given file path.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>Path</code> <p>Path to the file</p> required <code>step_name</code> <code>str</code> <p>Name of the step for error reporting</p> required <p>Raises:</p> Type Description <code>TaskExecutionError</code> <p>If directory cannot be created</p> Source code in <code>src/yaml_workflow/tasks/file_tasks.py</code> <pre><code>def ensure_directory(file_path: Path, step_name: str) -&gt; None:\n    \"\"\"\n    Ensure the directory exists for the given file path.\n\n    Args:\n        file_path: Path to the file\n        step_name: Name of the step for error reporting\n\n    Raises:\n        TaskExecutionError: If directory cannot be created\n    \"\"\"\n    try:\n        file_path.parent.mkdir(parents=True, exist_ok=True)\n    except OSError as e:\n        raise TaskExecutionError(step_name=step_name, original_error=e)\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/file_tasks/#yaml_workflow.tasks.file_tasks.move_file_direct","title":"<code>move_file_direct(source: str, destination: str, workspace: Path, step_name: str = 'move_file') -&gt; str</code>","text":"<p>Move a file from source to destination.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str</code> <p>Source file path</p> required <code>destination</code> <code>str</code> <p>Destination file path</p> required <code>workspace</code> <code>Path</code> <p>Workspace directory</p> required <code>step_name</code> <code>str</code> <p>Name of the step for error reporting</p> <code>'move_file'</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Path to destination file</p> <p>Raises:</p> Type Description <code>TaskExecutionError</code> <p>If file cannot be moved</p> Source code in <code>src/yaml_workflow/tasks/file_tasks.py</code> <pre><code>def move_file_direct(\n    source: str, destination: str, workspace: Path, step_name: str = \"move_file\"\n) -&gt; str:\n    \"\"\"Move a file from source to destination.\n\n    Args:\n        source: Source file path\n        destination: Destination file path\n        workspace: Workspace directory\n        step_name: Name of the step for error reporting\n\n    Returns:\n        str: Path to destination file\n\n    Raises:\n        TaskExecutionError: If file cannot be moved\n    \"\"\"\n    try:\n        source_path = resolve_path(workspace, source)\n        dest_path = resolve_path(workspace, destination)\n        ensure_directory(dest_path, step_name)\n        shutil.move(str(source_path), str(dest_path))\n        return str(dest_path)\n    except (IOError, shutil.Error) as e:\n        raise TaskExecutionError(step_name=step_name, original_error=e)\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/file_tasks/#yaml_workflow.tasks.file_tasks.move_file_task","title":"<code>move_file_task(config: TaskConfig) -&gt; Optional[Dict[str, Any]]</code>","text":"<p>Move a file from source to destination.</p> Source code in <code>src/yaml_workflow/tasks/file_tasks.py</code> <pre><code>@register_task(\"move_file\")\ndef move_file_task(config: TaskConfig) -&gt; Optional[Dict[str, Any]]:\n    \"\"\"Move a file from source to destination.\"\"\"\n    task_name = str(config.name or \"move_file\")\n    task_type = config.type or \"move_file\"\n    logger = get_task_logger(config.workspace, task_name)\n    log_task_execution(logger, config.step, config._context, config.workspace)\n    try:\n        processed = config.process_inputs()\n        source = processed.get(\"source\")\n        destination = processed.get(\"destination\")\n\n        if not source:\n            raise ValueError(\"No source file provided\")\n        if not destination:\n            raise ValueError(\"No destination file provided\")\n\n        result = move_file_direct(source, destination, config.workspace, task_name)\n        output = {\"source\": source, \"destination\": result}\n        log_task_result(logger, output)\n        return output\n    except Exception as e:\n        context = ErrorContext(\n            step_name=task_name,\n            task_type=task_type,\n            error=e,\n            task_config=config.step,\n            template_context=config._context,\n        )\n        handle_task_error(context)\n        return None\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/file_tasks/#yaml_workflow.tasks.file_tasks.process_templates","title":"<code>process_templates(data: Any, context: Dict[str, Any]) -&gt; Any</code>","text":"<p>Process template strings in data structure.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Any</code> <p>Data structure to process</p> required <code>context</code> <code>Dict[str, Any]</code> <p>Template context</p> required <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>Processed data structure</p> <p>Raises:</p> Type Description <code>TemplateError</code> <p>If template resolution fails</p> Source code in <code>src/yaml_workflow/tasks/file_tasks.py</code> <pre><code>def process_templates(data: Any, context: Dict[str, Any]) -&gt; Any:\n    \"\"\"Process template strings in data structure.\n\n    Args:\n        data: Data structure to process\n        context: Template context\n\n    Returns:\n        Any: Processed data structure\n\n    Raises:\n        TemplateError: If template resolution fails\n    \"\"\"\n    if isinstance(data, str):\n        try:\n            template = Template(data, undefined=StrictUndefined)\n            return template.render(**context)\n        except UndefinedError as e:\n            available = {\n                \"args\": list(context[\"args\"].keys()) if \"args\" in context else [],\n                \"env\": list(context[\"env\"].keys()) if \"env\" in context else [],\n                \"steps\": list(context[\"steps\"].keys()) if \"steps\" in context else [],\n            }\n            raise TemplateError(\n                f\"Failed to resolve variable in template '{data}': {str(e)}. \"\n                f\"Available variables: {available}\"\n            )\n    elif isinstance(data, dict):\n        return {k: process_templates(v, context) for k, v in data.items()}\n    elif isinstance(data, list):\n        return [process_templates(v, context) for v in data]\n    return data\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/file_tasks/#yaml_workflow.tasks.file_tasks.read_file_direct","title":"<code>read_file_direct(file_path: str, workspace: Path, encoding: str = 'utf-8', step_name: str = 'read_file') -&gt; str</code>","text":"<p>Read content from a file.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>Path to the file</p> required <code>workspace</code> <code>Path</code> <p>Workspace directory</p> required <code>encoding</code> <code>str</code> <p>File encoding (default: utf-8)</p> <code>'utf-8'</code> <code>step_name</code> <code>str</code> <p>Name of the step for error reporting</p> <code>'read_file'</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>File content</p> <p>Raises:</p> Type Description <code>TaskExecutionError</code> <p>If file cannot be read or decoded</p> Source code in <code>src/yaml_workflow/tasks/file_tasks.py</code> <pre><code>def read_file_direct(\n    file_path: str,\n    workspace: Path,\n    encoding: str = \"utf-8\",\n    step_name: str = \"read_file\",\n) -&gt; str:\n    \"\"\"Read content from a file.\n\n    Args:\n        file_path: Path to the file\n        workspace: Workspace directory\n        encoding: File encoding (default: utf-8)\n        step_name: Name of the step for error reporting\n\n    Returns:\n        str: File content\n\n    Raises:\n        TaskExecutionError: If file cannot be read or decoded\n    \"\"\"\n    try:\n        resolved_path = resolve_path(workspace, file_path)\n        with open(resolved_path, \"rb\") as f:\n            return f.read().decode(encoding)\n    except (IOError, UnicodeDecodeError) as e:\n        raise TaskExecutionError(step_name=step_name, original_error=e)\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/file_tasks/#yaml_workflow.tasks.file_tasks.read_file_task","title":"<code>read_file_task(config: TaskConfig) -&gt; Optional[Dict[str, Any]]</code>","text":"<p>Read content from a file.</p> Source code in <code>src/yaml_workflow/tasks/file_tasks.py</code> <pre><code>@register_task(\"read_file\")\ndef read_file_task(config: TaskConfig) -&gt; Optional[Dict[str, Any]]:\n    \"\"\"Read content from a file.\"\"\"\n    task_name = str(config.name or \"read_file\")\n    task_type = config.type or \"read_file\"\n    logger = get_task_logger(config.workspace, task_name)\n    log_task_execution(logger, config.step, config._context, config.workspace)\n    try:\n        processed = config.process_inputs()\n        file_path_input = processed.get(\"file\")\n        encoding = processed.get(\"encoding\", \"utf-8\")\n\n        if not file_path_input:\n            raise ValueError(\"No file path provided\")\n\n        content = read_file_direct(\n            file_path_input, config.workspace, encoding, task_name\n        )\n        output = {\"path\": file_path_input, \"content\": content}\n        log_task_result(logger, output)\n        return output\n    except Exception as e:\n        context = ErrorContext(\n            step_name=task_name,\n            task_type=task_type,\n            error=e,\n            task_config=config.step,\n            template_context=config._context,\n        )\n        handle_task_error(context)\n        return None\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/file_tasks/#yaml_workflow.tasks.file_tasks.read_json","title":"<code>read_json(file_path: str, workspace: Path, encoding: str = 'utf-8') -&gt; Dict[str, Any]</code>","text":"<p>Read JSON content from a file.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>Path to the file</p> required <code>workspace</code> <code>Path</code> <p>Workspace directory</p> required <code>encoding</code> <code>str</code> <p>File encoding (default: utf-8)</p> <code>'utf-8'</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str, Any]: Parsed JSON content</p> <p>Raises:</p> Type Description <code>TaskExecutionError</code> <p>If file cannot be read or JSON is invalid</p> Source code in <code>src/yaml_workflow/tasks/file_tasks.py</code> <pre><code>def read_json(\n    file_path: str, workspace: Path, encoding: str = \"utf-8\"\n) -&gt; Dict[str, Any]:\n    \"\"\"Read JSON content from a file.\n\n    Args:\n        file_path: Path to the file\n        workspace: Workspace directory\n        encoding: File encoding (default: utf-8)\n\n    Returns:\n        Dict[str, Any]: Parsed JSON content\n\n    Raises:\n        TaskExecutionError: If file cannot be read or JSON is invalid\n    \"\"\"\n    try:\n        content = read_file_direct(file_path, workspace, encoding)\n        return json.loads(content)\n    except json.JSONDecodeError as e:\n        raise TaskExecutionError(step_name=\"read_json\", original_error=e)\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/file_tasks/#yaml_workflow.tasks.file_tasks.read_json_task","title":"<code>read_json_task(config: TaskConfig) -&gt; Optional[Dict[str, Any]]</code>","text":"<p>Task handler for reading JSON files.</p> Source code in <code>src/yaml_workflow/tasks/file_tasks.py</code> <pre><code>@register_task(\"read_json\")\ndef read_json_task(config: TaskConfig) -&gt; Optional[Dict[str, Any]]:\n    \"\"\"Task handler for reading JSON files.\"\"\"\n    task_name = str(config.name or \"read_json\")\n    task_type = config.type or \"read_json\"\n    logger = get_task_logger(config.workspace, task_name)\n    log_task_execution(logger, config.step, config._context, config.workspace)\n\n    try:\n        processed = config.process_inputs()\n        file_path = processed.get(\"file\")\n        encoding = processed.get(\"encoding\", \"utf-8\")\n\n        if not file_path:\n            raise ValueError(\"No file path provided\")\n\n        result_data = read_json(file_path, config.workspace, encoding=encoding)\n        output = {\"data\": result_data}\n        log_task_result(logger, output)\n        return output\n    except Exception as e:\n        context = ErrorContext(\n            step_name=task_name,\n            task_type=task_type,\n            error=e,\n            task_config=config.step,\n            template_context=config._context,\n        )\n        handle_task_error(context)\n        return None\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/file_tasks/#yaml_workflow.tasks.file_tasks.read_yaml","title":"<code>read_yaml(file_path: str, workspace: Path, encoding: str = 'utf-8') -&gt; Dict[str, Any]</code>","text":"<p>Read YAML content from a file.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>Path to the file</p> required <code>workspace</code> <code>Path</code> <p>Workspace directory</p> required <code>encoding</code> <code>str</code> <p>File encoding (default: utf-8)</p> <code>'utf-8'</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str, Any]: Parsed YAML content</p> <p>Raises:</p> Type Description <code>TaskExecutionError</code> <p>If file cannot be read or YAML is invalid</p> Source code in <code>src/yaml_workflow/tasks/file_tasks.py</code> <pre><code>def read_yaml(\n    file_path: str, workspace: Path, encoding: str = \"utf-8\"\n) -&gt; Dict[str, Any]:\n    \"\"\"Read YAML content from a file.\n\n    Args:\n        file_path: Path to the file\n        workspace: Workspace directory\n        encoding: File encoding (default: utf-8)\n\n    Returns:\n        Dict[str, Any]: Parsed YAML content\n\n    Raises:\n        TaskExecutionError: If file cannot be read or YAML is invalid\n    \"\"\"\n    try:\n        content = read_file_direct(file_path, workspace, encoding)\n        return yaml.safe_load(content)\n    except yaml.YAMLError as e:\n        raise TaskExecutionError(step_name=\"read_yaml\", original_error=e)\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/file_tasks/#yaml_workflow.tasks.file_tasks.read_yaml_task","title":"<code>read_yaml_task(config: TaskConfig) -&gt; Optional[Dict[str, Any]]</code>","text":"<p>Task handler for reading YAML files.</p> Source code in <code>src/yaml_workflow/tasks/file_tasks.py</code> <pre><code>@register_task(\"read_yaml\")\ndef read_yaml_task(config: TaskConfig) -&gt; Optional[Dict[str, Any]]:\n    \"\"\"Task handler for reading YAML files.\"\"\"\n    task_name = str(config.name or \"read_yaml\")\n    task_type = config.type or \"read_yaml\"\n    logger = get_task_logger(config.workspace, task_name)\n    log_task_execution(logger, config.step, config._context, config.workspace)\n\n    try:\n        processed = config.process_inputs()\n        file_path = processed.get(\"file\")\n        encoding = processed.get(\"encoding\", \"utf-8\")\n\n        if not file_path:\n            raise ValueError(\"No file path provided\")\n\n        result_data = read_yaml(file_path, config.workspace, encoding=encoding)\n        output = {\"data\": result_data}\n        log_task_result(logger, output)\n        return output\n    except Exception as e:\n        context = ErrorContext(\n            step_name=task_name,\n            task_type=task_type,\n            error=e,\n            task_config=config.step,\n            template_context=config._context,\n        )\n        handle_task_error(context)\n        return None\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/file_tasks/#yaml_workflow.tasks.file_tasks.write_file_direct","title":"<code>write_file_direct(file_path: str, content: str, workspace: Path, encoding: str = 'utf-8', step_name: str = 'write_file') -&gt; str</code>","text":"<p>Write content to a file.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>Path to the file</p> required <code>content</code> <code>str</code> <p>Content to write</p> required <code>workspace</code> <code>Path</code> <p>Workspace directory</p> required <code>encoding</code> <code>str</code> <p>File encoding (default: utf-8)</p> <code>'utf-8'</code> <code>step_name</code> <code>str</code> <p>Name of the step for error reporting</p> <code>'write_file'</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Path to written file</p> <p>Raises:</p> Type Description <code>TaskExecutionError</code> <p>If file cannot be written or encoded</p> Source code in <code>src/yaml_workflow/tasks/file_tasks.py</code> <pre><code>def write_file_direct(\n    file_path: str,\n    content: str,\n    workspace: Path,\n    encoding: str = \"utf-8\",\n    step_name: str = \"write_file\",\n) -&gt; str:\n    \"\"\"Write content to a file.\n\n    Args:\n        file_path: Path to the file\n        content: Content to write\n        workspace: Workspace directory\n        encoding: File encoding (default: utf-8)\n        step_name: Name of the step for error reporting\n\n    Returns:\n        str: Path to written file\n\n    Raises:\n        TaskExecutionError: If file cannot be written or encoded\n    \"\"\"\n    try:\n        resolved_path = resolve_path(workspace, file_path)\n        ensure_directory(resolved_path, step_name)\n        with open(resolved_path, \"wb\") as f:\n            f.write(content.encode(encoding))\n        return str(resolved_path)\n    except (IOError, UnicodeEncodeError) as e:\n        raise TaskExecutionError(step_name=step_name, original_error=e)\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/file_tasks/#yaml_workflow.tasks.file_tasks.write_file_task","title":"<code>write_file_task(config: TaskConfig) -&gt; Optional[Dict[str, Any]]</code>","text":"<p>Write content to a file.</p> Source code in <code>src/yaml_workflow/tasks/file_tasks.py</code> <pre><code>@register_task(\"write_file\")\ndef write_file_task(config: TaskConfig) -&gt; Optional[Dict[str, Any]]:\n    \"\"\"Write content to a file.\"\"\"\n    task_name = str(config.name or \"write_file\")\n    task_type = config.type or \"write_file\"\n    logger = get_task_logger(config.workspace, task_name)\n    log_task_execution(logger, config.step, config._context, config.workspace)\n    try:\n        processed = config.process_inputs()\n        file_path = processed.get(\"file\")\n        content = processed.get(\"content\")\n        encoding = processed.get(\"encoding\", \"utf-8\")\n\n        if not file_path:\n            raise ValueError(\"No file path provided\")\n        if content is None:\n            raise ValueError(\"No content provided\")\n\n        result = write_file_direct(\n            file_path, str(content), config.workspace, encoding, task_name\n        )\n        output = {\"path\": result, \"content\": content}\n        log_task_result(logger, output)\n        return output\n    except Exception as e:\n        context = ErrorContext(\n            step_name=task_name,\n            task_type=task_type,\n            error=e,\n            task_config=config.step,\n            template_context=config._context,\n        )\n        handle_task_error(context)\n        return None\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/file_tasks/#yaml_workflow.tasks.file_tasks.write_json_direct","title":"<code>write_json_direct(file_path: str, data: Union[Dict[str, Any], List[Any]], indent: int = 2, workspace: Path = Path('.'), encoding: str = 'utf-8', step_name: str = 'write_json') -&gt; str</code>","text":"<p>Write JSON data to a file.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>Path to the file</p> required <code>data</code> <code>Union[Dict[str, Any], List[Any]]</code> <p>Data to write</p> required <code>indent</code> <code>int</code> <p>Indentation level (default: 2)</p> <code>2</code> <code>workspace</code> <code>Path</code> <p>Optional workspace directory</p> <code>Path('.')</code> <code>encoding</code> <code>str</code> <p>File encoding (default: utf-8)</p> <code>'utf-8'</code> <code>step_name</code> <code>str</code> <p>Name of the step for error reporting</p> <code>'write_json'</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Path to written file</p> <p>Raises:</p> Type Description <code>TemplateError</code> <p>If file cannot be written</p> Source code in <code>src/yaml_workflow/tasks/file_tasks.py</code> <pre><code>def write_json_direct(\n    file_path: str,\n    data: Union[Dict[str, Any], List[Any]],\n    indent: int = 2,\n    workspace: Path = Path(\".\"),\n    encoding: str = \"utf-8\",\n    step_name: str = \"write_json\",\n) -&gt; str:\n    \"\"\"Write JSON data to a file.\n\n    Args:\n        file_path: Path to the file\n        data: Data to write\n        indent: Indentation level (default: 2)\n        workspace: Optional workspace directory\n        encoding: File encoding (default: utf-8)\n        step_name: Name of the step for error reporting\n\n    Returns:\n        str: Path to written file\n\n    Raises:\n        TemplateError: If file cannot be written\n    \"\"\"\n    try:\n        if workspace:\n            file_path = str(resolve_path(workspace, file_path))\n            ensure_directory(Path(file_path), step_name)\n\n        with open(file_path, \"w\") as f:\n            json.dump(data, f, indent=indent)\n        return file_path\n    except (IOError, TypeError) as e:\n        raise TemplateError(f\"Failed to write JSON file '{file_path}': {str(e)}\")\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/file_tasks/#yaml_workflow.tasks.file_tasks.write_json_task","title":"<code>write_json_task(config: TaskConfig) -&gt; Optional[Dict[str, Any]]</code>","text":"<p>Write JSON data to a file.</p> Source code in <code>src/yaml_workflow/tasks/file_tasks.py</code> <pre><code>@register_task(\"write_json\")\ndef write_json_task(config: TaskConfig) -&gt; Optional[Dict[str, Any]]:\n    \"\"\"Write JSON data to a file.\"\"\"\n    task_name = str(config.name or \"write_json\")\n    task_type = config.type or \"write_json\"\n    logger = get_task_logger(config.workspace, task_name)\n    log_task_execution(logger, config.step, config._context, config.workspace)\n    try:\n        processed = config.process_inputs()\n        file_path = processed.get(\"file\")\n        data = processed.get(\"data\")\n        indent = int(processed.get(\"indent\", 2))\n        encoding = processed.get(\"encoding\", \"utf-8\")\n\n        if not file_path:\n            raise ValueError(\"No file path provided\")\n        if data is None:\n            raise ValueError(\"No data provided\")\n\n        result_path = write_json_direct(\n            file_path,\n            data,\n            indent=indent,\n            workspace=config.workspace,\n            encoding=encoding,\n            step_name=task_name,\n        )\n        output = {\"path\": result_path}\n        log_task_result(logger, output)\n        return output\n    except Exception as e:\n        context = ErrorContext(\n            step_name=task_name,\n            task_type=task_type,\n            error=e,\n            task_config=config.step,\n            template_context=config._context,\n        )\n        handle_task_error(context)\n        return None\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/file_tasks/#yaml_workflow.tasks.file_tasks.write_yaml_direct","title":"<code>write_yaml_direct(file_path: str, data: Dict[str, Any], workspace: Path = Path('.'), encoding: str = 'utf-8', step_name: str = 'write_yaml') -&gt; str</code>","text":"<p>Write YAML data to a file.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>Path to the file</p> required <code>data</code> <code>Dict[str, Any]</code> <p>Data to write</p> required <code>workspace</code> <code>Path</code> <p>Optional workspace directory</p> <code>Path('.')</code> <code>encoding</code> <code>str</code> <p>File encoding (default: utf-8)</p> <code>'utf-8'</code> <code>step_name</code> <code>str</code> <p>Name of the step for error reporting</p> <code>'write_yaml'</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Path to written file</p> <p>Raises:</p> Type Description <code>TemplateError</code> <p>If file cannot be written</p> Source code in <code>src/yaml_workflow/tasks/file_tasks.py</code> <pre><code>def write_yaml_direct(\n    file_path: str,\n    data: Dict[str, Any],\n    workspace: Path = Path(\".\"),\n    encoding: str = \"utf-8\",\n    step_name: str = \"write_yaml\",\n) -&gt; str:\n    \"\"\"Write YAML data to a file.\n\n    Args:\n        file_path: Path to the file\n        data: Data to write\n        workspace: Optional workspace directory\n        encoding: File encoding (default: utf-8)\n        step_name: Name of the step for error reporting\n\n    Returns:\n        str: Path to written file\n\n    Raises:\n        TemplateError: If file cannot be written\n    \"\"\"\n    try:\n        if workspace:\n            file_path = str(resolve_path(workspace, file_path))\n            ensure_directory(Path(file_path), step_name)\n\n        with open(file_path, \"w\") as f:\n            yaml.dump(data, f, default_flow_style=False)\n        return file_path\n    except (IOError, yaml.YAMLError) as e:\n        raise TemplateError(f\"Failed to write YAML file '{file_path}': {str(e)}\")\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/file_tasks/#yaml_workflow.tasks.file_tasks.write_yaml_task","title":"<code>write_yaml_task(config: TaskConfig) -&gt; Optional[Dict[str, Any]]</code>","text":"<p>Write YAML data to a file.</p> Source code in <code>src/yaml_workflow/tasks/file_tasks.py</code> <pre><code>@register_task(\"write_yaml\")\ndef write_yaml_task(config: TaskConfig) -&gt; Optional[Dict[str, Any]]:\n    \"\"\"Write YAML data to a file.\"\"\"\n    task_name = str(config.name or \"write_yaml\")\n    task_type = config.type or \"write_yaml\"\n    logger = get_task_logger(config.workspace, task_name)\n    log_task_execution(logger, config.step, config._context, config.workspace)\n    try:\n        processed = config.process_inputs()\n        file_path = processed.get(\"file\")\n        data = processed.get(\"data\")\n        encoding = processed.get(\"encoding\", \"utf-8\")\n\n        if not file_path:\n            raise ValueError(\"No file path provided\")\n        if data is None:\n            raise ValueError(\"No data provided\")\n\n        result_path = write_yaml_direct(\n            file_path,\n            data,\n            workspace=config.workspace,\n            encoding=encoding,\n            step_name=task_name,\n        )\n        output = {\"path\": result_path}\n        log_task_result(logger, output)\n        return output\n    except Exception as e:\n        context = ErrorContext(\n            step_name=task_name,\n            task_type=task_type,\n            error=e,\n            task_config=config.step,\n            template_context=config._context,\n        )\n        handle_task_error(context)\n        return None\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/file_utils/","title":"yaml_workflow.tasks.file_utils","text":""},{"location":"reference/yaml_workflow/tasks/file_utils/#yaml_workflow.tasks.file_utils","title":"<code>yaml_workflow.tasks.file_utils</code>","text":"<p>File utility tasks for file system operations.</p>"},{"location":"reference/yaml_workflow/tasks/file_utils/#yaml_workflow.tasks.file_utils-classes","title":"Classes","text":""},{"location":"reference/yaml_workflow/tasks/file_utils/#yaml_workflow.tasks.file_utils-functions","title":"Functions","text":""},{"location":"reference/yaml_workflow/tasks/file_utils/#yaml_workflow.tasks.file_utils.list_files","title":"<code>list_files(config: TaskConfig) -&gt; Dict[str, Any]</code>","text":"<p>List files in a directory matching a pattern.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>TaskConfig</code> <p>Task configuration containing: - step: Step configuration - context: Workflow context - workspace: Workspace directory</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str, Any]: Dictionary containing: - file_list: List of matching file paths - total_files: Total number of files found</p> Source code in <code>src/yaml_workflow/tasks/file_utils.py</code> <pre><code>@register_task(\"file_utils\")\ndef list_files(config: TaskConfig) -&gt; Dict[str, Any]:\n    \"\"\"\n    List files in a directory matching a pattern.\n\n    Args:\n        config: Task configuration containing:\n            - step: Step configuration\n            - context: Workflow context\n            - workspace: Workspace directory\n\n    Returns:\n        Dict[str, Any]: Dictionary containing:\n            - file_list: List of matching file paths\n            - total_files: Total number of files found\n    \"\"\"\n    logger = get_task_logger(config.workspace, config.step.get(\"name\", \"list_files\"))\n\n    # Get input parameters\n    inputs = config.step.get(\"inputs\", {})\n    directory = inputs.get(\"directory\")\n    pattern = inputs.get(\"pattern\", \"*\")\n    recursive = inputs.get(\"recursive\", False)\n\n    if not directory:\n        raise ValueError(\"directory parameter is required\")\n\n    # Resolve directory path relative to the workspace root\n    input_path = Path(directory)\n    if input_path.is_absolute():\n        resolved_dir = input_path\n    else:\n        # config.workspace is the Workspace object OR the Path obj in tests\n        # Access the path correctly depending on type (safer check)\n        workspace_path = getattr(config.workspace, \"path\", config.workspace)\n        resolved_dir = workspace_path / input_path\n\n    # Build glob pattern using resolved_dir\n    search_path_base = str(resolved_dir)\n    if recursive:\n        if not pattern.startswith(\"**/\"):\n            pattern = f\"**/{pattern}\"\n    search_pattern = os.path.join(search_path_base, pattern)\n\n    # Find files\n    logger.info(f\"Searching for files: {search_pattern}\")\n    # Use Path objects for manipulation and resolve to absolute paths\n    file_paths = [\n        Path(f).resolve()\n        for f in glob(search_pattern, recursive=recursive)\n        if Path(f).is_file()\n    ]\n    # Convert back to strings for the output dictionary\n    files_str = [str(p) for p in file_paths]\n    total = len(files_str)\n\n    logger.info(f\"Found {total} files matching pattern\")\n\n    # Return results\n    return {\"file_list\": files_str, \"total_files\": total}\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/noop/","title":"yaml_workflow.tasks.noop","text":""},{"location":"reference/yaml_workflow/tasks/noop/#yaml_workflow.tasks.noop","title":"<code>yaml_workflow.tasks.noop</code>","text":"<p>No-operation task for testing and demonstration.</p> <p>This task simply returns its inputs and some metadata about the task execution.</p>"},{"location":"reference/yaml_workflow/tasks/noop/#yaml_workflow.tasks.noop-classes","title":"Classes","text":""},{"location":"reference/yaml_workflow/tasks/noop/#yaml_workflow.tasks.noop-functions","title":"Functions","text":""},{"location":"reference/yaml_workflow/tasks/noop/#yaml_workflow.tasks.noop.noop_task","title":"<code>noop_task(config: TaskConfig) -&gt; Dict[str, Any]</code>","text":"<p>No-operation task that returns its inputs and metadata.</p> <p>This task is useful for testing and demonstrating the workflow engine's features without performing any actual operations.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>TaskConfig</code> <p>Task configuration with: - should_fail: Optional boolean to simulate task failure</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str, Any]: Task inputs and metadata</p> <p>Raises:</p> Type Description <code>TaskExecutionError</code> <p>If should_fail is True (via handle_task_error)</p> Source code in <code>src/yaml_workflow/tasks/noop.py</code> <pre><code>@register_task(\"noop\")\ndef noop_task(config: TaskConfig) -&gt; Dict[str, Any]:\n    \"\"\"\n    No-operation task that returns its inputs and metadata.\n\n    This task is useful for testing and demonstrating the workflow engine's\n    features without performing any actual operations.\n\n    Args:\n        config: Task configuration with:\n            - should_fail: Optional boolean to simulate task failure\n\n    Returns:\n        Dict[str, Any]: Task inputs and metadata\n\n    Raises:\n        TaskExecutionError: If should_fail is True (via handle_task_error)\n    \"\"\"\n    task_name = str(config.name or \"noop_task\")\n    task_type = str(config.type or \"noop\")\n    logger = get_task_logger(config.workspace, task_name)\n\n    try:\n        log_task_execution(logger, config.step, config._context, config.workspace)\n\n        processed = config.process_inputs()\n\n        # Demonstrate error handling if should_fail is True\n        if processed.get(\"should_fail\", False):\n            error = Exception(\"Task failed as requested\")\n            context = ErrorContext(\n                step_name=task_name,\n                task_type=task_type,\n                error=error,\n                task_config=config.step,\n                template_context=config._context,\n            )\n            handle_task_error(context)\n            # handle_task_error always raises, so this is unreachable\n            return {}  # Add return for type checker\n\n        # Return processed inputs and some metadata to demonstrate output handling\n        result = {\n            \"processed_inputs\": processed,\n            \"task_name\": task_name,\n            \"task_type\": config.type,\n            \"available_variables\": config.get_available_variables(),\n        }\n        log_task_result(logger, result)\n        return result\n\n    except Exception as e:\n        # Catch any other unexpected errors during setup/input processing\n        context = ErrorContext(\n            step_name=task_name,\n            task_type=task_type,\n            error=e,\n            task_config=config.step,\n            template_context=config._context,\n        )\n        handle_task_error(context)\n        return {}  # Unreachable\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/python_tasks/","title":"yaml_workflow.tasks.python_tasks","text":""},{"location":"reference/yaml_workflow/tasks/python_tasks/#yaml_workflow.tasks.python_tasks","title":"<code>yaml_workflow.tasks.python_tasks</code>","text":"<p>Python task implementations for executing Python functions.</p>"},{"location":"reference/yaml_workflow/tasks/python_tasks/#yaml_workflow.tasks.python_tasks-classes","title":"Classes","text":""},{"location":"reference/yaml_workflow/tasks/python_tasks/#yaml_workflow.tasks.python_tasks-functions","title":"Functions","text":""},{"location":"reference/yaml_workflow/tasks/python_tasks/#yaml_workflow.tasks.python_tasks.execute_code","title":"<code>execute_code(code: str, config: TaskConfig) -&gt; Any</code>","text":"<p>Execute Python code with TaskConfig support.</p> <p>Parameters:</p> Name Type Description Default <code>code</code> <code>str</code> <p>Python code to execute</p> required <code>config</code> <code>TaskConfig</code> <p>TaskConfig object for variable access</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The value of the 'result' variable after code execution</p> <p>Raises:</p> Type Description <code>TaskExecutionError</code> <p>If code execution fails</p> Source code in <code>src/yaml_workflow/tasks/python_tasks.py</code> <pre><code>def execute_code(code: str, config: TaskConfig) -&gt; Any:\n    \"\"\"Execute Python code with TaskConfig support.\n\n    Args:\n        code: Python code to execute\n        config: TaskConfig object for variable access\n\n    Returns:\n        The value of the 'result' variable after code execution\n\n    Raises:\n        TaskExecutionError: If code execution fails\n    \"\"\"\n    local_vars = {\n        \"context\": config._context,\n        \"args\": config._context.get(\"args\", {}),\n        \"env\": config._context.get(\"env\", {}),\n        \"steps\": config._context.get(\"steps\", {}),\n        \"batch\": config._context.get(\"batch\", {}),\n    }\n    # Update with inputs processed within the caller (python_task)\n    # Do NOT call config.process_inputs() here as it was done by the caller\n    local_vars.update(config._processed_inputs)\n\n    try:\n        exec(code, {}, local_vars)\n        return local_vars.get(\"result\", None)\n    except Exception as e:\n        # Centralized error handling\n        context = ErrorContext(\n            step_name=str(config.name),\n            task_type=str(config.type),\n            error=e,\n            task_config=config.step,\n            template_context=config._context,  # or potentially just local_vars?\n        )\n        handle_task_error(context)\n        return None  # Unreachable\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/python_tasks/#yaml_workflow.tasks.python_tasks.execute_function","title":"<code>execute_function(code: str, config: TaskConfig) -&gt; Any</code>","text":"<p>Execute a Python function with TaskConfig support.</p> <p>Parameters:</p> Name Type Description Default <code>code</code> <code>str</code> <p>Python code containing function definition</p> required <code>config</code> <code>TaskConfig</code> <p>TaskConfig object for variable access</p> required <p>Returns:</p> Type Description <code>Any</code> <p>Function result</p> <p>Raises:</p> Type Description <code>TaskExecutionError</code> <p>If function execution fails</p> Source code in <code>src/yaml_workflow/tasks/python_tasks.py</code> <pre><code>def execute_function(code: str, config: TaskConfig) -&gt; Any:\n    \"\"\"Execute a Python function with TaskConfig support.\n\n    Args:\n        code: Python code containing function definition\n        config: TaskConfig object for variable access\n\n    Returns:\n        Function result\n\n    Raises:\n        TaskExecutionError: If function execution fails\n    \"\"\"\n    try:\n        local_vars: Dict[str, Any] = {}\n        exec(code, {}, local_vars)\n\n        if \"process\" not in local_vars or not callable(local_vars[\"process\"]):\n            raise ValueError(\"Function mode requires a 'process' function\")\n\n        # Inputs already processed by caller (python_task)\n        processed = config._processed_inputs\n        args = processed.get(\"args\", [])\n        kwargs = processed.get(\"kwargs\", {})\n\n        processed_args = []\n        for arg in args:\n            if isinstance(arg, str):\n                try:\n                    import ast\n\n                    processed_args.append(ast.literal_eval(arg))\n                except (ValueError, SyntaxError):\n                    processed_args.append(arg)\n            else:\n                processed_args.append(arg)\n\n        result = local_vars[\"process\"](*processed_args, **kwargs)\n        return result\n    except Exception as e:\n        # Centralized error handling\n        context = ErrorContext(\n            step_name=str(config.name),\n            task_type=str(config.type),\n            error=e,\n            task_config=config.step,\n            template_context=config._context,\n        )\n        handle_task_error(context)\n        return None  # Unreachable\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/python_tasks/#yaml_workflow.tasks.python_tasks.handle_custom_operation","title":"<code>handle_custom_operation(config: TaskConfig) -&gt; Dict[str, Any]</code>","text":"<p>Handle custom operation with TaskConfig support.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>TaskConfig</code> <p>TaskConfig object containing operation parameters</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict containing the custom operation result</p> <p>Raises:</p> Type Description <code>TaskExecutionError</code> <p>If operation fails</p> Source code in <code>src/yaml_workflow/tasks/python_tasks.py</code> <pre><code>def handle_custom_operation(config: TaskConfig) -&gt; Dict[str, Any]:\n    \"\"\"Handle custom operation with TaskConfig support.\n\n    Args:\n        config: TaskConfig object containing operation parameters\n\n    Returns:\n        Dict containing the custom operation result\n\n    Raises:\n        TaskExecutionError: If operation fails\n    \"\"\"\n    try:\n        processed = config._processed_inputs  # Use already processed inputs\n        # Example: Add numbers\n        if config.type == \"add_numbers\":  # Assuming type is passed or inferred\n            num1 = float(processed.get(\"num1\", 0))\n            num2 = float(processed.get(\"num2\", 0))\n            return {\"result\": num1 + num2}\n        else:\n            raise NotImplementedError(\n                f\"Custom operation '{config.type}' not implemented\"\n            )\n\n    except Exception as e:\n        # Centralized error handling\n        context = ErrorContext(\n            step_name=str(config.name),\n            task_type=str(config.type),\n            error=e,\n            task_config=config.step,\n            template_context=config._context,\n        )\n        handle_task_error(context)\n        return {}  # Unreachable\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/python_tasks/#yaml_workflow.tasks.python_tasks.handle_divide_operation","title":"<code>handle_divide_operation(config: TaskConfig) -&gt; Dict[str, Any]</code>","text":"<p>Handle divide operation with TaskConfig support.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>TaskConfig</code> <p>TaskConfig object containing operation parameters</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict containing the division result</p> <p>Raises:</p> Type Description <code>TaskExecutionError</code> <p>If operation fails</p> Source code in <code>src/yaml_workflow/tasks/python_tasks.py</code> <pre><code>def handle_divide_operation(config: TaskConfig) -&gt; Dict[str, Any]:\n    \"\"\"Handle divide operation with TaskConfig support.\n\n    Args:\n        config: TaskConfig object containing operation parameters\n\n    Returns:\n        Dict containing the division result\n\n    Raises:\n        TaskExecutionError: If operation fails\n    \"\"\"\n    try:\n        processed = config._processed_inputs  # Use already processed inputs\n\n        dividend = processed.get(\"dividend\")\n        if \"item\" in processed:\n            dividend = processed[\"item\"]\n        if dividend is None:\n            raise ValueError(\"Dividend must be provided for divide operation\")\n\n        divisor = float(processed.get(\"divisor\", 1))\n        if divisor == 0:\n            raise ZeroDivisionError(\"Division by zero\")\n\n        dividend = float(dividend)\n        # This check seems wrong, removing: if dividend == 0:\n        #    raise TemplateError(\"Cannot divide zero by a number\")\n        division_result = dividend / divisor\n        return {\"result\": division_result}\n\n    except Exception as e:\n        # Centralized error handling\n        context = ErrorContext(\n            step_name=str(config.name),\n            task_type=str(config.type),\n            error=e,\n            task_config=config.step,\n            template_context=config._context,\n        )\n        handle_task_error(context)\n        return {}  # Unreachable\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/python_tasks/#yaml_workflow.tasks.python_tasks.handle_multiply_operation","title":"<code>handle_multiply_operation(config: TaskConfig) -&gt; Dict[str, Any]</code>","text":"<p>Handle multiply operation with TaskConfig support.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>TaskConfig</code> <p>TaskConfig object containing operation parameters</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict containing the multiplication result</p> <p>Raises:</p> Type Description <code>TaskExecutionError</code> <p>If operation fails</p> Source code in <code>src/yaml_workflow/tasks/python_tasks.py</code> <pre><code>def handle_multiply_operation(config: TaskConfig) -&gt; Dict[str, Any]:\n    \"\"\"Handle multiply operation with TaskConfig support.\n\n    Args:\n        config: TaskConfig object containing operation parameters\n\n    Returns:\n        Dict containing the multiplication result\n\n    Raises:\n        TaskExecutionError: If operation fails\n    \"\"\"\n    try:\n        processed = config._processed_inputs  # Use already processed inputs\n\n        numbers = processed.get(\"numbers\", [])\n        if isinstance(numbers, str):\n            try:\n                import ast\n\n                numbers = ast.literal_eval(numbers)\n            except (ValueError, SyntaxError) as e:\n                raise ValueError(\n                    f\"Invalid numbers format: {str(e)}\"\n                )  # Raise specific config error\n\n        if \"item\" in processed:\n            item = processed[\"item\"]\n            if isinstance(item, (int, float)):\n                numbers = [float(item)]\n            elif isinstance(item, list):\n                numbers = [float(x) for x in item]\n            else:\n                raise ValueError(\n                    f\"Item must be a number or list of numbers, got {type(item)}\"\n                )\n        if not numbers:\n            raise ValueError(\"Numbers must be a non-empty list\")\n\n        try:\n            factor = float(processed.get(\"factor\", 1))\n        except (TypeError, ValueError) as e:\n            raise ValueError(f\"Invalid factor: {str(e)}\")\n\n        if \"item\" in processed:\n            results = [num * factor for num in numbers]\n            if isinstance(processed[\"item\"], (int, float)):\n                return {\"result\": float(results[0])}\n            return {\"result\": [float(r) for r in results]}\n\n        multiply_result: float = 1.0\n        for num in numbers:\n            multiply_result *= float(num)\n        multiply_result *= factor\n        return {\"result\": multiply_result}\n\n    except Exception as e:\n        # Centralized error handling\n        context = ErrorContext(\n            step_name=str(config.name),\n            task_type=str(config.type),\n            error=e,\n            task_config=config.step,\n            template_context=config._context,\n        )\n        handle_task_error(context)\n        return {}  # Unreachable\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/python_tasks/#yaml_workflow.tasks.python_tasks.print_message_task","title":"<code>print_message_task(config: TaskConfig) -&gt; dict</code>","text":"<p>Prints a templated message to the console.</p> Source code in <code>src/yaml_workflow/tasks/python_tasks.py</code> <pre><code>@register_task(name=\"print_message\")  # Explicitly register with desired name\ndef print_message_task(config: TaskConfig) -&gt; dict:\n    \"\"\"Prints a templated message to the console.\"\"\"\n    inputs = config.process_inputs()  # Render inputs using context\n    context = config._context\n    message = inputs.get(\"message\", \"\")\n\n    if not message:\n        logger.warning(\"print_message task called with no message.\")\n        # Even if empty, consider it success, just print nothing\n        # return {\"success\": False, \"error\": \"No message provided\"}\n\n    # The message is already rendered by process_inputs, just print it\n    print(message)  # Prints directly to runner's stdout\n    sys.stdout.flush()  # Flush after printing\n    return {\"success\": True, \"printed_length\": len(message)}\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/python_tasks/#yaml_workflow.tasks.python_tasks.print_vars_task","title":"<code>print_vars_task(config: TaskConfig) -&gt; dict</code>","text":"<p>Prints selected variables from the context for debugging.</p> Source code in <code>src/yaml_workflow/tasks/python_tasks.py</code> <pre><code>@register_task()\ndef print_vars_task(config: TaskConfig) -&gt; dict:\n    \"\"\"Prints selected variables from the context for debugging.\"\"\"\n    inputs = config.process_inputs()\n    context = config._context\n    message = inputs.get(\"message\", \"Current Context Variables:\")\n\n    print(f\"\\n--- {message} ---\")  # Prints directly to runner's stdout\n\n    # Select variables to print (add more as needed)\n    print(\"Workflow Variables:\")\n    print(\"==================\")\n    # Use direct context access via config.context\n    print(f\"args: {context.get('args')}\")\n    print(f\"workflow_name: {context.get('workflow_name')}\")\n    print(f\"workspace: {context.get('workspace')}\")\n    print(f\"output: {context.get('output')}\")\n    print(f\"run_number: {context.get('run_number')}\")\n    print(f\"timestamp: {context.get('timestamp')}\")\n\n    # Safely access nested step results\n    print(\"\\nStep Results:\")\n    print(\"=============\")\n    steps_context = context.get(\"steps\", {})\n    if steps_context:\n        # Use pprint for potentially large/nested step results\n        pprint.pprint(steps_context, indent=2)\n        # for name, step_info in steps_context.items():\n        #     if step_info.get(\"skipped\"):\n        #         print(f\"  - {name}: (skipped)\")\n        #     else:\n        #         # Truncate long results for clarity\n        #         result_repr = repr(step_info.get('result', 'N/A'))\n        #         if len(result_repr) &gt; 100:\n        #             result_repr = result_repr[:100] + \"...\"\n        #         print(f\"  - {name}: {result_repr}\")\n    else:\n        print(\"  (No step results yet)\")\n\n    print(\"--------------------\\n\")\n    sys.stdout.flush()  # Flush after printing\n    return {\"success\": True}  # Indicate task success\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/python_tasks/#yaml_workflow.tasks.python_tasks.process_template_value","title":"<code>process_template_value(value: Any, context: Dict[str, Any], task_config: TaskConfig) -&gt; Any</code>","text":"<p>Process a template value using the given context.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Any</code> <p>The value to process (can be a string template or any other type)</p> required <code>context</code> <code>Dict[str, Any]</code> <p>The context for template resolution</p> required <code>task_config</code> <code>TaskConfig</code> <p>The TaskConfig object for error context</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The processed value with preserved type</p> <p>Raises:</p> Type Description <code>TaskExecutionError</code> <p>If template resolution fails or if a variable is undefined</p> Source code in <code>src/yaml_workflow/tasks/python_tasks.py</code> <pre><code>def process_template_value(\n    value: Any, context: Dict[str, Any], task_config: TaskConfig\n) -&gt; Any:\n    \"\"\"Process a template value using the given context.\n\n    Args:\n        value: The value to process (can be a string template or any other type)\n        context: The context for template resolution\n        task_config: The TaskConfig object for error context\n\n    Returns:\n        The processed value with preserved type\n\n    Raises:\n        TaskExecutionError: If template resolution fails or if a variable is undefined\n    \"\"\"\n    if not isinstance(value, str):\n        return value\n\n    try:\n        if \"{{\" in value and \"}}\" in value:\n            template = Template(value, undefined=StrictUndefined)\n            try:\n                result = template.render(context)\n            except UndefinedError as e:\n                # Use new handler, pass task_config for context\n                err_context = ErrorContext(\n                    step_name=str(task_config.name),\n                    task_type=str(task_config.type),\n                    error=e,\n                    task_config=task_config.step,\n                    template_context=context,\n                )\n                handle_task_error(err_context)\n                return None  # Unreachable\n\n            try:\n                import ast\n\n                return ast.literal_eval(result)\n            except (ValueError, SyntaxError):\n                return result\n        return value\n    except Exception as e:\n        # Use new handler, pass task_config for context\n        err_context = ErrorContext(\n            step_name=str(task_config.name),\n            task_type=str(task_config.type),\n            error=e,\n            task_config=task_config.step,\n            template_context=context,\n        )\n        handle_task_error(err_context)\n        return None  # Unreachable\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/python_tasks/#yaml_workflow.tasks.python_tasks.python_task","title":"<code>python_task(config: TaskConfig) -&gt; Dict[str, Any]</code>","text":"<p>Execute a Python task with the given operation and inputs.</p> <p>The task supports two modes: 1. Operation mode: Execute predefined operations (multiply, divide, custom) 2. Code mode: Execute arbitrary Python code</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>TaskConfig</code> <p>TaskConfig object containing task configuration</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict containing the result of the operation/code and task metadata</p> <p>Raises:</p> Type Description <code>TaskExecutionError</code> <p>If the task fails for any reason.</p> Example YAML usage <pre><code>steps:\n  - name: multiply_numbers\n    task: python\n    inputs:\n      operation: multiply\n      numbers: [2, 3, 4]\n      factor: 2\n\n  - name: execute_code\n    task: python\n    inputs:\n      code: |\n        x = 10\n        y = 20\n        result = x + y\n\n  - name: function_mode\n    task: python\n    inputs:\n      operation: function\n      code: |\n        def process(x, y):\n            return x + y\n      args: [\"{{ args.x }}\", \"{{ args.y }}\"]\n</code></pre> Source code in <code>src/yaml_workflow/tasks/python_tasks.py</code> <pre><code>@register_task(\"python\")\ndef python_task(config: TaskConfig) -&gt; Dict[str, Any]:\n    \"\"\"Execute a Python task with the given operation and inputs.\n\n    The task supports two modes:\n    1. Operation mode: Execute predefined operations (multiply, divide, custom)\n    2. Code mode: Execute arbitrary Python code\n\n    Args:\n        config: TaskConfig object containing task configuration\n\n    Returns:\n        Dict containing the result of the operation/code and task metadata\n\n    Raises:\n        TaskExecutionError: If the task fails for any reason.\n\n    Example YAML usage:\n        ```yaml\n        steps:\n          - name: multiply_numbers\n            task: python\n            inputs:\n              operation: multiply\n              numbers: [2, 3, 4]\n              factor: 2\n\n          - name: execute_code\n            task: python\n            inputs:\n              code: |\n                x = 10\n                y = 20\n                result = x + y\n\n          - name: function_mode\n            task: python\n            inputs:\n              operation: function\n              code: |\n                def process(x, y):\n                    return x + y\n              args: [\"{{ args.x }}\", \"{{ args.y }}\"]\n        ```\n    \"\"\"\n    task_name = str(config.name or \"python_task\")\n    task_type = str(config.type or \"python\")\n    logger = get_task_logger(config.workspace, task_name)\n\n    try:\n        log_task_execution(logger, config.step, config._context, config.workspace)\n\n        # Process inputs first to handle any templates\n        # This now uses the refactored config.process_inputs which calls handle_task_error internally\n        processed = config.process_inputs()\n        # Store processed inputs back in config for helper functions to use\n        config._processed_inputs = processed\n\n        result = None\n\n        if \"code\" in processed:\n            if \"operation\" not in processed:\n                result = execute_code(processed[\"code\"], config)\n            elif processed[\"operation\"] == \"function\":\n                result = execute_function(processed[\"code\"], config)\n            # else: # Should we handle invalid operation here?\n            #     raise ValueError(\"Cannot specify both 'code' and 'operation' unless operation is 'function'\")\n        else:\n            operation = processed.get(\"operation\")\n            if not operation:\n                raise ValueError(\n                    \"Either 'code' or 'operation' must be specified for Python task\"\n                )\n\n            if operation == \"multiply\":\n                operation_result = handle_multiply_operation(config)\n                result = operation_result.get(\"result\")\n            elif operation == \"divide\":\n                operation_result = handle_divide_operation(config)\n                result = operation_result.get(\"result\")\n            elif operation == \"custom\":\n                # Assuming handle_custom_operation uses config.type or similar\n                operation_result = handle_custom_operation(config)\n                result = operation_result.get(\"result\")\n            else:\n                raise ValueError(f\"Unknown operation: {operation}\")\n\n        output = {\n            \"result\": result,\n            # Add other potential outputs based on specific operations if needed\n        }\n        log_task_result(logger, output)\n        return output\n\n    except Exception as e:\n        # Centralized error handling for python_task specific errors (e.g., config validation)\n        context = ErrorContext(\n            step_name=task_name,\n            task_type=task_type,\n            error=e,\n            task_config=config.step,\n            template_context=config._context,\n        )\n        handle_task_error(context)\n        return {}  # Unreachable\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/shell_tasks/","title":"yaml_workflow.tasks.shell_tasks","text":""},{"location":"reference/yaml_workflow/tasks/shell_tasks/#yaml_workflow.tasks.shell_tasks","title":"<code>yaml_workflow.tasks.shell_tasks</code>","text":"<p>Shell operation tasks for executing commands and managing processes.</p>"},{"location":"reference/yaml_workflow/tasks/shell_tasks/#yaml_workflow.tasks.shell_tasks-classes","title":"Classes","text":""},{"location":"reference/yaml_workflow/tasks/shell_tasks/#yaml_workflow.tasks.shell_tasks-functions","title":"Functions","text":""},{"location":"reference/yaml_workflow/tasks/shell_tasks/#yaml_workflow.tasks.shell_tasks.check_command","title":"<code>check_command(command: Union[str, List[str]], cwd: Optional[str] = None, env: Optional[Dict[str, str]] = None, shell: bool = False, timeout: Optional[float] = None) -&gt; str</code>","text":"<p>Run a command and raise an error if it fails.</p> <p>Parameters:</p> Name Type Description Default <code>command</code> <code>Union[str, List[str]]</code> <p>Command to run (string or list of arguments)</p> required <code>cwd</code> <code>Optional[str]</code> <p>Working directory for the command</p> <code>None</code> <code>env</code> <code>Optional[Dict[str, str]]</code> <p>Environment variables to set</p> <code>None</code> <code>shell</code> <code>bool</code> <p>Whether to run command through shell</p> <code>False</code> <code>timeout</code> <code>Optional[float]</code> <p>Timeout in seconds</p> <code>None</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Command output (stdout)</p> <p>Raises:</p> Type Description <code>CalledProcessError</code> <p>If command returns non-zero exit code</p> Source code in <code>src/yaml_workflow/tasks/shell_tasks.py</code> <pre><code>def check_command(\n    command: Union[str, List[str]],\n    cwd: Optional[str] = None,\n    env: Optional[Dict[str, str]] = None,\n    shell: bool = False,\n    timeout: Optional[float] = None,\n) -&gt; str:\n    \"\"\"\n    Run a command and raise an error if it fails.\n\n    Args:\n        command: Command to run (string or list of arguments)\n        cwd: Working directory for the command\n        env: Environment variables to set\n        shell: Whether to run command through shell\n        timeout: Timeout in seconds\n\n    Returns:\n        str: Command output (stdout)\n\n    Raises:\n        subprocess.CalledProcessError: If command returns non-zero exit code\n    \"\"\"\n    if isinstance(command, str) and not shell:\n        command = command.split()\n\n    result = subprocess.run(\n        command,\n        cwd=cwd,\n        env=env,\n        shell=shell,\n        capture_output=True,\n        text=True,\n        timeout=timeout,\n        check=True,\n    )\n\n    return result.stdout\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/shell_tasks/#yaml_workflow.tasks.shell_tasks.get_environment","title":"<code>get_environment() -&gt; Dict[str, str]</code>","text":"<p>Get current environment variables.</p> <p>Returns:</p> Type Description <code>Dict[str, str]</code> <p>Dict[str, str]: Dictionary of environment variables</p> Source code in <code>src/yaml_workflow/tasks/shell_tasks.py</code> <pre><code>def get_environment() -&gt; Dict[str, str]:\n    \"\"\"\n    Get current environment variables.\n\n    Returns:\n        Dict[str, str]: Dictionary of environment variables\n    \"\"\"\n    return dict(os.environ)\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/shell_tasks/#yaml_workflow.tasks.shell_tasks.process_command","title":"<code>process_command(command: str, context: Dict[str, Any]) -&gt; str</code>","text":"<p>Process a shell command template with the given context.</p> <p>Parameters:</p> Name Type Description Default <code>command</code> <code>str</code> <p>Shell command template</p> required <code>context</code> <code>Dict[str, Any]</code> <p>Template context</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Processed shell command</p> <p>Raises:</p> Type Description <code>TaskExecutionError</code> <p>If template resolution fails (via handle_task_error)</p> Source code in <code>src/yaml_workflow/tasks/shell_tasks.py</code> <pre><code>def process_command(command: str, context: Dict[str, Any]) -&gt; str:\n    \"\"\"\n    Process a shell command template with the given context.\n\n    Args:\n        command: Shell command template\n        context: Template context\n\n    Returns:\n        str: Processed shell command\n\n    Raises:\n        TaskExecutionError: If template resolution fails (via handle_task_error)\n    \"\"\"\n    try:\n        template = Template(command, undefined=StrictUndefined)\n        return template.render(**context)\n    except UndefinedError as e:\n        task_name = context.get(\"step_name\", \"shell_template\")  # Try to get step name\n        task_type = context.get(\"task_type\", \"shell\")  # Try to get task type\n        # Extract the undefined variable name from the error message\n        var_name = str(e).split(\"'\")[1] if \"'\" in str(e) else \"unknown\"\n\n        # Get available variables by namespace\n        available = {\n            \"args\": list(context.get(\"args\", {}).keys()),\n            \"env\": list(context.get(\"env\", {}).keys()),\n            \"steps\": list(context.get(\"steps\", {}).keys()),\n            \"batch\": (\n                list(context.get(\"batch\", {}).keys()) if \"batch\" in context else []\n            ),\n        }\n\n        # Build a helpful error message\n        msg = f\"Undefined variable '{var_name}' in shell command template. \"\n        msg += \"Available variables by namespace:\\n\"\n        for ns, vars in available.items():\n            msg += f\"  {ns}: {', '.join(vars) if vars else '(empty)'}\\n\"\n\n        # Wrap the original UndefinedError\n        template_error = TemplateError(msg)\n        err_context = ErrorContext(\n            step_name=str(task_name),\n            task_type=str(task_type),\n            error=template_error,\n            task_config=context.get(\"task_config\"),  # Pass config if available\n            template_context=context,\n        )\n        handle_task_error(err_context)\n        return \"\"  # Unreachable\n    except Exception as e:  # Catch other template processing errors\n        handle_task_error(\n            ErrorContext(\n                step_name=str(task_name),\n                task_type=str(task_type),\n                error=e,\n                task_config=context.get(\"task_config\"),\n                template_context=context,\n            )\n        )\n        return \"\"  # Unreachable\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/shell_tasks/#yaml_workflow.tasks.shell_tasks.run_command","title":"<code>run_command(command: Union[str, List[str]], cwd: Optional[str] = None, env: Optional[Dict[str, str]] = None, shell: bool = False, timeout: Optional[float] = None) -&gt; Tuple[int, str, str]</code>","text":"<p>Run a shell command and return its output.</p> <p>Parameters:</p> Name Type Description Default <code>command</code> <code>Union[str, List[str]]</code> <p>Command to run (string or list of arguments)</p> required <code>cwd</code> <code>Optional[str]</code> <p>Working directory for the command</p> <code>None</code> <code>env</code> <code>Optional[Dict[str, str]]</code> <p>Environment variables to set</p> <code>None</code> <code>shell</code> <code>bool</code> <p>Whether to run command through shell</p> <code>False</code> <code>timeout</code> <code>Optional[float]</code> <p>Timeout in seconds</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[int, str, str]</code> <p>Tuple[int, str, str]: Return code, stdout, and stderr</p> Source code in <code>src/yaml_workflow/tasks/shell_tasks.py</code> <pre><code>def run_command(\n    command: Union[str, List[str]],\n    cwd: Optional[str] = None,\n    env: Optional[Dict[str, str]] = None,\n    shell: bool = False,\n    timeout: Optional[float] = None,\n) -&gt; Tuple[int, str, str]:\n    \"\"\"\n    Run a shell command and return its output.\n\n    Args:\n        command: Command to run (string or list of arguments)\n        cwd: Working directory for the command\n        env: Environment variables to set\n        shell: Whether to run command through shell\n        timeout: Timeout in seconds\n\n    Returns:\n        Tuple[int, str, str]: Return code, stdout, and stderr\n    \"\"\"\n    if isinstance(command, str) and not shell:\n        command = command.split()\n\n    result = subprocess.run(\n        command,\n        cwd=cwd,\n        env=env,\n        shell=shell,\n        capture_output=True,\n        text=True,\n        timeout=timeout,\n    )\n\n    return result.returncode, result.stdout, result.stderr\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/shell_tasks/#yaml_workflow.tasks.shell_tasks.set_environment","title":"<code>set_environment(env_vars: Dict[str, str]) -&gt; Dict[str, str]</code>","text":"<p>Set environment variables.</p> <p>Parameters:</p> Name Type Description Default <code>env_vars</code> <code>Dict[str, str]</code> <p>Dictionary of environment variables to set</p> required <p>Returns:</p> Type Description <code>Dict[str, str]</code> <p>Dict[str, str]: Updated environment variables</p> Source code in <code>src/yaml_workflow/tasks/shell_tasks.py</code> <pre><code>def set_environment(env_vars: Dict[str, str]) -&gt; Dict[str, str]:\n    \"\"\"\n    Set environment variables.\n\n    Args:\n        env_vars: Dictionary of environment variables to set\n\n    Returns:\n        Dict[str, str]: Updated environment variables\n    \"\"\"\n    os.environ.update(env_vars)\n    return dict(os.environ)\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/shell_tasks/#yaml_workflow.tasks.shell_tasks.shell_task","title":"<code>shell_task(config: TaskConfig) -&gt; Dict[str, Any]</code>","text":"<p>Run a shell command with namespace support.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>TaskConfig</code> <p>Task configuration with namespace support</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str, Any]: Command execution results</p> <p>Raises:</p> Type Description <code>TaskExecutionError</code> <p>If command execution fails or template resolution fails</p> Source code in <code>src/yaml_workflow/tasks/shell_tasks.py</code> <pre><code>@register_task(\"shell\")\ndef shell_task(config: TaskConfig) -&gt; Dict[str, Any]:\n    \"\"\"\n    Run a shell command with namespace support.\n\n    Args:\n        config: Task configuration with namespace support\n\n    Returns:\n        Dict[str, Any]: Command execution results\n\n    Raises:\n        TaskExecutionError: If command execution fails or template resolution fails\n    \"\"\"\n    # Use str() to handle None safely, default to 'shell_task' if name is None\n    task_name = str(config.name or \"shell_task\")\n    task_type = str(config.type or \"shell\")\n    logger = get_task_logger(config.workspace, task_name)\n\n    try:\n        log_task_execution(logger, config.step, config._context, config.workspace)\n\n        # Process inputs with template support\n        # process_inputs now uses handle_task_error internally\n        processed = config.process_inputs()\n        config._processed_inputs = processed  # Store for potential future use\n\n        # Get command (required)\n        if \"command\" not in processed:\n            # Raise ValueError for config issue, will be caught by outer handler\n            missing_cmd_error = ValueError(\"command parameter is required\")\n            raise missing_cmd_error\n        command = processed[\"command\"]\n\n        # Handle working directory\n        cwd = config.workspace\n        if \"working_dir\" in processed:\n            working_dir = processed[\"working_dir\"]\n            if not os.path.isabs(working_dir):\n                cwd = config.workspace / working_dir\n            else:\n                cwd = Path(working_dir)\n\n        # Get environment variables\n        env = get_environment()\n        if \"env\" in processed:\n            env.update(processed[\"env\"])\n\n        # Get shell mode - default to True for better script compatibility\n        shell = processed.get(\"shell\", True)\n\n        # Get timeout\n        timeout = processed.get(\"timeout\", None)\n\n        # Process command template - process_command now uses handle_task_error\n        # Pass necessary context for error reporting within process_command\n        command_context = {\n            **config._context,\n            \"step_name\": task_name,\n            \"task_type\": task_type,\n            \"task_config\": config.step,\n        }\n        command = process_command(command, command_context)\n\n        # Run command\n        returncode, stdout, stderr = run_command(\n            command, cwd=str(cwd), env=env, shell=shell, timeout=timeout\n        )\n\n        # Check return code\n        if returncode != 0:\n            # Create specific error for non-zero exit code\n            error_message = f\"Command failed with exit code {returncode}\"\n            if stderr:\n                error_message += f\"\\nStderr:\\n{stderr}\"\n            # Use CalledProcessError for consistency, even though we caught it manually\n            cmd_error = subprocess.CalledProcessError(\n                returncode, cmd=command, output=stdout, stderr=stderr\n            )\n            # Let the central handler wrap this\n            raise cmd_error\n\n        # Log successful execution\n        result = {\"return_code\": returncode, \"stdout\": stdout, \"stderr\": stderr}\n        log_task_result(logger, result)\n        return result\n\n    except Exception as e:\n        # Centralized error handling for any exception during setup or execution\n        context = ErrorContext(\n            step_name=task_name,\n            task_type=task_type,\n            error=e,\n            task_config=config.step,\n            template_context=config._context,\n        )\n        handle_task_error(context)\n        return {}  # Unreachable\n</code></pre>"},{"location":"reference/yaml_workflow/tasks/template_tasks/","title":"yaml_workflow.tasks.template_tasks","text":""},{"location":"reference/yaml_workflow/tasks/template_tasks/#yaml_workflow.tasks.template_tasks","title":"<code>yaml_workflow.tasks.template_tasks</code>","text":"<p>Template-based task handlers.</p>"},{"location":"reference/yaml_workflow/tasks/template_tasks/#yaml_workflow.tasks.template_tasks-classes","title":"Classes","text":""},{"location":"reference/yaml_workflow/tasks/template_tasks/#yaml_workflow.tasks.template_tasks-functions","title":"Functions","text":""},{"location":"reference/yaml_workflow/tasks/template_tasks/#yaml_workflow.tasks.template_tasks.render_template","title":"<code>render_template(config: TaskConfig) -&gt; Dict[str, Any]</code>","text":"<p>Render a template and save it to a file.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>TaskConfig</code> <p>Task configuration object</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str, Any]: Dictionary containing the path to the output file</p> <p>Raises:</p> Type Description <code>TaskExecutionError</code> <p>If template resolution fails or file cannot be written (via handle_task_error)</p> Source code in <code>src/yaml_workflow/tasks/template_tasks.py</code> <pre><code>@register_task(\"template\")\ndef render_template(config: TaskConfig) -&gt; Dict[str, Any]:\n    \"\"\"\n    Render a template and save it to a file.\n\n    Args:\n        config: Task configuration object\n\n    Returns:\n        Dict[str, Any]: Dictionary containing the path to the output file\n\n    Raises:\n        TaskExecutionError: If template resolution fails or file cannot be written (via handle_task_error)\n    \"\"\"\n    task_name = str(config.name or \"template_task\")\n    task_type = str(config.type or \"template\")\n    logger = get_task_logger(config.workspace, task_name)\n\n    try:\n        log_task_execution(logger, config.step, config._context, config.workspace)\n\n        # Process inputs with template resolution\n        processed = config.process_inputs()\n\n        template_str = processed.get(\"template\")\n        if not template_str:\n            raise ValueError(\"No template provided\")\n\n        output_file = processed.get(\"output\")\n        if not output_file:\n            raise ValueError(\"No output file specified\")\n\n        # Render template with strict undefined handling\n        template = Template(template_str, undefined=StrictUndefined)\n        rendered = template.render(**config._context)\n\n        # Save to file\n        # Assuming output_file is relative to workspace\n        output_path = config.workspace / output_file\n        output_path.parent.mkdir(parents=True, exist_ok=True)\n        output_path.write_text(rendered)\n\n        result = {\"output_path\": str(output_path)}\n        log_task_result(logger, result)\n        return result\n\n    except Exception as e:\n        # Centralized error handling\n        context = ErrorContext(\n            step_name=task_name,\n            task_type=task_type,\n            error=e,\n            task_config=config.step,\n            template_context=config._context,\n        )\n        handle_task_error(context)\n        return {}  # Unreachable\n</code></pre>"},{"location":"reference/yaml_workflow/utils/","title":"yaml_workflow.utils","text":""},{"location":"reference/yaml_workflow/utils/#yaml_workflow.utils","title":"<code>yaml_workflow.utils</code>","text":""},{"location":"reference/yaml_workflow/utils/yaml_utils/","title":"yaml_workflow.utils.yaml_utils","text":""},{"location":"reference/yaml_workflow/utils/yaml_utils/#yaml_workflow.utils.yaml_utils","title":"<code>yaml_workflow.utils.yaml_utils</code>","text":"<p>YAML utilities for the workflow engine.</p>"},{"location":"reference/yaml_workflow/utils/yaml_utils/#yaml_workflow.utils.yaml_utils-functions","title":"Functions","text":""},{"location":"reference/yaml_workflow/utils/yaml_utils/#yaml_workflow.utils.yaml_utils.get_safe_loader","title":"<code>get_safe_loader() -&gt; type[yaml.SafeLoader]</code>","text":"<p>Get a SafeLoader with custom constructors registered.</p> Source code in <code>src/yaml_workflow/utils/yaml_utils.py</code> <pre><code>def get_safe_loader() -&gt; type[yaml.SafeLoader]:\n    \"\"\"Get a SafeLoader with custom constructors registered.\"\"\"\n    loader = yaml.SafeLoader\n    loader.add_constructor(\"!raw\", raw_constructor)\n    return loader\n</code></pre>"},{"location":"reference/yaml_workflow/utils/yaml_utils/#yaml_workflow.utils.yaml_utils.raw_constructor","title":"<code>raw_constructor(loader: yaml.SafeLoader, node: yaml.ScalarNode) -&gt; str</code>","text":"<p>Constructor for !raw tag that preserves raw string content.</p> Source code in <code>src/yaml_workflow/utils/yaml_utils.py</code> <pre><code>def raw_constructor(loader: yaml.SafeLoader, node: yaml.ScalarNode) -&gt; str:\n    \"\"\"Constructor for !raw tag that preserves raw string content.\"\"\"\n    return loader.construct_scalar(node)\n</code></pre>"}]}